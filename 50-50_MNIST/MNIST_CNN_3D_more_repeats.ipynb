{"cells":[{"cell_type":"markdown","metadata":{"id":"Tnr5Tf1Qa1H-"},"source":["# Setup and utils"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:41.121611Z","iopub.status.busy":"2023-11-12T15:26:41.121288Z","iopub.status.idle":"2023-11-12T15:26:47.333420Z","shell.execute_reply":"2023-11-12T15:26:47.332577Z","shell.execute_reply.started":"2023-11-12T15:26:41.121585Z"},"id":"L0eJ0XYWQHS6","trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import copy\n","import matplotlib.pyplot as plt\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import datasets, transforms\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from types import SimpleNamespace\n","import plotly.express as px\n","import pandas as pd\n","import plotly.graph_objects as go\n","from scipy.interpolate import griddata\n","import math\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device\n","\n","# ------------------------------------ MODEL UTILS ----------------------------------------------\n","class CustomCNN(nn.Module):\n","    def __init__(self, input_dim, output_dim, depth, num_channels, hidden_dim_lin, activation_function, kernel_size, use_pooling=True):\n","        super(CustomCNN, self).__init__()\n","\n","        # Initial number of input channels, assuming grayscale images\n","        in_channels = 1\n","\n","        # Dynamically add convolutional and activation layers based on the specified depth\n","        for i in range(depth):\n","            # Create a convolutional layer and add it to the model\n","            setattr(self, f\"conv{i}\", nn.Conv2d(in_channels, num_channels, kernel_size=kernel_size, padding=math.floor(kernel_size/2)))\n","\n","            # Create an activation layer (e.g., ReLU) and add it to the model\n","            setattr(self, f\"act{i}\", activation_function())\n","\n","            # Update the input dimensions after convolution\n","            input_dim = (input_dim - kernel_size + 2 * math.floor(kernel_size/2)) + 1\n","\n","            # Optionally add pooling layers to reduce spatial dimensions\n","            if use_pooling and (i+1) % depth == 0:\n","                setattr(self, f\"pool{i}\", nn.MaxPool2d(2))\n","                input_dim = input_dim // 2\n","\n","            # Update the input channels for the next convolutional layer\n","            in_channels = num_channels\n","\n","        # Compute the size of the flattened features for the fully connected layer\n","        flattened_size = in_channels * input_dim * input_dim\n","        # Add two fully connected layers for classification\n","        self.fc_1 = nn.Linear(flattened_size, hidden_dim_lin)\n","        self.relu = activation_function()\n","        self.fc_2 = nn.Linear(hidden_dim_lin, output_dim)\n","\n","        # Add log softmax layer for multi-class classification output\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x):\n","        # Iterate over each module in the CustomCNN class\n","        for layer_name, layer in self.named_children():\n","            # Process the input tensor through convolutional and activation layers\n","            if \"conv\" in layer_name or \"act\" in layer_name:\n","                x = layer(x)\n","            # Process the input tensor through pooling layers if they exist\n","            elif \"pool\" in layer_name:\n","                x = layer(x)\n","            # If reached fully connected layers, break the loop\n","            elif isinstance(layer, nn.Linear):\n","                break\n","\n","        # Flatten the tensor to fit the input shape of the fully connected layers\n","        x = x.view(x.size(0), -1)\n","        # Pass the tensor through the fully connected layers\n","        x = self.fc_1(x)\n","        x = self.relu(x)\n","        x = self.fc_2(x)\n","\n","        # Return log softmax activated output\n","        return self.logsoftmax(x)\n","\n","def generate_cnn(input_dim, output_dim, depth, num_channels, hidden_dim_lin, kernel_size, activation_function=nn.ReLU, use_pooling=True):\n","    model = CustomCNN(input_dim, output_dim, depth, num_channels, hidden_dim_lin, activation_function, kernel_size, use_pooling)\n","    return model\n","\n","class Trainer:\n","    \"\"\"\n","    A class for training and evaluating a model with early stopping and best model saving functionalities.\n","\n","    Attributes:\n","    - model: PyTorch model to be trained and evaluated.\n","    - dataloader: Contains data loaders (train, validation, test) for training and evaluation.\n","    - params: Dictionary containing various hyperparameters and settings.\n","    - device: the device to which tensors should be moved before computation.\n","    - optimizer: The optimizer for training.\n","    - best_model_state: State dictionary of the best model.\n","    - max_val_acc: The highest validation accuracy encountered during training.\n","    - no_improve_epochs: Number of epochs without improvement in validation accuracy.\n","    - is_cnn: Flag indicating if the model is a CNN.\n","    - is_debug: Flag indicating if debug information should be printed.\n","    - classification_report_flag: Flag indicating if a classification report should be generated.\n","\n","    Methods:\n","    - train_epoch(): Runs a single epoch of training.\n","    - evaluate(loader): Evaluates the model on a given data loader.\n","    - save_best_model(): Saves the current state of the model as the best model.\n","    - save_checkpoint(epoch, train_acc, val_acc): Saves the current state of the model and other information as a checkpoint.\n","    - early_stopping_check(val_acc): Checks the stopping criterion and performs actions based on it.\n","    - train(): Runs the training process for a number of epochs, with early stopping functionality.\n","\n","    Usage:\n","    params = {\n","      'device': 'cuda',\n","      'lr': 0.001,\n","      'num_train': 10,\n","      'early_stop_patience': 3,\n","      'save_best': True,\n","      'save_checkpoints': False,\n","      'is_cnn': True,\n","      'is_debug': True,\n","      'classification_report_flag': True\n","    }\n","\n","    trainer = Trainer(model, dataloader, params)\n","    train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","    \"\"\"\n","    def __init__(self, model, dataloader, params):\n","        self.model = model\n","        self.dataloader = dataloader\n","        self.params = params\n","        self.device = torch.device(params['device'])\n","        self.optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n","        # optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n","        # Initialize best_model_state with the current model state\n","        self.best_model_state = copy.deepcopy(self.model.state_dict())\n","        self.max_val_acc = 0.\n","        self.no_improve_epochs = 0\n","        self.is_cnn = params.get('is_cnn', False)\n","        self.is_debug = params.get('is_debug', False)\n","        self.classification_report_flag = params.get('classification_report_flag', False)\n","        self.logger = params.get('logger', print)\n","\n","    def train_epoch(self):\n","      self.model.train()\n","      for batch_idx, (data, target) in enumerate(self.dataloader.train_loader):\n","          # Print the size of the current batch\n","          if self.is_cnn:\n","            data = data.view(data.size(0), 1, 28, 28)\n","          else:\n","            data = data.reshape([data.shape[0], -1])\n","          data, target = data.to(self.device), target.to(self.device)\n","          self.optimizer.zero_grad()\n","          output = self.model(data)\n","          loss = F.nll_loss(output, target)\n","          loss.backward()\n","          self.optimizer.step()\n","\n","          if self.is_debug and batch_idx % 20 == 0:\n","              self.logger(f\"Batch: {batch_idx}, Loss: {loss.item()}\")\n","\n","    def evaluate(self, loader):\n","        return eval(self.model, self.device, loader, self.is_debug, self.classification_report_flag, self.is_cnn)\n","\n","    def save_best_model(self):\n","        torch.save(self.model.state_dict(), 'best_model.pth')\n","\n","    def save_checkpoint(self, epoch, train_acc, val_acc):\n","        checkpoint = {\n","            'epoch': epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': self.optimizer.state_dict(),\n","            'train_acc': train_acc,\n","            'val_acc': val_acc\n","        }\n","        torch.save(checkpoint, f'checkpoint_epoch_{epoch}.pth')\n","        return checkpoint\n","\n","    def early_stopping_check(self, val_acc):\n","        if val_acc > self.max_val_acc:\n","            self.max_val_acc = val_acc\n","            self.no_improve_epochs = 0\n","            # Deep copy the model's state\n","            self.best_model_state = copy.deepcopy(self.model.state_dict())\n","            if self.params.get('save_best', False):\n","                self.save_best_model()\n","        else:\n","            self.no_improve_epochs += 1\n","            if self.no_improve_epochs >= self.params['early_stop_patience']:\n","                self.logger(\"Early stopping invoked.\")\n","                # Only load if best_model_state has been set\n","                if self.best_model_state is not None:\n","                    self.model.load_state_dict(self.best_model_state)\n","                return True\n","        return False\n","\n","    def train(self, verbose=1):\n","        effective_epochs = 0\n","        checkpoints = []\n","\n","        for epoch in range(self.params['num_train']):\n","            effective_epochs += 1\n","            self.train_epoch()\n","\n","            train_acc = self.evaluate(self.dataloader.train_loader)\n","            val_acc = self.evaluate(self.dataloader.val_loader)\n","            if verbose >= 1:\n","                self.logger(f'Epoch: {epoch} \\tTraining Accuracy: {train_acc*100:.2f}%')\n","                self.logger(f'Validation Accuracy: {val_acc*100:.2f}%')\n","\n","            if self.params.get('early_stop_patience', None):\n","                if self.early_stopping_check(val_acc):\n","                    self.model.load_state_dict(self.best_model_state)\n","                    break\n","\n","            if self.params.get('save_checkpoints', False):\n","                checkpoint = self.save_checkpoint(epoch, train_acc, val_acc)\n","                checkpoints.append(checkpoint)\n","\n","        # Final evaluations\n","        train_acc = self.evaluate(self.dataloader.train_loader)\n","        test_acc = self.evaluate(self.dataloader.test_loader)\n","\n","        return train_acc, test_acc, effective_epochs, checkpoints\n","\n","def eval(model, device, dataset_loader, debug=False, classification_report_flag=False, is_cnn=True, logger=print):\n","    \"\"\"\n","    Evaluates the model on the given dataset loader.\n","\n","    Parameters:\n","    - model: the PyTorch model to evaluate.\n","    - device: the device to which tensors should be moved before computation.\n","    - dataset_loader: DataLoader for evaluation.\n","    - debug: whether to print debug info like loss and accuracy.\n","    - classification_report_flag: whether to print a classification report.\n","    - is_cnn: a flag indicating if the model is a CNN. If it's not, the input data will be reshaped.\n","    - logger: logging function for printing messages.\n","\n","    Returns:\n","    - Accuracy of the model on the provided dataset loader.\n","\n","    Usage:\n","    - accuracy = eval(model, device, dataset_loader, debug=False, is_cnn=False, classification_report_flag=False)\n","    \"\"\"\n","\n","    model.eval()\n","    test_loss, correct = 0., 0.\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for data, target in dataset_loader:\n","            if is_cnn:\n","              data = data.view(data.size(0), 1, 28, 28)\n","            else:\n","              data = data.reshape([data.shape[0], -1])\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","            all_preds.extend(pred.cpu().numpy())\n","            all_labels.extend(target.cpu().numpy())\n","\n","    num_data = len(dataset_loader.dataset)\n","    test_loss /= num_data\n","    acc = correct / num_data\n","\n","    if debug:\n","        logger('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, num_data, 100. * acc))\n","\n","    if classification_report_flag:\n","        unique_labels = np.unique(all_labels).tolist()\n","        logger(classification_report(all_labels, all_preds, labels=unique_labels, target_names=[f'Class {i}' for i in unique_labels]))\n","\n","    return acc\n","\n","def cut_custom_cnn_model(model, cut_point, freeze=True, reinitialize=False):\n","    \"\"\"\n","    Cut the CustomCNN model at a specific layer and reinitialize the weights for layers after cut_point.\n","\n","    Parameters:\n","    - model (CustomCNN): Original CustomCNN model.\n","    - cut_point (int): Layer index (in terms of conv layers) at which to modify the model.\n","    - freeze (bool): If True, layers before cut_point will have their weights frozen.\n","    - reinitialize (bool): If True, layers after cut_point will have their weights reinitialized.\n","\n","    Returns:\n","    - new_model (CustomCNN): Modified model.\n","    \"\"\"\n","\n","    new_model = copy.deepcopy(model)\n","\n","    # Get names of layers in the model\n","    layer_names = list(new_model._modules.keys())\n","\n","    # Find indices of Conv layers\n","    conv_indices = [i for i, name in enumerate(layer_names) if 'conv' in name]\n","    #print(conv_indices)\n","\n","    # If freeze is True, set requires_grad to False for layers before cut_point\n","    if freeze:\n","        for idx in conv_indices[:cut_point]:\n","            for param in getattr(new_model, layer_names[idx]).parameters():\n","                param.requires_grad = False\n","\n","    # Reinitialize layers after cut_point\n","    if reinitialize:\n","        for idx in conv_indices[cut_point:]:\n","            layer = getattr(new_model, layer_names[idx])\n","            nn.init.kaiming_uniform_(layer.weight, a=0, mode='fan_in', nonlinearity='relu')\n","            if layer.bias is not None:\n","                nn.init.constant_(layer.bias, 0)\n","\n","    # reinit the final dense layer anyway\n","    new_model.fc_2.reset_parameters()\n","\n","    # if reinit_both_dense: reinit the one before the last one too\n","    if params[\"reinit_both_dense\"]:\n","        new_model.fc_1.reset_parameters()\n","\n","    return new_model\n","\n","# --------------------------------- DATA UTILS -----------------------------------\n","def reduce_dataset(dataloader, percentage, balanced=True, seed=42):\n","\n","    \"\"\"\n","    Reduces the dataset to the given percentage. Can ensure class balance if needed.\n","\n","    Parameters:\n","    - dataloader: PyTorch DataLoader object.\n","    - percentage: Desired percentage of the original dataset.\n","    - balanced: If True, ensures class balance. If False, reduces randomly.\n","    - seed: Seed for reproducibility.\n","\n","    Returns:\n","    - reduced_dataloader: DataLoader with the reduced dataset.\n","    \"\"\"\n","    # Extract the dataset from the dataloader\n","    dataset = dataloader.dataset\n","\n","    # Extract all data and labels from the dataset\n","    X = [dataset[i][0] for i in range(len(dataset))]\n","    y = [dataset[i][1] for i in range(len(dataset))]\n","\n","    # Set the seed for reproducibility\n","    torch.manual_seed(seed)\n","\n","    if not balanced:\n","        # Determine the number of samples to keep\n","        num_samples = int(len(dataset) * percentage)\n","\n","        # Randomly select indices without replacement\n","        indices = torch.randperm(len(dataset))[:num_samples].tolist()\n","\n","    else:\n","        # Get unique classes and their counts\n","        classes, class_counts = torch.unique(torch.tensor(y), return_counts=True)\n","\n","        # Determine the number of samples per class to keep\n","        num_samples_per_class = int(len(dataset) * percentage / len(classes))\n","        indices = []\n","\n","        for class_label in classes:\n","            class_indices = [i for i, label in enumerate(y) if label == class_label]\n","\n","            # Randomly select indices without replacement for each class\n","            class_selected_indices = torch.randperm(len(class_indices))[:num_samples_per_class].tolist()\n","            indices.extend([class_indices[i] for i in class_selected_indices])\n","\n","    # Use a Subset of the original dataset to create a reduced dataset\n","    reduced_dataset = data.Subset(dataset, indices)\n","\n","    # Create a DataLoader with the reduced dataset.\n","    reduced_dataloader = data.DataLoader(reduced_dataset, batch_size=dataloader.batch_size, shuffle=True)\n","\n","    return reduced_dataloader\n","\n","class RelabeledSubset(torch.utils.data.Dataset):\n","    def __init__(self, dataset, offset):\n","        self.dataset = dataset\n","        self.offset = offset\n","\n","    def __getitem__(self, idx):\n","        data, label = self.dataset[idx]\n","        # Offset the label to start from 0\n","        label = label - self.offset\n","        return data, label\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","class TransferLearningMNIST(object):\n","    def __init__(self, batch_size, input_dim=28*28, val_split=0.1, num_workers=0, seed=42):\n","        self.input_dim = input_dim\n","        self.output_dim = 10\n","        self.val_split = val_split\n","\n","        def filter_dataset(dataset, classes):\n","            indices = [i for i, t in enumerate(dataset.targets) if t in classes]\n","            return torch.utils.data.Subset(dataset, indices)\n","\n","        mnist_train_data = datasets.MNIST(\n","            '../data',\n","            train=True,\n","            download=True,\n","            transform=transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Lambda(lambda x: (x * 2 - 1) * 0.5),\n","            ]))\n","\n","        pretrain_train_data = filter_dataset(mnist_train_data, list(range(5)))\n","        finetune_train_data = filter_dataset(mnist_train_data, list(range(5, 10)))\n","\n","        pretrain_len = len(pretrain_train_data)\n","        finetune_len = len(finetune_train_data)\n","        pretrain_val_len = int(val_split * pretrain_len)\n","        finetune_val_len = int(val_split * finetune_len)\n","        pretrain_train_set, pretrain_val_set = torch.utils.data.random_split(\n","            pretrain_train_data, [pretrain_len - pretrain_val_len, pretrain_val_len], generator=torch.Generator().manual_seed(seed))\n","        finetune_train_set, finetune_val_set = torch.utils.data.random_split(\n","            finetune_train_data, [finetune_len - finetune_val_len, finetune_val_len], generator=torch.Generator().manual_seed(seed))\n","\n","        self.pretrain_train_loader = torch.utils.data.DataLoader(pretrain_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","        self.pretrain_val_loader = torch.utils.data.DataLoader(pretrain_val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        # Use the RelabeledSubset for fine-tuning datasets\n","        finetune_train_set = RelabeledSubset(finetune_train_set, 5)\n","        finetune_val_set = RelabeledSubset(finetune_val_set, 5)\n","\n","        self.finetune_train_loader = torch.utils.data.DataLoader(finetune_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","        self.finetune_val_loader = torch.utils.data.DataLoader(finetune_val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        mnist_test_data = datasets.MNIST(\n","            '../data',\n","            train=False,\n","            download=True,\n","            transform=transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Lambda(lambda x: (x * 2 - 1) * 0.5),\n","            ]))\n","\n","        pretrain_test_data = filter_dataset(mnist_test_data, list(range(5)))\n","        finetune_test_data = filter_dataset(mnist_test_data, list(range(5, 10)))\n","\n","        self.pretrain_test_loader = torch.utils.data.DataLoader(pretrain_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        # Use the RelabeledSubset for fine-tuning test datasets\n","        finetune_test_data = RelabeledSubset(finetune_test_data, 5)\n","        self.finetune_test_loader = torch.utils.data.DataLoader(finetune_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        # Complete test loader contains all test examples.\n","        self.complete_test_loader = torch.utils.data.DataLoader(mnist_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","class TransferLearningMNISTWrapper:\n","    \"\"\"\n","    This wrapper class provides a convenient way to switch between pretraining and fine-tuning phases.\n","\n","    It allows for changing the phase and accordingly updating the data loaders (train, val, test)\n","    to either pretraining or fine-tuning sets.\n","    \"\"\"\n","    def __init__(self, transferLearningMNISTObj, phase):\n","        \"\"\"\n","        Initializes the TransferLearningMNISTWrapper object.\n","\n","        Parameters:\n","        - transferLearningMNISTObj: An instance of the TransferLearningMNIST class.\n","        - phase: String indicating the current phase (\"pretrain\" or \"finetune\").\n","        \"\"\"\n","        self.transferLearningMNISTObj = transferLearningMNISTObj\n","        self.phase = phase\n","        self.input_dim = self.transferLearningMNISTObj.input_dim\n","        self.output_dim = self.transferLearningMNISTObj.output_dim\n","        self.update_phase(phase)\n","\n","    def update_phase(self, phase):\n","        \"\"\"\n","        Updates the phase and the corresponding data loaders.\n","\n","        Parameters:\n","        - phase: String indicating the desired phase (\"pretrain\" or \"finetune\").\n","\n","        Throws:\n","        - ValueError: If the phase is neither \"pretrain\" nor \"finetune\".\n","        \"\"\"\n","        self.phase = phase\n","        if phase == 'pretrain':\n","            self.train_loader = self.transferLearningMNISTObj.pretrain_train_loader\n","            self.val_loader = self.transferLearningMNISTObj.pretrain_val_loader\n","            self.test_loader = self.transferLearningMNISTObj.pretrain_test_loader\n","        elif phase == 'finetune':\n","            self.train_loader = self.transferLearningMNISTObj.finetune_train_loader\n","            self.val_loader = self.transferLearningMNISTObj.finetune_val_loader\n","            self.test_loader = self.transferLearningMNISTObj.finetune_test_loader\n","        else:\n","            raise ValueError('Phase must be either \"pretrain\" or \"finetune\".')\n","\n","    def get_current_phase(self):\n","      return self.phase\n","\n","# ------------------------------------------ PLOTTING UTILS -------------------------------------------\n","'''def effective_rank(singular_values):\n","    sigma_max = np.max(singular_values)\n","    sigma_min = singular_values[-1] if singular_values[-1] > 0 else np.min(singular_values[singular_values > 0])\n","    # print(sigma_max, sigma_min)\n","    print(np.sqrt(sigma_max / sigma_min))\n","    print('----')\n","    return np.sqrt(sigma_max / sigma_min)'''\n","\n","def effective_rank(singular_values):\n","    normalized_singular_values = singular_values / np.sum(singular_values)\n","    entropy = -np.sum(normalized_singular_values * np.log(normalized_singular_values))\n","    eff_rank = np.exp(entropy)\n","    return eff_rank\n","\n","def plot_layer_effective_ranks(model, print_ranks=True):\n","    effective_ranks = []\n","    layer_names = []\n","\n","    for name, param in model.named_parameters():\n","        if 'weight' in name:  # We are only interested in weight matrices\n","            weight_matrix = param.detach().cpu().numpy()\n","            singular_values = np.linalg.svd(weight_matrix, compute_uv=False)\n","            eff_rank = effective_rank(singular_values)\n","            effective_ranks.append(eff_rank)\n","            layer_names.append(name)\n","\n","    if print_ranks:\n","        for layer_name, eff_rank in zip(layer_names, effective_ranks):\n","            print(f'{layer_name}: {eff_rank:.4f}')\n","\n","    # Plotting\n","    plt.figure(figsize=(15, 5))\n","    plt.bar(layer_names, effective_ranks, color='green')\n","    plt.xlabel('Layer')\n","    plt.ylabel('Effective Rank')\n","    plt.title('Effective Rank of Weight Matrices for Each Layer')\n","    plt.grid(True)\n","\n","    y_max = np.max(effective_ranks) + 1  # Get maximum rank and add 1 for better visualization\n","    y_min = np.min(effective_ranks) - 1  # Get minimum rank and subtract 1 for better visualization\n","    plt.yticks(np.arange(0, int(y_max)+2, step=2))  # Set yticks\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"NJ5JiRZYQW-J"},"source":["# EXPERIMENT SETUP 1: _FREEZE, REINIT, POOLING, DENSE:REINIT BOTH_\n","- percentages_set_1 = [0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.8, 1]\n","- dataset: same as before MNIST 5 to 5\n","\n","- architecture:\n","  - Conv 1 (5,5), channels=10\n","  - Relu\n","  - Conv 2 (5,5), channels=10\n","  - Relu\n","  - Conv 3 (5,5), channels=10\n","  - Relu\n","  - _POOLING_\n","  - Dense 1 (x, a) x=output shape of prev layer, a:random hidden layer width (we use 128)\n","  - Relu\n","  - Dense 2 (a, 5)\n","  - softmax\n","\n","- lr pretraining = 0.001\n","- lr finetuning = 0.0001\n","- lr end-to-end = 0.001\n","\n","- Freezing the layers before the cut: _YES_\n","- Reinitializing the Convolutional layers after the cut: _YES_\n","- Reinitializing Dense 1: _YES_\n","- Reinitializing Dense 2: _YES_\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n","#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:47.336625Z","iopub.status.busy":"2023-11-12T15:26:47.335716Z","iopub.status.idle":"2023-11-12T15:26:47.341905Z","shell.execute_reply":"2023-11-12T15:26:47.340983Z","shell.execute_reply.started":"2023-11-12T15:26:47.336587Z"},"id":"FeWfmLUgswad","trusted":true},"outputs":[],"source":["percentages = [0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.8, 1]\n","learning_rates = [0.001, 0.0001]    # later change when we have lr per layer\n","\n","# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3]\n","seed_set = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]  # currently not being used\n","repeats = 3\n","batch_size = 4096"]},{"cell_type":"markdown","metadata":{"id":"UbrS0kwrcHfE"},"source":["## Pretraining\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act0): ReLU()\n","  (conv1): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act1): ReLU()\n","  (conv2): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act2): ReLU()\n","  (fc_1): Linear(in_features=7840, out_features=128, bias=True)\n","  (relu): ReLU()\n","  (fc_2): Linear(in_features=128, out_features=10, bias=True)\n","  (logsoftmax): LogSoftmax(dim=1)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dataloader = TransferLearningMNIST(batch_size)\n","dataloader_wrapped = TransferLearningMNISTWrapper(dataloader, phase = 'pretrain')\n","\n","# Changes Here for the experiments\n","params = {\n","      'depth': 3,\n","      'width': 10, # num channels for CNN\n","      'hidden_dim_lin': 128,\n","      'activation_function': nn.ReLU,\n","      'kernel_size': 5,\n","      'device': device,\n","      'lr': 0.001,\n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'save_best': True,\n","      'save_checkpoints': True,\n","      'is_cnn': True,\n","      'is_debug': False,\n","      'classification_report_flag': False,\n","      'use_pooling': False,   # CHANGE\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': False,         # CHANGE: reinit the conv lyers only after the cut\n","      'reinit_both_dense': True   # CHANGE: True for reinitialize both dense layers, False for reinit only the last dense layer\n","    }\n","\n","# Create DNN model\n","pretrained_model = generate_cnn(input_dim = 28, output_dim = 10, depth = params['depth'], num_channels = params['width'],\n","                     hidden_dim_lin = params['hidden_dim_lin'], kernel_size = params['kernel_size'], activation_function = params[\"activation_function\"], use_pooling=params['use_pooling'])\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 19.03%\n","Validation Accuracy: 19.65%\n","Epoch: 1 \tTraining Accuracy: 70.13%\n","Validation Accuracy: 69.86%\n","Epoch: 2 \tTraining Accuracy: 88.73%\n","Validation Accuracy: 88.69%\n","Epoch: 3 \tTraining Accuracy: 93.80%\n","Validation Accuracy: 93.59%\n","Epoch: 4 \tTraining Accuracy: 95.07%\n","Validation Accuracy: 94.64%\n","Epoch: 5 \tTraining Accuracy: 95.72%\n","Validation Accuracy: 95.10%\n","Epoch: 6 \tTraining Accuracy: 96.35%\n","Validation Accuracy: 95.36%\n","Epoch: 7 \tTraining Accuracy: 96.74%\n","Validation Accuracy: 95.98%\n","Epoch: 8 \tTraining Accuracy: 97.16%\n","Validation Accuracy: 96.60%\n","Epoch: 9 \tTraining Accuracy: 97.37%\n","Validation Accuracy: 96.73%\n","Epoch: 10 \tTraining Accuracy: 97.63%\n","Validation Accuracy: 96.89%\n","Epoch: 11 \tTraining Accuracy: 97.84%\n","Validation Accuracy: 97.03%\n","Epoch: 12 \tTraining Accuracy: 97.90%\n","Validation Accuracy: 97.25%\n","Epoch: 13 \tTraining Accuracy: 98.18%\n","Validation Accuracy: 97.74%\n","Epoch: 14 \tTraining Accuracy: 98.27%\n","Validation Accuracy: 97.65%\n","Epoch: 15 \tTraining Accuracy: 98.28%\n","Validation Accuracy: 97.78%\n","Epoch: 16 \tTraining Accuracy: 98.47%\n","Validation Accuracy: 98.10%\n","Epoch: 17 \tTraining Accuracy: 98.57%\n","Validation Accuracy: 98.20%\n","Epoch: 18 \tTraining Accuracy: 98.62%\n","Validation Accuracy: 98.17%\n","Epoch: 19 \tTraining Accuracy: 98.60%\n","Validation Accuracy: 97.97%\n","Epoch: 20 \tTraining Accuracy: 98.79%\n","Validation Accuracy: 98.30%\n","Epoch: 21 \tTraining Accuracy: 98.85%\n","Validation Accuracy: 98.30%\n","Epoch: 22 \tTraining Accuracy: 98.95%\n","Validation Accuracy: 98.53%\n","Epoch: 23 \tTraining Accuracy: 99.05%\n","Validation Accuracy: 98.59%\n","Epoch: 24 \tTraining Accuracy: 99.05%\n","Validation Accuracy: 98.46%\n","Epoch: 25 \tTraining Accuracy: 99.12%\n","Validation Accuracy: 98.37%\n","Epoch: 26 \tTraining Accuracy: 99.21%\n","Validation Accuracy: 98.59%\n","Epoch: 27 \tTraining Accuracy: 99.24%\n","Validation Accuracy: 98.59%\n","Epoch: 28 \tTraining Accuracy: 99.21%\n","Validation Accuracy: 98.56%\n","Epoch: 29 \tTraining Accuracy: 99.27%\n","Validation Accuracy: 98.56%\n","Early stopping invoked.\n","Final Training Accuracy: 0.9905\n","Final Test Accuracy: 0.9916\n"]}],"source":["# Train and evaluate\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.0478, Accuracy: 3016.0/3059 (99%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.99      0.99      0.99       544\n","     Class 1       1.00      0.99      0.99       670\n","     Class 2       0.98      0.97      0.98       631\n","     Class 3       0.98      0.98      0.98       613\n","     Class 4       0.99      0.99      0.99       601\n","\n","    accuracy                           0.99      3059\n","   macro avg       0.99      0.99      0.99      3059\n","weighted avg       0.99      0.99      0.99      3059\n","\n"]},{"data":{"text/plain":["0.9859431186662307"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.val_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574},"execution":{"iopub.execute_input":"2023-11-12T15:29:07.305269Z","iopub.status.busy":"2023-11-12T15:29:07.304953Z","iopub.status.idle":"2023-11-12T15:29:09.267085Z","shell.execute_reply":"2023-11-12T15:29:09.266127Z","shell.execute_reply.started":"2023-11-12T15:29:07.305238Z"},"id":"k75KSEM8pj8l","outputId":"be5d50f8-3458-4168-e181-8b94dea876ea","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["conv0.weight: 41.1782\n","conv1.weight: 380.3818\n","conv2.weight: 376.5214\n","fc_1.weight: 100.8473\n","fc_2.weight: 9.8947\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1500x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Effective Rank of Pretrained model\n","plot_layer_effective_ranks(pretrained_model)  # Note: You'll need to define or load 'model' before calling this function\n"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7947\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.001, Repeat: 1\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Train and evaluate\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model_new, dataset_namespace_new, params)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m train_acc, test_acc, effective_epochs, checkpoints \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Test Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Store the results\u001b[39;00m\n","\u001b[1;32m/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=204'>205</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_epoch()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=206'>207</a>\u001b[0m train_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader\u001b[39m.\u001b[39mtrain_loader)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=207'>208</a>\u001b[0m val_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader\u001b[39m.\u001b[39;49mval_loader)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=208'>209</a>\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=209'>210</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTraining Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;32m/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, loader):\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39meval\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice, loader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_debug, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassification_report_flag, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mis_cnn)\n","\u001b[1;32m/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=257'>258</a>\u001b[0m   data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreshape([data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=258'>259</a>\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=259'>260</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=260'>261</a>\u001b[0m test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(output, target, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=261'>262</a>\u001b[0m pred \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","File \u001b[0;32m~/anaconda3/envs/mp-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","\u001b[1;32m/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# Pass the tensor through the fully connected layers\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_1(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/user/Desktop/MP/mp-tl-study/50-50_MNIST/MNIST_CNN_3D_more_repeats.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# Return log softmax activated output\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/mp-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/mp-env/lib/python3.11/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n","File \u001b[0;32m~/anaconda3/envs/mp-env/lib/python3.11/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","# Store results\n","results = []\n","# Store unique combinations that have been tested: we need this if we want to test random combinations\n","# tested_combinations = set()\n","\n","for lr in learning_rates:\n","    params[\"lr\"] = lr\n","    # repeating the whole thing with multiple lr and saving the results somewhere\n","    for sampled_percentage in percentages:\n","        if sampled_percentage <= 0.01:\n","            repeats = 10\n","        elif sampled_percentage < 0.5:\n","            repeats = 5\n","        else:\n","            repeats = 3\n","            \n","        for sampled_cut_point in cuts:\n","            for repeat in range(repeats):\n","                # Add the combination to the tested set\n","                # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","                # Print or log the sampled values for transparency\n","                print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {lr}, Repeat: {repeat}\")\n","\n","                # Reduce the dataset\n","                train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=42)\n","                dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","                torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","                \n","                # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","                model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, freeze=params[\"freeze\"], reinitialize=params[\"reinit\"])\n","\n","                # Train and evaluate\n","                trainer = Trainer(model_new, dataset_namespace_new, params)\n","                train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","                print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","                # Store the results\n","                results.append({\"lr\":lr, \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"markdown","metadata":{},"source":["## Train the Baselines"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["results = []"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T17:54:32.887734Z","iopub.status.busy":"2023-11-12T17:54:32.887406Z","iopub.status.idle":"2023-11-12T18:30:01.606630Z","shell.execute_reply":"2023-11-12T18:30:01.605416Z","shell.execute_reply.started":"2023-11-12T17:54:32.887709Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7396\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7377\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7684\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7690\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.7603\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7081\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7669\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7307\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7904\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7147\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.7834\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 1\n","Training Accuracy: 1.0000, Test Accuracy: 0.7628\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.7953\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.8083\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.8323\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7550\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.8021\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.7937\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.9800, Test Accuracy: 0.8251\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.9000, Test Accuracy: 0.6929\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9615, Test Accuracy: 0.8702\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 1\n","Training Accuracy: 1.0000, Test Accuracy: 0.8764\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.8615, Test Accuracy: 0.8472\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.9615, Test Accuracy: 0.8813\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.8823\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 5\n","Training Accuracy: 0.9923, Test Accuracy: 0.8809\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.8718\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 7\n","Training Accuracy: 0.9923, Test Accuracy: 0.8764\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.8846, Test Accuracy: 0.8702\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 9\n","Training Accuracy: 0.9769, Test Accuracy: 0.8755\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9615, Test Accuracy: 0.9064\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9962, Test Accuracy: 0.9006\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9538, Test Accuracy: 0.9066\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9808, Test Accuracy: 0.8978\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9923, Test Accuracy: 0.8998\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 5\n","Training Accuracy: 0.9808, Test Accuracy: 0.9097\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.3769, Test Accuracy: 0.3497\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 7\n","Training Accuracy: 0.9731, Test Accuracy: 0.9074\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 8\n","Training Accuracy: 0.9692, Test Accuracy: 0.8988\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 9\n","Training Accuracy: 0.9692, Test Accuracy: 0.8998\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9273, Test Accuracy: 0.9150\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9477, Test Accuracy: 0.9301\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9280, Test Accuracy: 0.9194\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9364, Test Accuracy: 0.9255\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9439, Test Accuracy: 0.9249\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9255, Test Accuracy: 0.9198\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9418, Test Accuracy: 0.9331\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9240, Test Accuracy: 0.9194\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9285, Test Accuracy: 0.9192\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9403, Test Accuracy: 0.9288\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9624, Test Accuracy: 0.9547\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9648, Test Accuracy: 0.9582\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9603, Test Accuracy: 0.9556\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9638, Test Accuracy: 0.9576\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9608, Test Accuracy: 0.9545\n","\n","Sampled Percentage: 0.5, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9811, Test Accuracy: 0.9790\n","\n","Sampled Percentage: 0.5, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9821, Test Accuracy: 0.9831\n","\n","Sampled Percentage: 0.5, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9782, Test Accuracy: 0.9786\n","\n","Sampled Percentage: 0.8, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.9826, Test Accuracy: 0.9813\n","\n","Sampled Percentage: 0.8, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9889, Test Accuracy: 0.9864\n","\n","Sampled Percentage: 0.8, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9880, Test Accuracy: 0.9860\n","\n","Sampled Percentage: 1, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9877, Test Accuracy: 0.9850\n","\n","Sampled Percentage: 1, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9917, Test Accuracy: 0.9885\n","\n","Sampled Percentage: 1, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9905, Test Accuracy: 0.9877\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7396\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7377\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7684\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7690\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.7603\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7081\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7669\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7307\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7904\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.7147\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.7834\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 1\n","Training Accuracy: 1.0000, Test Accuracy: 0.7628\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.7953\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 3\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39m# Train and evaluate\u001b[39;00m\n\u001b[1;32m     37\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model_temp, dataset_namespace_new, params)\n\u001b[0;32m---> 38\u001b[0m train_acc, test_acc, effective_epochs, checkpoints \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain(verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Test Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[39m# Store the results\u001b[39;00m\n","Cell \u001b[0;32mIn[1], line 219\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39msave_checkpoints\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 219\u001b[0m         checkpoint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_checkpoint(epoch, train_acc, val_acc)\n\u001b[1;32m    220\u001b[0m         checkpoints\u001b[39m.\u001b[39mappend(checkpoint)\n\u001b[1;32m    222\u001b[0m \u001b[39m# Final evaluations\u001b[39;00m\n","Cell \u001b[0;32mIn[1], line 178\u001b[0m, in \u001b[0;36mTrainer.save_checkpoint\u001b[0;34m(self, epoch, train_acc, val_acc)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_checkpoint\u001b[39m(\u001b[39mself\u001b[39m, epoch, train_acc, val_acc):\n\u001b[1;32m    171\u001b[0m     checkpoint \u001b[39m=\u001b[39m {\n\u001b[1;32m    172\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: epoch,\n\u001b[1;32m    173\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstate_dict(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m: val_acc\n\u001b[1;32m    177\u001b[0m     }\n\u001b[0;32m--> 178\u001b[0m     torch\u001b[39m.\u001b[39;49msave(checkpoint, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcheckpoint_epoch_\u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m}\u001b[39;49;00m\u001b[39m.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    179\u001b[0m     \u001b[39mreturn\u001b[39;00m checkpoint\n","File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/serialization.py:443\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    442\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 443\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    444\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/serialization.py:667\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[39m# given that we copy things around anyway, we might use storage.cpu()\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[39m# this means to that to get tensors serialized, you need to implement\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[39m# .cpu() on the underlying Storage\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m storage\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 667\u001b[0m     storage \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m    668\u001b[0m \u001b[39m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    669\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n","File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/storage.py:121\u001b[0m, in \u001b[0;36m_StorageBase.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mUntypedStorage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize())\u001b[39m.\u001b[39;49mcopy_(\u001b[39mself\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#training of baseline, end to end, models (#trials x #percentages)\n","\n","params[\"lr\"] = 0.001 #back to training learning rate \n","dataloader_wrapped.update_phase('finetune')\n","\n","# template_model = generate_cnn(input_dim = 28, output_dim = 10, depth = params['depth'], num_channels = params['width'],\n","#                      hidden_dim_lin = params['hidden_dim_lin'], kernel_size = params['kernel_size'], activation_function = params[\"activation_function\"], use_pooling=params['use_pooling'])\n","\n","for lr in learning_rates:\n","    params[\"lr\"] = lr\n","    for sampled_percentage in percentages:      \n","        for sampled_percentage in percentages:\n","            if sampled_percentage <= 0.01:\n","                repeats = 10\n","            elif sampled_percentage < 0.5:\n","                repeats = 5\n","            else:\n","                repeats = 3\n","            \n","            for repeat in range(repeats):\n","                # Print or log the sampled values for transparency\n","                print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {lr}, Repeat: {repeat}\")\n","\n","                # Reduce the dataset\n","                train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = 42)\n","                torch.manual_seed(repeat)\n","                #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","                dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","                # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","                #model_temp = copy.deepcopy(template_model)\n","                model_temp = generate_cnn(input_dim = 28, output_dim = 10, depth = params['depth'], num_channels = params['width'],\n","                hidden_dim_lin = params['hidden_dim_lin'], kernel_size = params['kernel_size'], activation_function = params[\"activation_function\"], use_pooling=params['use_pooling'])\n","                model_temp.to(device)\n","\n","                # Train and evaluate\n","                trainer = Trainer(model_temp, dataset_namespace_new, params)\n","                train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","                print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","                # Store the results\n","                results.append({\"lr\":lr, \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"markdown","metadata":{},"source":["## Visualizations"]},{"cell_type":"markdown","metadata":{},"source":["### Print the results and save somewhere for future analysis"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T17:54:32.880142Z","iopub.status.busy":"2023-11-12T17:54:32.879807Z","iopub.status.idle":"2023-11-12T17:54:32.886060Z","shell.execute_reply":"2023-11-12T17:54:32.885037Z","shell.execute_reply.started":"2023-11-12T17:54:32.880110Z"},"id":"750Ub3vCFV9s","outputId":"d8eb5c60-83c5-4c83-cfa4-dd17c1cc9e4a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7395597613659741}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7377082904752109}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7683604196667353}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 1.0, 'test_acc': 0.768977576630323}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.7603373791400946}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 1.0, 'test_acc': 0.7080847562229994}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.7669203867516972}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 1.0, 'test_acc': 0.7307138448878832}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 1.0, 'test_acc': 0.7903723513680313}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 1.0, 'test_acc': 0.714667763834602}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7833779057807035}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7628060069944456}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7953096070767331}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 1.0, 'test_acc': 0.8082699033120757}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.8323390248919975}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 1.0, 'test_acc': 0.7549886854556676}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.8020983336761983}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 1.0, 'test_acc': 0.7936638551738325}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.98, 'test_acc': 0.8251388603168073}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.9, 'test_acc': 0.6928615511211684}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9615384615384616, 'test_acc': 0.8701913186587122}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.8763628882945896}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.8615384615384616, 'test_acc': 0.8471507920181033}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9615384615384616, 'test_acc': 0.8813001440032915}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.8823287389426044}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.9923076923076923, 'test_acc': 0.8808887060275663}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.8718370705616129}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.9923076923076923, 'test_acc': 0.8763628882945896}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.8846153846153846, 'test_acc': 0.8701913186587122}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.9769230769230769, 'test_acc': 0.8755400123431393}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9615384615384616, 'test_acc': 0.9063978605225262}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9961538461538462, 'test_acc': 0.900637728862374}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9538461538461539, 'test_acc': 0.9066035795103888}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9807692307692307, 'test_acc': 0.8977576630322979}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.9923076923076923, 'test_acc': 0.8998148529109237}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.9807692307692307, 'test_acc': 0.9096893643283275}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.3769230769230769, 'test_acc': 0.3497222793663855}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.9730769230769231, 'test_acc': 0.9074264554618391}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.9692307692307692, 'test_acc': 0.8987862579716108}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.9692307692307692, 'test_acc': 0.8998148529109237}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9272727272727272, 'test_acc': 0.9150380580127546}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9477272727272728, 'test_acc': 0.9300555441267229}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.928030303030303, 'test_acc': 0.9193581567578688}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9363636363636364, 'test_acc': 0.9255297263937461}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.943939393939394, 'test_acc': 0.9249125694301584}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9255198487712666, 'test_acc': 0.9197695947335939}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9417769376181474, 'test_acc': 0.9331413289446616}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.924007561436673, 'test_acc': 0.9193581567578688}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9285444234404537, 'test_acc': 0.9191524377700062}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.9402646502835539, 'test_acc': 0.9288212301995474}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9624448645242596, 'test_acc': 0.9547418226702324}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9648393194706995, 'test_acc': 0.9582390454638963}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9603024574669187, 'test_acc': 0.9555646986216828}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9638311279143037, 'test_acc': 0.9576218885003086}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.9608065532451165, 'test_acc': 0.9545361036823699}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.981103552532124, 'test_acc': 0.9790166632380168}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9820861678004535, 'test_acc': 0.9831310429952684}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9781557067271353, 'test_acc': 0.9786052252622917}, {'lr': 0.001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9826169107227208, 'test_acc': 0.9812795721045052}, {'lr': 0.001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9888993859234766, 'test_acc': 0.9864225468010698}, {'lr': 0.001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.987954652810581, 'test_acc': 0.9860111088253446}, {'lr': 0.001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9877486750134419, 'test_acc': 0.9849825138860316}, {'lr': 0.001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.991666026576542, 'test_acc': 0.9884797366796956}, {'lr': 0.001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9905138643521008, 'test_acc': 0.9876568607282452}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7395597613659741}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7377082904752109}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7683604196667353}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 1.0, 'test_acc': 0.768977576630323}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.7603373791400946}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 1.0, 'test_acc': 0.7080847562229994}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.7669203867516972}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 1.0, 'test_acc': 0.7307138448878832}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 1.0, 'test_acc': 0.7903723513680313}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 1.0, 'test_acc': 0.714667763834602}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7833779057807035}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7628060069944456}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7953096070767331}]\n"]}],"source":["print(results)"]},{"cell_type":"markdown","metadata":{"id":"gcNE-dVg7uK-"},"source":["### The Results Table and 3D plot (both go into the report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["{\"lr\":lr, \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["{'lr': 0.001,\n"," 'sampled_percentage': 0.002,\n"," 'sampled_cut_point': -1,\n"," 'repeat': 0,\n"," 'train_acc': 1.0,\n"," 'test_acc': 0.7833779057807035}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["results[10]"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2023-11-12T18:30:01.609498Z","iopub.status.busy":"2023-11-12T18:30:01.608625Z","iopub.status.idle":"2023-11-12T18:30:01.659272Z","shell.execute_reply":"2023-11-12T18:30:01.658364Z","shell.execute_reply.started":"2023-11-12T18:30:01.609455Z"},"id":"qhGdMh3o7x2y","outputId":"a978e1ba-9bb5-4ac9-f8e9-7002898c9214","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["i:  10 repeat:  0\n","i:  10 repeat:  0\n","i:  10 repeat:  0\n","i:  10 repeat:  0\n","i:  20 repeat:  0\n","i:  20 repeat:  0\n","i:  20 repeat:  0\n","i:  20 repeat:  0\n","i:  30 repeat:  0\n","i:  30 repeat:  0\n","i:  30 repeat:  0\n","i:  30 repeat:  0\n","i:  40 repeat:  0\n","i:  40 repeat:  0\n","i:  40 repeat:  0\n","i:  40 repeat:  0\n","i:  45 repeat:  5\n","i:  45 repeat:  0\n","i:  45 repeat:  0\n","i:  45 repeat:  0\n","i:  45 repeat:  0\n","i:  50 repeat:  5\n","i:  50 repeat:  0\n","i:  50 repeat:  0\n","i:  50 repeat:  0\n","i:  50 repeat:  0\n","i:  55 repeat:  5\n","i:  55 repeat:  0\n","i:  55 repeat:  0\n","i:  55 repeat:  0\n","i:  55 repeat:  0\n","i:  58 repeat:  3\n","i:  58 repeat:  0\n","i:  58 repeat:  0\n","i:  58 repeat:  0\n","i:  58 repeat:  0\n","i:  61 repeat:  3\n","i:  61 repeat:  0\n","i:  61 repeat:  0\n","i:  61 repeat:  0\n","i:  61 repeat:  0\n","i:  64 repeat:  3\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n"]},{"name":"stderr","output_type":"stream","text":["/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n","  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Percentage</th>\n","      <th>Cut Point</th>\n","      <th>Learning Rate</th>\n","      <th>Mean Train Accuracy</th>\n","      <th>Std Train Accuracy</th>\n","      <th>Mean Test Accuracy</th>\n","      <th>Std Test Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.001</td>\n","      <td>-1</td>\n","      <td>0.0010</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.74857</td>\n","      <td>0.025174</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.001</td>\n","      <td>0</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.001</td>\n","      <td>1</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.001</td>\n","      <td>2</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.001</td>\n","      <td>3</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>1.000</td>\n","      <td>-1</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>1.000</td>\n","      <td>0</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>1.000</td>\n","      <td>1</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>1.000</td>\n","      <td>2</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>1.000</td>\n","      <td>3</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows  7 columns</p>\n","</div>"],"text/plain":["    Percentage  Cut Point  Learning Rate  Mean Train Accuracy   \n","0        0.001         -1         0.0010                  1.0  \\\n","1        0.001          0         0.0010                  NaN   \n","2        0.001          1         0.0010                  NaN   \n","3        0.001          2         0.0010                  NaN   \n","4        0.001          3         0.0010                  NaN   \n","..         ...        ...            ...                  ...   \n","95       1.000         -1         0.0001                  NaN   \n","96       1.000          0         0.0001                  NaN   \n","97       1.000          1         0.0001                  NaN   \n","98       1.000          2         0.0001                  NaN   \n","99       1.000          3         0.0001                  NaN   \n","\n","    Std Train Accuracy  Mean Test Accuracy  Std Test Accuracy  \n","0                  0.0             0.74857           0.025174  \n","1                  NaN                 NaN                NaN  \n","2                  NaN                 NaN                NaN  \n","3                  NaN                 NaN                NaN  \n","4                  NaN                 NaN                NaN  \n","..                 ...                 ...                ...  \n","95                 NaN                 NaN                NaN  \n","96                 NaN                 NaN                NaN  \n","97                 NaN                 NaN                NaN  \n","98                 NaN                 NaN                NaN  \n","99                 NaN                 NaN                NaN  \n","\n","[100 rows x 7 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# first of all convert results to df and calculate the mean and std of repats\n","repeats_mean = []\n","i = 0\n","for lr in learning_rates:\n","    for sampled_percentage in percentages:\n","        for sampled_cut_point in [-1]+cuts:\n","            \n","            train, test = [], []\n","            for repeat in range(repeats):\n","                if results[i][\"repeat\"] != repeat or results[i][\"sampled_percentage\"] != sampled_percentage or results[i][\"sampled_cut_point\"] != sampled_cut_point or results[i][\"lr\"] != lr:\n","                    print(\"i: \", i, \"repeat: \", repeat)\n","                    break\n","                train.append(results[i][\"train_acc\"])\n","                test.append(results[i][\"test_acc\"])\n","                i += 1\n","            repeats_mean.append((sampled_percentage, sampled_cut_point, lr, np.mean(train), np.std(train), np.mean(test), np.std(test)))\n","df = pd.DataFrame(repeats_mean, columns=['Percentage', 'Cut Point', 'Learning Rate', 'Mean Train Accuracy', 'Std Train Accuracy', 'Mean Test Accuracy', 'Std Test Accuracy'])\n","df"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}

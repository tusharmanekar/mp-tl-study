{"cells":[{"cell_type":"markdown","metadata":{"id":"Tnr5Tf1Qa1H-"},"source":["# Setup and utils"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:41.121611Z","iopub.status.busy":"2023-11-12T15:26:41.121288Z","iopub.status.idle":"2023-11-12T15:26:47.333420Z","shell.execute_reply":"2023-11-12T15:26:47.332577Z","shell.execute_reply.started":"2023-11-12T15:26:41.121585Z"},"id":"L0eJ0XYWQHS6","trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import copy\n","import matplotlib.pyplot as plt\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as data\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision import datasets, transforms\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from types import SimpleNamespace\n","import plotly.express as px\n","import pandas as pd\n","import plotly.graph_objects as go\n","from scipy.interpolate import griddata\n","import math\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device\n","\n","# ------------------------------------ MODEL UTILS ----------------------------------------------\n","class CustomCNN(nn.Module):\n","    def __init__(self, input_dim, output_dim, depth, num_channels, hidden_dim_lin, activation_function, kernel_size, use_pooling=True):\n","        super(CustomCNN, self).__init__()\n","\n","        # Initial number of input channels, assuming grayscale images\n","        in_channels = 1\n","\n","        # Dynamically add convolutional and activation layers based on the specified depth\n","        for i in range(depth):\n","            # Create a convolutional layer and add it to the model\n","            setattr(self, f\"conv{i}\", nn.Conv2d(in_channels, num_channels, kernel_size=kernel_size, padding=math.floor(kernel_size/2)))\n","\n","            # Create an activation layer (e.g., ReLU) and add it to the model\n","            setattr(self, f\"act{i}\", activation_function())\n","\n","            # Update the input dimensions after convolution\n","            input_dim = (input_dim - kernel_size + 2 * math.floor(kernel_size/2)) + 1\n","\n","            # Optionally add pooling layers to reduce spatial dimensions\n","            if use_pooling and (i+1) % depth == 0:\n","                setattr(self, f\"pool{i}\", nn.MaxPool2d(2))\n","                input_dim = input_dim // 2\n","\n","            # Update the input channels for the next convolutional layer\n","            in_channels = num_channels\n","\n","        # Compute the size of the flattened features for the fully connected layer\n","        flattened_size = in_channels * input_dim * input_dim\n","        # Add two fully connected layers for classification\n","        self.fc_1 = nn.Linear(flattened_size, hidden_dim_lin)\n","        self.relu = activation_function()\n","        self.fc_2 = nn.Linear(hidden_dim_lin, output_dim)\n","\n","        # Add log softmax layer for multi-class classification output\n","        self.logsoftmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x):\n","        # Iterate over each module in the CustomCNN class\n","        for layer_name, layer in self.named_children():\n","            # Process the input tensor through convolutional and activation layers\n","            if \"conv\" in layer_name or \"act\" in layer_name:\n","                x = layer(x)\n","            # Process the input tensor through pooling layers if they exist\n","            elif \"pool\" in layer_name:\n","                x = layer(x)\n","            # If reached fully connected layers, break the loop\n","            elif isinstance(layer, nn.Linear):\n","                break\n","\n","        # Flatten the tensor to fit the input shape of the fully connected layers\n","        x = x.view(x.size(0), -1)\n","        # Pass the tensor through the fully connected layers\n","        x = self.fc_1(x)\n","        x = self.relu(x)\n","        x = self.fc_2(x)\n","\n","        # Return log softmax activated output\n","        return self.logsoftmax(x)\n","\n","def generate_cnn(input_dim, output_dim, depth, num_channels, hidden_dim_lin, kernel_size, activation_function=nn.ReLU, use_pooling=True):\n","    model = CustomCNN(input_dim, output_dim, depth, num_channels, hidden_dim_lin, activation_function, kernel_size, use_pooling)\n","    return model\n","\n","class Trainer:\n","    \"\"\"\n","    A class for training and evaluating a model with early stopping and best model saving functionalities.\n","\n","    Attributes:\n","    - model: PyTorch model to be trained and evaluated.\n","    - dataloader: Contains data loaders (train, validation, test) for training and evaluation.\n","    - params: Dictionary containing various hyperparameters and settings.\n","    - device: the device to which tensors should be moved before computation.\n","    - optimizer: The optimizer for training.\n","    - best_model_state: State dictionary of the best model.\n","    - max_val_acc: The highest validation accuracy encountered during training.\n","    - no_improve_epochs: Number of epochs without improvement in validation accuracy.\n","    - is_cnn: Flag indicating if the model is a CNN.\n","    - is_debug: Flag indicating if debug information should be printed.\n","    - classification_report_flag: Flag indicating if a classification report should be generated.\n","\n","    Methods:\n","    - train_epoch(): Runs a single epoch of training.\n","    - evaluate(loader): Evaluates the model on a given data loader.\n","    - save_best_model(): Saves the current state of the model as the best model.\n","    - save_checkpoint(epoch, train_acc, val_acc): Saves the current state of the model and other information as a checkpoint.\n","    - early_stopping_check(val_acc): Checks the stopping criterion and performs actions based on it.\n","    - train(): Runs the training process for a number of epochs, with early stopping functionality.\n","\n","    Usage:\n","    params = {\n","      'device': 'cuda',\n","      'lr': 0.001,\n","      'num_train': 10,\n","      'early_stop_patience': 3,\n","      'save_best': True,\n","      'save_checkpoints': False,\n","      'is_cnn': True,\n","      'is_debug': True,\n","      'classification_report_flag': True\n","    }\n","\n","    trainer = Trainer(model, dataloader, params)\n","    train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","    \"\"\"\n","    def __init__(self, model, dataloader, params):\n","        self.model = model\n","        self.dataloader = dataloader\n","        self.params = params\n","        self.device = torch.device(params['device'])\n","        self.optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n","        # optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n","        # Initialize best_model_state with the current model state\n","        self.best_model_state = copy.deepcopy(self.model.state_dict())\n","        self.max_val_acc = 0.\n","        self.no_improve_epochs = 0\n","        self.is_cnn = params.get('is_cnn', False)\n","        self.is_debug = params.get('is_debug', False)\n","        self.classification_report_flag = params.get('classification_report_flag', False)\n","        self.logger = params.get('logger', print)\n","\n","    def train_epoch(self):\n","      self.model.train()\n","      for batch_idx, (data, target) in enumerate(self.dataloader.train_loader):\n","          # Print the size of the current batch\n","          if self.is_cnn:\n","            data = data.view(data.size(0), 1, 28, 28)\n","          else:\n","            data = data.reshape([data.shape[0], -1])\n","          data, target = data.to(self.device), target.to(self.device)\n","          self.optimizer.zero_grad()\n","          output = self.model(data)\n","          loss = F.nll_loss(output, target)\n","          loss.backward()\n","          self.optimizer.step()\n","\n","          if self.is_debug and batch_idx % 20 == 0:\n","              self.logger(f\"Batch: {batch_idx}, Loss: {loss.item()}\")\n","\n","    def evaluate(self, loader):\n","        return eval(self.model, self.device, loader, self.is_debug, self.classification_report_flag, self.is_cnn)\n","\n","    def save_best_model(self):\n","        torch.save(self.model.state_dict(), 'best_model.pth')\n","\n","    def save_checkpoint(self, epoch, train_acc, val_acc):\n","        checkpoint = {\n","            'epoch': epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': self.optimizer.state_dict(),\n","            'train_acc': train_acc,\n","            'val_acc': val_acc\n","        }\n","        torch.save(checkpoint, f'checkpoint_epoch_{epoch}.pth')\n","        return checkpoint\n","\n","    def early_stopping_check(self, val_acc):\n","        if val_acc > self.max_val_acc:\n","            self.max_val_acc = val_acc\n","            self.no_improve_epochs = 0\n","            # Deep copy the model's state\n","            self.best_model_state = copy.deepcopy(self.model.state_dict())\n","            if self.params.get('save_best', False):\n","                self.save_best_model()\n","        else:\n","            self.no_improve_epochs += 1\n","            if self.no_improve_epochs >= self.params['early_stop_patience']:\n","                self.logger(\"Early stopping invoked.\")\n","                # Only load if best_model_state has been set\n","                if self.best_model_state is not None:\n","                    self.model.load_state_dict(self.best_model_state)\n","                return True\n","        return False\n","\n","    def train(self, verbose=1):\n","        effective_epochs = 0\n","        checkpoints = []\n","\n","        for epoch in range(self.params['num_train']):\n","            effective_epochs += 1\n","            self.train_epoch()\n","\n","            train_acc = self.evaluate(self.dataloader.train_loader)\n","            val_acc = self.evaluate(self.dataloader.val_loader)\n","            if verbose >= 1:\n","                self.logger(f'Epoch: {epoch} \\tTraining Accuracy: {train_acc*100:.2f}%')\n","                self.logger(f'Validation Accuracy: {val_acc*100:.2f}%')\n","\n","            if self.params.get('early_stop_patience', None):\n","                if self.early_stopping_check(val_acc):\n","                    self.model.load_state_dict(self.best_model_state)\n","                    break\n","\n","            if self.params.get('save_checkpoints', False):\n","                checkpoint = self.save_checkpoint(epoch, train_acc, val_acc)\n","                checkpoints.append(checkpoint)\n","\n","        # Final evaluations\n","        train_acc = self.evaluate(self.dataloader.train_loader)\n","        test_acc = self.evaluate(self.dataloader.test_loader)\n","\n","        return train_acc, test_acc, effective_epochs, checkpoints\n","\n","def eval(model, device, dataset_loader, debug=False, classification_report_flag=False, is_cnn=True, logger=print):\n","    \"\"\"\n","    Evaluates the model on the given dataset loader.\n","\n","    Parameters:\n","    - model: the PyTorch model to evaluate.\n","    - device: the device to which tensors should be moved before computation.\n","    - dataset_loader: DataLoader for evaluation.\n","    - debug: whether to print debug info like loss and accuracy.\n","    - classification_report_flag: whether to print a classification report.\n","    - is_cnn: a flag indicating if the model is a CNN. If it's not, the input data will be reshaped.\n","    - logger: logging function for printing messages.\n","\n","    Returns:\n","    - Accuracy of the model on the provided dataset loader.\n","\n","    Usage:\n","    - accuracy = eval(model, device, dataset_loader, debug=False, is_cnn=False, classification_report_flag=False)\n","    \"\"\"\n","\n","    model.eval()\n","    test_loss, correct = 0., 0.\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for data, target in dataset_loader:\n","            if is_cnn:\n","              data = data.view(data.size(0), 1, 28, 28)\n","            else:\n","              data = data.reshape([data.shape[0], -1])\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","            all_preds.extend(pred.cpu().numpy())\n","            all_labels.extend(target.cpu().numpy())\n","\n","    num_data = len(dataset_loader.dataset)\n","    test_loss /= num_data\n","    acc = correct / num_data\n","\n","    if debug:\n","        logger('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, num_data, 100. * acc))\n","\n","    if classification_report_flag:\n","        unique_labels = np.unique(all_labels).tolist()\n","        logger(classification_report(all_labels, all_preds, labels=unique_labels, target_names=[f'Class {i}' for i in unique_labels]))\n","\n","    return acc\n","\n","def cut_custom_cnn_model(model, cut_point, freeze=True, reinitialize=False):\n","    \"\"\"\n","    Cut the CustomCNN model at a specific layer and reinitialize the weights for layers after cut_point.\n","\n","    Parameters:\n","    - model (CustomCNN): Original CustomCNN model.\n","    - cut_point (int): Layer index (in terms of conv layers) at which to modify the model.\n","    - freeze (bool): If True, layers before cut_point will have their weights frozen.\n","    - reinitialize (bool): If True, layers after cut_point will have their weights reinitialized.\n","\n","    Returns:\n","    - new_model (CustomCNN): Modified model.\n","    \"\"\"\n","\n","    new_model = copy.deepcopy(model)\n","\n","    # Get names of layers in the model\n","    layer_names = list(new_model._modules.keys())\n","\n","    # Find indices of Conv layers\n","    conv_indices = [i for i, name in enumerate(layer_names) if 'conv' in name]\n","    #print(conv_indices)\n","\n","    # If freeze is True, set requires_grad to False for layers before cut_point\n","    if freeze:\n","        for idx in conv_indices[:cut_point]:\n","            for param in getattr(new_model, layer_names[idx]).parameters():\n","                param.requires_grad = False\n","\n","    # Reinitialize layers after cut_point\n","    if reinitialize:\n","        for idx in conv_indices[cut_point:]:\n","            layer = getattr(new_model, layer_names[idx])\n","            nn.init.kaiming_uniform_(layer.weight, a=0, mode='fan_in', nonlinearity='relu')\n","            if layer.bias is not None:\n","                nn.init.constant_(layer.bias, 0)\n","\n","    # reinit the final dense layer anyway\n","    new_model.fc_2.reset_parameters()\n","\n","    # if reinit_both_dense: reinit the one before the last one too\n","    if params[\"reinit_both_dense\"]:\n","        new_model.fc_1.reset_parameters()\n","\n","    return new_model\n","\n","# --------------------------------- DATA UTILS -----------------------------------\n","def reduce_dataset(dataloader, percentage, balanced=True, seed=42):\n","\n","    \"\"\"\n","    Reduces the dataset to the given percentage. Can ensure class balance if needed.\n","\n","    Parameters:\n","    - dataloader: PyTorch DataLoader object.\n","    - percentage: Desired percentage of the original dataset.\n","    - balanced: If True, ensures class balance. If False, reduces randomly.\n","    - seed: Seed for reproducibility.\n","\n","    Returns:\n","    - reduced_dataloader: DataLoader with the reduced dataset.\n","    \"\"\"\n","    # Extract the dataset from the dataloader\n","    dataset = dataloader.dataset\n","\n","    # Extract all data and labels from the dataset\n","    X = [dataset[i][0] for i in range(len(dataset))]\n","    y = [dataset[i][1] for i in range(len(dataset))]\n","\n","    # Set the seed for reproducibility\n","    torch.manual_seed(seed)\n","\n","    if not balanced:\n","        # Determine the number of samples to keep\n","        num_samples = int(len(dataset) * percentage)\n","\n","        # Randomly select indices without replacement\n","        indices = torch.randperm(len(dataset))[:num_samples].tolist()\n","\n","    else:\n","        # Get unique classes and their counts\n","        classes, class_counts = torch.unique(torch.tensor(y), return_counts=True)\n","\n","        # Determine the number of samples per class to keep\n","        num_samples_per_class = int(len(dataset) * percentage / len(classes))\n","        indices = []\n","\n","        for class_label in classes:\n","            class_indices = [i for i, label in enumerate(y) if label == class_label]\n","\n","            # Randomly select indices without replacement for each class\n","            class_selected_indices = torch.randperm(len(class_indices))[:num_samples_per_class].tolist()\n","            indices.extend([class_indices[i] for i in class_selected_indices])\n","\n","    # Use a Subset of the original dataset to create a reduced dataset\n","    reduced_dataset = data.Subset(dataset, indices)\n","\n","    # Create a DataLoader with the reduced dataset.\n","    reduced_dataloader = data.DataLoader(reduced_dataset, batch_size=dataloader.batch_size, shuffle=True)\n","\n","    return reduced_dataloader\n","\n","class RelabeledSubset(torch.utils.data.Dataset):\n","    def __init__(self, dataset, offset):\n","        self.dataset = dataset\n","        self.offset = offset\n","\n","    def __getitem__(self, idx):\n","        data, label = self.dataset[idx]\n","        # Offset the label to start from 0\n","        label = label - self.offset\n","        return data, label\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","class TransferLearningMNIST(object):\n","    def __init__(self, batch_size, input_dim=28*28, val_split=0.1, num_workers=0, seed=42):\n","        self.input_dim = input_dim\n","        self.output_dim = 10\n","        self.val_split = val_split\n","\n","        def filter_dataset(dataset, classes):\n","            indices = [i for i, t in enumerate(dataset.targets) if t in classes]\n","            return torch.utils.data.Subset(dataset, indices)\n","\n","        mnist_train_data = datasets.MNIST(\n","            '../data',\n","            train=True,\n","            download=True,\n","            transform=transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Lambda(lambda x: (x * 2 - 1) * 0.5),\n","            ]))\n","\n","        pretrain_train_data = filter_dataset(mnist_train_data, list(range(5)))\n","        finetune_train_data = filter_dataset(mnist_train_data, list(range(5, 10)))\n","\n","        pretrain_len = len(pretrain_train_data)\n","        finetune_len = len(finetune_train_data)\n","        pretrain_val_len = int(val_split * pretrain_len)\n","        finetune_val_len = int(val_split * finetune_len)\n","        pretrain_train_set, pretrain_val_set = torch.utils.data.random_split(\n","            pretrain_train_data, [pretrain_len - pretrain_val_len, pretrain_val_len], generator=torch.Generator().manual_seed(seed))\n","        finetune_train_set, finetune_val_set = torch.utils.data.random_split(\n","            finetune_train_data, [finetune_len - finetune_val_len, finetune_val_len], generator=torch.Generator().manual_seed(seed))\n","\n","        self.pretrain_train_loader = torch.utils.data.DataLoader(pretrain_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","        self.pretrain_val_loader = torch.utils.data.DataLoader(pretrain_val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        # Use the RelabeledSubset for fine-tuning datasets\n","        finetune_train_set = RelabeledSubset(finetune_train_set, 5)\n","        finetune_val_set = RelabeledSubset(finetune_val_set, 5)\n","\n","        self.finetune_train_loader = torch.utils.data.DataLoader(finetune_train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","        self.finetune_val_loader = torch.utils.data.DataLoader(finetune_val_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        mnist_test_data = datasets.MNIST(\n","            '../data',\n","            train=False,\n","            download=True,\n","            transform=transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Lambda(lambda x: (x * 2 - 1) * 0.5),\n","            ]))\n","\n","        pretrain_test_data = filter_dataset(mnist_test_data, list(range(5)))\n","        finetune_test_data = filter_dataset(mnist_test_data, list(range(5, 10)))\n","\n","        self.pretrain_test_loader = torch.utils.data.DataLoader(pretrain_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        # Use the RelabeledSubset for fine-tuning test datasets\n","        finetune_test_data = RelabeledSubset(finetune_test_data, 5)\n","        self.finetune_test_loader = torch.utils.data.DataLoader(finetune_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","        # Complete test loader contains all test examples.\n","        self.complete_test_loader = torch.utils.data.DataLoader(mnist_test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","class TransferLearningMNISTWrapper:\n","    \"\"\"\n","    This wrapper class provides a convenient way to switch between pretraining and fine-tuning phases.\n","\n","    It allows for changing the phase and accordingly updating the data loaders (train, val, test)\n","    to either pretraining or fine-tuning sets.\n","    \"\"\"\n","    def __init__(self, transferLearningMNISTObj, phase):\n","        \"\"\"\n","        Initializes the TransferLearningMNISTWrapper object.\n","\n","        Parameters:\n","        - transferLearningMNISTObj: An instance of the TransferLearningMNIST class.\n","        - phase: String indicating the current phase (\"pretrain\" or \"finetune\").\n","        \"\"\"\n","        self.transferLearningMNISTObj = transferLearningMNISTObj\n","        self.phase = phase\n","        self.input_dim = self.transferLearningMNISTObj.input_dim\n","        self.output_dim = self.transferLearningMNISTObj.output_dim\n","        self.update_phase(phase)\n","\n","    def update_phase(self, phase):\n","        \"\"\"\n","        Updates the phase and the corresponding data loaders.\n","\n","        Parameters:\n","        - phase: String indicating the desired phase (\"pretrain\" or \"finetune\").\n","\n","        Throws:\n","        - ValueError: If the phase is neither \"pretrain\" nor \"finetune\".\n","        \"\"\"\n","        self.phase = phase\n","        if phase == 'pretrain':\n","            self.train_loader = self.transferLearningMNISTObj.pretrain_train_loader\n","            self.val_loader = self.transferLearningMNISTObj.pretrain_val_loader\n","            self.test_loader = self.transferLearningMNISTObj.pretrain_test_loader\n","        elif phase == 'finetune':\n","            self.train_loader = self.transferLearningMNISTObj.finetune_train_loader\n","            self.val_loader = self.transferLearningMNISTObj.finetune_val_loader\n","            self.test_loader = self.transferLearningMNISTObj.finetune_test_loader\n","        else:\n","            raise ValueError('Phase must be either \"pretrain\" or \"finetune\".')\n","\n","    def get_current_phase(self):\n","      return self.phase\n","\n","# ------------------------------------------ PLOTTING UTILS -------------------------------------------\n","'''def effective_rank(singular_values):\n","    sigma_max = np.max(singular_values)\n","    sigma_min = singular_values[-1] if singular_values[-1] > 0 else np.min(singular_values[singular_values > 0])\n","    # print(sigma_max, sigma_min)\n","    print(np.sqrt(sigma_max / sigma_min))\n","    print('----')\n","    return np.sqrt(sigma_max / sigma_min)'''\n","\n","def effective_rank(singular_values):\n","    normalized_singular_values = singular_values / np.sum(singular_values)\n","    entropy = -np.sum(normalized_singular_values * np.log(normalized_singular_values))\n","    eff_rank = np.exp(entropy)\n","    return eff_rank\n","\n","def plot_layer_effective_ranks(model, print_ranks=True):\n","    effective_ranks = []\n","    layer_names = []\n","\n","    for name, param in model.named_parameters():\n","        if 'weight' in name:  # We are only interested in weight matrices\n","            weight_matrix = param.detach().cpu().numpy()\n","            singular_values = np.linalg.svd(weight_matrix, compute_uv=False)\n","            eff_rank = effective_rank(singular_values)\n","            effective_ranks.append(eff_rank)\n","            layer_names.append(name)\n","\n","    if print_ranks:\n","        for layer_name, eff_rank in zip(layer_names, effective_ranks):\n","            print(f'{layer_name}: {eff_rank:.4f}')\n","\n","    # Plotting\n","    plt.figure(figsize=(15, 5))\n","    plt.bar(layer_names, effective_ranks, color='green')\n","    plt.xlabel('Layer')\n","    plt.ylabel('Effective Rank')\n","    plt.title('Effective Rank of Weight Matrices for Each Layer')\n","    plt.grid(True)\n","\n","    y_max = np.max(effective_ranks) + 1  # Get maximum rank and add 1 for better visualization\n","    y_min = np.min(effective_ranks) - 1  # Get minimum rank and subtract 1 for better visualization\n","    plt.yticks(np.arange(0, int(y_max)+2, step=2))  # Set yticks\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"NJ5JiRZYQW-J"},"source":["# EXPERIMENT SETUP 1: _FREEZE, REINIT, POOLING, DENSE:REINIT BOTH_\n","- percentages_set_1 = [0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.8, 1]\n","- dataset: same as before MNIST 5 to 5\n","\n","- architecture:\n","  - Conv 1 (5,5), channels=10\n","  - Relu\n","  - Conv 2 (5,5), channels=10\n","  - Relu\n","  - Conv 3 (5,5), channels=10\n","  - Relu\n","  - _POOLING_\n","  - Dense 1 (x, a) x=output shape of prev layer, a:random hidden layer width (we use 128)\n","  - Relu\n","  - Dense 2 (a, 5)\n","  - softmax\n","\n","- lr pretraining = 0.001\n","- lr finetuning = 0.0001\n","- lr end-to-end = 0.001\n","\n","- Freezing the layers before the cut: _YES_\n","- Reinitializing the Convolutional layers after the cut: _YES_\n","- Reinitializing Dense 1: _YES_\n","- Reinitializing Dense 2: _YES_\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n","#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:47.336625Z","iopub.status.busy":"2023-11-12T15:26:47.335716Z","iopub.status.idle":"2023-11-12T15:26:47.341905Z","shell.execute_reply":"2023-11-12T15:26:47.340983Z","shell.execute_reply.started":"2023-11-12T15:26:47.336587Z"},"id":"FeWfmLUgswad","trusted":true},"outputs":[],"source":["percentages = [0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.8, 1]\n","learning_rates = [0.001, 0.0001]    # later change when we have lr per layer\n","\n","# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3]\n","seed_set = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]  # currently not being used\n","repeats = 3\n","batch_size = 4096"]},{"cell_type":"markdown","metadata":{"id":"UbrS0kwrcHfE"},"source":["## Pretraining\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act0): ReLU()\n","  (conv1): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act1): ReLU()\n","  (conv2): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act2): ReLU()\n","  (fc_1): Linear(in_features=7840, out_features=128, bias=True)\n","  (relu): ReLU()\n","  (fc_2): Linear(in_features=128, out_features=10, bias=True)\n","  (logsoftmax): LogSoftmax(dim=1)\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dataloader = TransferLearningMNIST(batch_size)\n","dataloader_wrapped = TransferLearningMNISTWrapper(dataloader, phase = 'pretrain')\n","\n","# Changes Here for the experiments\n","params = {\n","      'depth': 3,\n","      'width': 10, # num channels for CNN\n","      'hidden_dim_lin': 128,\n","      'activation_function': nn.ReLU,\n","      'kernel_size': 5,\n","      'device': device,\n","      'lr': 0.001,\n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'save_best': True,\n","      'save_checkpoints': True,\n","      'is_cnn': True,\n","      'is_debug': False,\n","      'classification_report_flag': False,\n","      'use_pooling': False,   # CHANGE\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': False,         # CHANGE: reinit the conv lyers only after the cut\n","      'reinit_both_dense': True   # CHANGE: True for reinitialize both dense layers, False for reinit only the last dense layer\n","    }\n","\n","# Create DNN model\n","pretrained_model = generate_cnn(input_dim = 28, output_dim = 10, depth = params['depth'], num_channels = params['width'],\n","                     hidden_dim_lin = params['hidden_dim_lin'], kernel_size = params['kernel_size'], activation_function = params[\"activation_function\"], use_pooling=params['use_pooling'])\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 52.84%\n","Validation Accuracy: 50.25%\n","Epoch: 1 \tTraining Accuracy: 78.55%\n","Validation Accuracy: 77.90%\n","Epoch: 2 \tTraining Accuracy: 90.26%\n","Validation Accuracy: 89.51%\n","Epoch: 3 \tTraining Accuracy: 93.81%\n","Validation Accuracy: 93.00%\n","Epoch: 4 \tTraining Accuracy: 95.36%\n","Validation Accuracy: 94.61%\n","Epoch: 5 \tTraining Accuracy: 95.73%\n","Validation Accuracy: 94.87%\n","Epoch: 6 \tTraining Accuracy: 96.43%\n","Validation Accuracy: 95.46%\n","Epoch: 7 \tTraining Accuracy: 96.78%\n","Validation Accuracy: 95.95%\n","Epoch: 8 \tTraining Accuracy: 97.06%\n","Validation Accuracy: 96.31%\n","Epoch: 9 \tTraining Accuracy: 97.23%\n","Validation Accuracy: 96.40%\n","Epoch: 10 \tTraining Accuracy: 97.33%\n","Validation Accuracy: 96.73%\n","Epoch: 11 \tTraining Accuracy: 97.61%\n","Validation Accuracy: 97.16%\n","Epoch: 12 \tTraining Accuracy: 97.70%\n","Validation Accuracy: 97.12%\n","Epoch: 13 \tTraining Accuracy: 97.90%\n","Validation Accuracy: 97.32%\n","Epoch: 14 \tTraining Accuracy: 98.01%\n","Validation Accuracy: 97.25%\n","Epoch: 15 \tTraining Accuracy: 98.17%\n","Validation Accuracy: 97.55%\n","Epoch: 16 \tTraining Accuracy: 98.16%\n","Validation Accuracy: 97.45%\n","Epoch: 17 \tTraining Accuracy: 98.39%\n","Validation Accuracy: 97.94%\n","Epoch: 18 \tTraining Accuracy: 98.43%\n","Validation Accuracy: 97.81%\n","Epoch: 19 \tTraining Accuracy: 98.51%\n","Validation Accuracy: 98.23%\n","Epoch: 20 \tTraining Accuracy: 98.49%\n","Validation Accuracy: 97.78%\n","Epoch: 21 \tTraining Accuracy: 98.63%\n","Validation Accuracy: 98.10%\n","Epoch: 22 \tTraining Accuracy: 98.67%\n","Validation Accuracy: 98.27%\n","Epoch: 23 \tTraining Accuracy: 98.82%\n","Validation Accuracy: 98.37%\n","Epoch: 24 \tTraining Accuracy: 98.84%\n","Validation Accuracy: 98.33%\n","Epoch: 25 \tTraining Accuracy: 98.91%\n","Validation Accuracy: 98.37%\n","Epoch: 26 \tTraining Accuracy: 99.02%\n","Validation Accuracy: 98.59%\n","Epoch: 27 \tTraining Accuracy: 99.05%\n","Validation Accuracy: 98.63%\n","Epoch: 28 \tTraining Accuracy: 99.07%\n","Validation Accuracy: 98.50%\n","Epoch: 29 \tTraining Accuracy: 99.10%\n","Validation Accuracy: 98.59%\n","Epoch: 30 \tTraining Accuracy: 99.17%\n","Validation Accuracy: 98.59%\n","Epoch: 31 \tTraining Accuracy: 99.14%\n","Validation Accuracy: 98.66%\n","Epoch: 32 \tTraining Accuracy: 99.20%\n","Validation Accuracy: 98.69%\n","Epoch: 33 \tTraining Accuracy: 99.09%\n","Validation Accuracy: 98.66%\n","Epoch: 34 \tTraining Accuracy: 99.27%\n","Validation Accuracy: 98.86%\n","Epoch: 35 \tTraining Accuracy: 99.28%\n","Validation Accuracy: 98.73%\n","Epoch: 36 \tTraining Accuracy: 99.36%\n","Validation Accuracy: 98.95%\n","Epoch: 37 \tTraining Accuracy: 99.38%\n","Validation Accuracy: 98.99%\n","Epoch: 38 \tTraining Accuracy: 99.46%\n","Validation Accuracy: 98.92%\n","Epoch: 39 \tTraining Accuracy: 99.35%\n","Validation Accuracy: 98.82%\n","Final Training Accuracy: 0.9935\n","Final Test Accuracy: 0.9932\n"]}],"source":["# Train and evaluate\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.0317, Accuracy: 3023.0/3059 (99%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.99      0.99      0.99       544\n","     Class 1       1.00      0.99      0.99       670\n","     Class 2       0.97      0.99      0.98       631\n","     Class 3       0.99      0.98      0.98       613\n","     Class 4       1.00      1.00      1.00       601\n","\n","    accuracy                           0.99      3059\n","   macro avg       0.99      0.99      0.99      3059\n","weighted avg       0.99      0.99      0.99      3059\n","\n"]},{"data":{"text/plain":["0.9882314481856816"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.val_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574},"execution":{"iopub.execute_input":"2023-11-12T15:29:07.305269Z","iopub.status.busy":"2023-11-12T15:29:07.304953Z","iopub.status.idle":"2023-11-12T15:29:09.267085Z","shell.execute_reply":"2023-11-12T15:29:09.266127Z","shell.execute_reply.started":"2023-11-12T15:29:07.305238Z"},"id":"k75KSEM8pj8l","outputId":"be5d50f8-3458-4168-e181-8b94dea876ea","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["conv0.weight: 39.9300\n","conv1.weight: 383.6501\n","conv2.weight: 378.8453\n","fc_1.weight: 103.9267\n","fc_2.weight: 9.8704\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1500x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Effective Rank of Pretrained model\n","plot_layer_effective_ranks(pretrained_model)  # Note: You'll need to define or load 'model' before calling this function\n"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["learning_rates = [0.0001]   # later change when we have lr per layer\n","results = []"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2400, Test Accuracy: 0.2707\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.6000, Test Accuracy: 0.3329\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3273\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.2263\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.3600, Test Accuracy: 0.2331\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3308\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2800, Test Accuracy: 0.2611\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.5600, Test Accuracy: 0.3499\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3407\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3347\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.2400, Test Accuracy: 0.2100\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2462, Test Accuracy: 0.2244\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.5231, Test Accuracy: 0.4631\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.3462, Test Accuracy: 0.3329\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.3923, Test Accuracy: 0.3512\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3839\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.4615, Test Accuracy: 0.3837\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.3077, Test Accuracy: 0.2833\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.5038, Test Accuracy: 0.4801\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.3269, Test Accuracy: 0.3150\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.3731, Test Accuracy: 0.3553\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.2038, Test Accuracy: 0.2144\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.2038, Test Accuracy: 0.1878\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2553, Test Accuracy: 0.2695\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.3758, Test Accuracy: 0.3767\n","\n","Sampled Percentage: 0.1, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.1, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.1, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.1, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2851, Test Accuracy: 0.3001\n","\n","Sampled Percentage: 0.1, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.3716, Test Accuracy: 0.3765\n","\n","Sampled Percentage: 0.3, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.3, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.3, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.3628, Test Accuracy: 0.3436\n","\n","Sampled Percentage: 0.3, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2001, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.3, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.3719, Test Accuracy: 0.3779\n","\n","Sampled Percentage: 0.5, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9137, Test Accuracy: 0.9144\n","\n","Sampled Percentage: 0.5, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9307, Test Accuracy: 0.9282\n","\n","Sampled Percentage: 0.5, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9177, Test Accuracy: 0.9194\n","\n","Sampled Percentage: 0.8, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9335, Test Accuracy: 0.9311\n","\n","Sampled Percentage: 0.8, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9481, Test Accuracy: 0.9430\n","\n","Sampled Percentage: 0.8, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9286, Test Accuracy: 0.9278\n","\n","Sampled Percentage: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9397, Test Accuracy: 0.9389\n","\n","Sampled Percentage: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9520, Test Accuracy: 0.9484\n","\n","Sampled Percentage: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9356, Test Accuracy: 0.9350\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2400, Test Accuracy: 0.2707\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.6000, Test Accuracy: 0.3329\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3273\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.2263\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.3600, Test Accuracy: 0.2331\n","\n","Sampled Percentage: 0.001, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3308\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2800, Test Accuracy: 0.2611\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.5600, Test Accuracy: 0.3499\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3407\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3347\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.002, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.2400, Test Accuracy: 0.2100\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.2462, Test Accuracy: 0.2244\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.5231, Test Accuracy: 0.4631\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.3462, Test Accuracy: 0.3329\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.3923, Test Accuracy: 0.3512\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.4000, Test Accuracy: 0.3839\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.005, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.4615, Test Accuracy: 0.3837\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.3077, Test Accuracy: 0.2833\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.5038, Test Accuracy: 0.4801\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 5\n","Early stopping invoked.\n","Training Accuracy: 0.3269, Test Accuracy: 0.3150\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 6\n","Early stopping invoked.\n","Training Accuracy: 0.3731, Test Accuracy: 0.3553\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 7\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2115\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 8\n","Early stopping invoked.\n","Training Accuracy: 0.2038, Test Accuracy: 0.2144\n","\n","Sampled Percentage: 0.01, Lr: 0.0001, Repeat: 9\n","Early stopping invoked.\n","Training Accuracy: 0.2038, Test Accuracy: 0.1878\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.2076\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.2000, Test Accuracy: 0.1971\n","\n","Sampled Percentage: 0.05, Lr: 0.0001, Repeat: 3\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSampled Percentage: \u001b[39m\u001b[39m{\u001b[39;00msampled_percentage\u001b[39m}\u001b[39;00m\u001b[39m, Lr: \u001b[39m\u001b[39m{\u001b[39;00mlr\u001b[39m}\u001b[39;00m\u001b[39m, Repeat: \u001b[39m\u001b[39m{\u001b[39;00mrepeat\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Reduce the dataset\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m train_loader_reduced \u001b[39m=\u001b[39m reduce_dataset(dataloader_wrapped\u001b[39m.\u001b[39;49mtrain_loader, sampled_percentage, seed \u001b[39m=\u001b[39;49m \u001b[39m42\u001b[39;49m)\n\u001b[1;32m     25\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(repeat)\n\u001b[1;32m     26\u001b[0m \u001b[39m#train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\u001b[39;00m\n","Cell \u001b[0;32mIn[1], line 346\u001b[0m, in \u001b[0;36mreduce_dataset\u001b[0;34m(dataloader, percentage, balanced, seed)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m# Extract all data and labels from the dataset\u001b[39;00m\n\u001b[1;32m    345\u001b[0m X \u001b[39m=\u001b[39m [dataset[i][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset))]\n\u001b[0;32m--> 346\u001b[0m y \u001b[39m=\u001b[39m [dataset[i][\u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(dataset))]\n\u001b[1;32m    348\u001b[0m \u001b[39m# Set the seed for reproducibility\u001b[39;00m\n\u001b[1;32m    349\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(seed)\n","Cell \u001b[0;32mIn[1], line 346\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m# Extract all data and labels from the dataset\u001b[39;00m\n\u001b[1;32m    345\u001b[0m X \u001b[39m=\u001b[39m [dataset[i][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset))]\n\u001b[0;32m--> 346\u001b[0m y \u001b[39m=\u001b[39m [dataset[i][\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset))]\n\u001b[1;32m    348\u001b[0m \u001b[39m# Set the seed for reproducibility\u001b[39;00m\n\u001b[1;32m    349\u001b[0m torch\u001b[39m.\u001b[39mmanual_seed(seed)\n","Cell \u001b[0;32mIn[1], line 387\u001b[0m, in \u001b[0;36mRelabeledSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m--> 387\u001b[0m     data, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx]\n\u001b[1;32m    388\u001b[0m     \u001b[39m# Offset the label to start from 0\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     label \u001b[39m=\u001b[39m label \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset\n","File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n","File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n","File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n","File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#training of baseline, end to end, models (#trials x #percentages)\n","\n","dataloader_wrapped.update_phase('finetune')\n","\n","# template_model = generate_cnn(input_dim = 28, output_dim = 10, depth = params['depth'], num_channels = params['width'],\n","#                      hidden_dim_lin = params['hidden_dim_lin'], kernel_size = params['kernel_size'], activation_function = params[\"activation_function\"], use_pooling=params['use_pooling'])\n","\n","for lr in learning_rates:\n","    params[\"lr\"] = lr\n","    for sampled_percentage in percentages:      \n","        for sampled_percentage in percentages:\n","            if sampled_percentage <= 0.01:\n","                repeats = 10\n","            elif sampled_percentage < 0.5:\n","                repeats = 5\n","            else:\n","                repeats = 3\n","            \n","            for repeat in range(repeats):\n","                # Print or log the sampled values for transparency\n","                print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {lr}, Repeat: {repeat}\")\n","\n","                # Reduce the dataset\n","                train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = 42)\n","                torch.manual_seed(repeat)\n","                #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","                dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","                # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","                #model_temp = copy.deepcopy(template_model)\n","                model_temp = generate_cnn(input_dim = 28, output_dim = 10, depth = params['depth'], num_channels = params['width'],\n","                hidden_dim_lin = params['hidden_dim_lin'], kernel_size = params['kernel_size'], activation_function = params[\"activation_function\"], use_pooling=params['use_pooling'])\n","                model_temp.to(device)\n","\n","                # Train and evaluate\n","                trainer = Trainer(model_temp, dataset_namespace_new, params)\n","                train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","                print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","                # Store the results\n","                results.append({\"lr\":lr, \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.24, 'test_acc': 0.2707261880271549}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.6, 'test_acc': 0.332853322361654}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.4, 'test_acc': 0.3272989096893643}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.4, 'test_acc': 0.22629088664883767}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.36, 'test_acc': 0.2330796132483028}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.4, 'test_acc': 0.3307961324830282}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.28, 'test_acc': 0.26105739559761365}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.56, 'test_acc': 0.3499279983542481}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.4, 'test_acc': 0.340670643900432}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.4, 'test_acc': 0.3347047932524172}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.24, 'test_acc': 0.21003908660769388}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.24615384615384617, 'test_acc': 0.22443941575807447}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.5230769230769231, 'test_acc': 0.46307344167866693}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.34615384615384615, 'test_acc': 0.332853322361654}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.3923076923076923, 'test_acc': 0.3511623122814236}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.4, 'test_acc': 0.38387163135157376}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.46153846153846156, 'test_acc': 0.38366591236371117}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.3076923076923077, 'test_acc': 0.28327504628677225}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.5038461538461538, 'test_acc': 0.48014811767126103}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.3269230769230769, 'test_acc': 0.3149557704176095}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.3730769230769231, 'test_acc': 0.3552766920386752}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.20384615384615384, 'test_acc': 0.21435918535280807}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.20384615384615384, 'test_acc': 0.18782143591853528}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.2553030303030303, 'test_acc': 0.26949187409997943}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.37575757575757573, 'test_acc': 0.37667146677638347}, {'lr': 0.0001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.28506616257088846, 'test_acc': 0.3001440032915038}, {'lr': 0.0001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.3716446124763705, 'test_acc': 0.3764657477885209}, {'lr': 0.0001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.362822936357908, 'test_acc': 0.3435507097305081}, {'lr': 0.0001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.20012602394454945, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.3718966603654694, 'test_acc': 0.37790578070355896}, {'lr': 0.0001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9136810279667422, 'test_acc': 0.9144209010491668}, {'lr': 0.0001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9306878306878307, 'test_acc': 0.9282040732359597}, {'lr': 0.0001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.917687074829932, 'test_acc': 0.9193581567578688}, {'lr': 0.0001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9334907888521493, 'test_acc': 0.9310841390660358}, {'lr': 0.0001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9480869154463863, 'test_acc': 0.9430158403620654}, {'lr': 0.0001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9285781766650921, 'test_acc': 0.9277926352602345}, {'lr': 0.0001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9396651048467625, 'test_acc': 0.9389014606048138}, {'lr': 0.0001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9519932406482833, 'test_acc': 0.9483645340464925}, {'lr': 0.0001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9355941316537368, 'test_acc': 0.9349927998354248}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.24, 'test_acc': 0.2707261880271549}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.6, 'test_acc': 0.332853322361654}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.4, 'test_acc': 0.3272989096893643}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.4, 'test_acc': 0.22629088664883767}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.36, 'test_acc': 0.2330796132483028}, {'lr': 0.0001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.4, 'test_acc': 0.3307961324830282}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.28, 'test_acc': 0.26105739559761365}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.56, 'test_acc': 0.3499279983542481}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.4, 'test_acc': 0.340670643900432}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.4, 'test_acc': 0.3347047932524172}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.24, 'test_acc': 0.21003908660769388}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.24615384615384617, 'test_acc': 0.22443941575807447}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.5230769230769231, 'test_acc': 0.46307344167866693}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.34615384615384615, 'test_acc': 0.332853322361654}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.3923076923076923, 'test_acc': 0.3511623122814236}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.4, 'test_acc': 0.38387163135157376}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.46153846153846156, 'test_acc': 0.38366591236371117}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.3076923076923077, 'test_acc': 0.28327504628677225}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.5038461538461538, 'test_acc': 0.48014811767126103}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.3269230769230769, 'test_acc': 0.3149557704176095}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.3730769230769231, 'test_acc': 0.3552766920386752}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.2, 'test_acc': 0.21147911952273196}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.20384615384615384, 'test_acc': 0.21435918535280807}, {'lr': 0.0001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.20384615384615384, 'test_acc': 0.18782143591853528}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.2, 'test_acc': 0.20757045875334293}, {'lr': 0.0001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.2, 'test_acc': 0.19707879037235138}]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.7322\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.6676\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.7219\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7062\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.7215\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.7319\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.7171\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.7194\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.7136\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.7165\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.7307\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.6667\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.7184\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7075\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.7182\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.7311\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.7157\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.7178\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.7114\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.7155\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.7328\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.6686\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.7223\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7079\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.7173\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.7359\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.7182\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.7200\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.7147\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.7153\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.7346\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 1.0000, Test Accuracy: 0.6680\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.7252\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7101\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.7173\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.7359\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.7221\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.7247\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.7182\n","\n","Sampled Percentage: 0.001, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.7155\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.8089\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 1.0000, Test Accuracy: 0.7918\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.8050\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7955\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.8060\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.8089\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.8103\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.8146\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.8054\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.8068\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.8093\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 1.0000, Test Accuracy: 0.7908\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.8035\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7941\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.8033\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.8085\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.8091\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.8136\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.8048\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.8058\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.8054\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 1.0000, Test Accuracy: 0.7910\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.8019\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7941\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.8019\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.8070\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.8072\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.8097\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.8023\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.8031\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.8013\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 1.0000, Test Accuracy: 0.7865\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 1.0000, Test Accuracy: 0.7978\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 1.0000, Test Accuracy: 0.7891\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.7978\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 1.0000, Test Accuracy: 0.8011\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 1.0000, Test Accuracy: 0.8017\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 1.0000, Test Accuracy: 0.8054\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 1.0000, Test Accuracy: 0.7988\n","\n","Sampled Percentage: 0.002, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 1.0000, Test Accuracy: 0.8000\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9692, Test Accuracy: 0.8904\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9615, Test Accuracy: 0.8877\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9615, Test Accuracy: 0.8906\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9615, Test Accuracy: 0.8936\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9692, Test Accuracy: 0.8916\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9538, Test Accuracy: 0.8860\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9615, Test Accuracy: 0.8914\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9692, Test Accuracy: 0.8992\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9692, Test Accuracy: 0.8957\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9692, Test Accuracy: 0.8971\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9692, Test Accuracy: 0.8899\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9615, Test Accuracy: 0.8858\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9615, Test Accuracy: 0.8908\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9615, Test Accuracy: 0.8916\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9615, Test Accuracy: 0.8891\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9538, Test Accuracy: 0.8854\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9615, Test Accuracy: 0.8904\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9692, Test Accuracy: 0.8988\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9692, Test Accuracy: 0.8955\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9615, Test Accuracy: 0.8963\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9538, Test Accuracy: 0.8897\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9615, Test Accuracy: 0.8832\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9538, Test Accuracy: 0.8904\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9615, Test Accuracy: 0.8918\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9615, Test Accuracy: 0.8887\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9538, Test Accuracy: 0.8846\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9538, Test Accuracy: 0.8877\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9692, Test Accuracy: 0.8994\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9538, Test Accuracy: 0.8961\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9615, Test Accuracy: 0.8955\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9538, Test Accuracy: 0.8864\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9538, Test Accuracy: 0.8823\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9462, Test Accuracy: 0.8887\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9538, Test Accuracy: 0.8899\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9615, Test Accuracy: 0.8881\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9538, Test Accuracy: 0.8854\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9462, Test Accuracy: 0.8860\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9615, Test Accuracy: 0.8990\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9538, Test Accuracy: 0.8936\n","\n","Sampled Percentage: 0.005, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9538, Test Accuracy: 0.8949\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9615, Test Accuracy: 0.9060\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9615, Test Accuracy: 0.9060\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9615, Test Accuracy: 0.9072\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9500, Test Accuracy: 0.9095\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9654, Test Accuracy: 0.9099\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9615, Test Accuracy: 0.9045\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9538, Test Accuracy: 0.9078\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9692, Test Accuracy: 0.9171\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9692, Test Accuracy: 0.9103\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9692, Test Accuracy: 0.9128\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9615, Test Accuracy: 0.9062\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9538, Test Accuracy: 0.9052\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9577, Test Accuracy: 0.9060\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9500, Test Accuracy: 0.9080\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9654, Test Accuracy: 0.9087\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9615, Test Accuracy: 0.9045\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9500, Test Accuracy: 0.9074\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9692, Test Accuracy: 0.9167\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9692, Test Accuracy: 0.9101\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9654, Test Accuracy: 0.9126\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9615, Test Accuracy: 0.9043\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9538, Test Accuracy: 0.9039\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9577, Test Accuracy: 0.9060\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9462, Test Accuracy: 0.9054\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9615, Test Accuracy: 0.9089\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9577, Test Accuracy: 0.9041\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9462, Test Accuracy: 0.9054\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9615, Test Accuracy: 0.9140\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9577, Test Accuracy: 0.9093\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9615, Test Accuracy: 0.9117\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9500, Test Accuracy: 0.9039\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9500, Test Accuracy: 0.9054\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9462, Test Accuracy: 0.9050\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9423, Test Accuracy: 0.9076\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9577, Test Accuracy: 0.9076\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 5\n","Training Accuracy: 0.9500, Test Accuracy: 0.9035\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 6\n","Training Accuracy: 0.9462, Test Accuracy: 0.9060\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 7\n","Training Accuracy: 0.9615, Test Accuracy: 0.9140\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 8\n","Training Accuracy: 0.9500, Test Accuracy: 0.9103\n","\n","Sampled Percentage: 0.01, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 9\n","Training Accuracy: 0.9577, Test Accuracy: 0.9105\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9303, Test Accuracy: 0.9150\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9258, Test Accuracy: 0.9169\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9273, Test Accuracy: 0.9148\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9303, Test Accuracy: 0.9185\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9318, Test Accuracy: 0.9187\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9273, Test Accuracy: 0.9150\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9265, Test Accuracy: 0.9161\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9273, Test Accuracy: 0.9142\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9273, Test Accuracy: 0.9161\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9311, Test Accuracy: 0.9165\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9258, Test Accuracy: 0.9126\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9258, Test Accuracy: 0.9144\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9235, Test Accuracy: 0.9113\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9227, Test Accuracy: 0.9144\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9288, Test Accuracy: 0.9157\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9250, Test Accuracy: 0.9115\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9220, Test Accuracy: 0.9134\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9197, Test Accuracy: 0.9097\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9189, Test Accuracy: 0.9124\n","\n","Sampled Percentage: 0.05, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9258, Test Accuracy: 0.9134\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9263, Test Accuracy: 0.9200\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9248, Test Accuracy: 0.9237\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9233, Test Accuracy: 0.9202\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9244, Test Accuracy: 0.9224\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9267, Test Accuracy: 0.9224\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9251, Test Accuracy: 0.9187\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9240, Test Accuracy: 0.9218\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9225, Test Accuracy: 0.9185\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9236, Test Accuracy: 0.9214\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9251, Test Accuracy: 0.9194\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9202, Test Accuracy: 0.9179\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9217, Test Accuracy: 0.9214\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9202, Test Accuracy: 0.9189\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9206, Test Accuracy: 0.9208\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9225, Test Accuracy: 0.9187\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9187, Test Accuracy: 0.9175\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9202, Test Accuracy: 0.9206\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9183, Test Accuracy: 0.9163\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9202, Test Accuracy: 0.9169\n","\n","Sampled Percentage: 0.1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9198, Test Accuracy: 0.9179\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9564, Test Accuracy: 0.9504\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9568, Test Accuracy: 0.9502\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9568, Test Accuracy: 0.9490\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9572, Test Accuracy: 0.9517\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9573, Test Accuracy: 0.9502\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9540, Test Accuracy: 0.9477\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9544, Test Accuracy: 0.9492\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9558, Test Accuracy: 0.9473\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9553, Test Accuracy: 0.9506\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9558, Test Accuracy: 0.9494\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9507, Test Accuracy: 0.9436\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9522, Test Accuracy: 0.9461\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9501, Test Accuracy: 0.9436\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9534, Test Accuracy: 0.9463\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9510, Test Accuracy: 0.9447\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9473, Test Accuracy: 0.9401\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9477, Test Accuracy: 0.9422\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9452, Test Accuracy: 0.9389\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 3\n","Training Accuracy: 0.9482, Test Accuracy: 0.9418\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 4\n","Training Accuracy: 0.9464, Test Accuracy: 0.9410\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9710, Test Accuracy: 0.9724\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9713, Test Accuracy: 0.9737\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9707, Test Accuracy: 0.9726\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9692, Test Accuracy: 0.9702\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9704, Test Accuracy: 0.9706\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9689, Test Accuracy: 0.9698\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9655, Test Accuracy: 0.9663\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9669, Test Accuracy: 0.9663\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9646, Test Accuracy: 0.9661\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9619, Test Accuracy: 0.9595\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9630, Test Accuracy: 0.9611\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9622, Test Accuracy: 0.9613\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9766, Test Accuracy: 0.9782\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9778, Test Accuracy: 0.9782\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9770, Test Accuracy: 0.9792\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9739, Test Accuracy: 0.9743\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.9706, Test Accuracy: 0.9673\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.9729, Test Accuracy: 0.9739\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.9686, Test Accuracy: 0.9698\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.9724, Test Accuracy: 0.9696\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.9703, Test Accuracy: 0.9700\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9691, Test Accuracy: 0.9689\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9722, Test Accuracy: 0.9700\n","\n","Sampled Percentage: 0.8, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9698, Test Accuracy: 0.9700\n","\n","Sampled Percentage: 1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9798, Test Accuracy: 0.9794\n","\n","Sampled Percentage: 1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9805, Test Accuracy: 0.9790\n","\n","Sampled Percentage: 1, Sampled Cut Point: 0, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9809, Test Accuracy: 0.9813\n","\n","Sampled Percentage: 1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9788, Test Accuracy: 0.9774\n","\n","Sampled Percentage: 1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9792, Test Accuracy: 0.9778\n","\n","Sampled Percentage: 1, Sampled Cut Point: 1, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9795, Test Accuracy: 0.9788\n","\n","Sampled Percentage: 1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 0\n","Training Accuracy: 0.9765, Test Accuracy: 0.9765\n","\n","Sampled Percentage: 1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9768, Test Accuracy: 0.9782\n","\n","Sampled Percentage: 1, Sampled Cut Point: 2, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9766, Test Accuracy: 0.9772\n","\n","Sampled Percentage: 1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.9703, Test Accuracy: 0.9689\n","\n","Sampled Percentage: 1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 1\n","Training Accuracy: 0.9742, Test Accuracy: 0.9731\n","\n","Sampled Percentage: 1, Sampled Cut Point: 3, Lr: 0.0001, Repeat: 2\n","Training Accuracy: 0.9731, Test Accuracy: 0.9747\n"]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","# Store results\n","#results = []\n","# Store unique combinations that have been tested: we need this if we want to test random combinations\n","# tested_combinations = set()\n","\n","# for lr in learning_rates:\n","#     params[\"lr\"] = lr\n","# repeating the whole thing with multiple lr and saving the results somewhere\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 10\n","    elif sampled_percentage < 0.5:\n","        repeats = 5\n","    else:\n","        repeats = 3\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {lr}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=42)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, freeze=params[\"freeze\"], reinitialize=params[\"reinit\"])\n","\n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":lr, \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#save results\n","with open('results_lr_10_min_4.json', 'w') as f:\n","    json.dump(results, f)\n","\n","#load results\n","with open('results.json', 'r') as f:\n","    results = json.load(f)"]},{"cell_type":"markdown","metadata":{},"source":["## Visualizations"]},{"cell_type":"markdown","metadata":{},"source":["### Print the results and save somewhere for future analysis"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T17:54:32.880142Z","iopub.status.busy":"2023-11-12T17:54:32.879807Z","iopub.status.idle":"2023-11-12T17:54:32.886060Z","shell.execute_reply":"2023-11-12T17:54:32.885037Z","shell.execute_reply.started":"2023-11-12T17:54:32.880110Z"},"id":"750Ub3vCFV9s","outputId":"d8eb5c60-83c5-4c83-cfa4-dd17c1cc9e4a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7395597613659741}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7377082904752109}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7683604196667353}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 1.0, 'test_acc': 0.768977576630323}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.7603373791400946}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 1.0, 'test_acc': 0.7080847562229994}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.7669203867516972}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 1.0, 'test_acc': 0.7307138448878832}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 1.0, 'test_acc': 0.7903723513680313}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 1.0, 'test_acc': 0.714667763834602}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7833779057807035}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7628060069944456}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7953096070767331}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 1.0, 'test_acc': 0.8082699033120757}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.8323390248919975}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 1.0, 'test_acc': 0.7549886854556676}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.8020983336761983}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 1.0, 'test_acc': 0.7936638551738325}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.98, 'test_acc': 0.8251388603168073}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.9, 'test_acc': 0.6928615511211684}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9615384615384616, 'test_acc': 0.8701913186587122}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.8763628882945896}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.8615384615384616, 'test_acc': 0.8471507920181033}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9615384615384616, 'test_acc': 0.8813001440032915}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.8823287389426044}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.9923076923076923, 'test_acc': 0.8808887060275663}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.8718370705616129}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.9923076923076923, 'test_acc': 0.8763628882945896}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.8846153846153846, 'test_acc': 0.8701913186587122}, {'lr': 0.001, 'sampled_percentage': 0.005, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.9769230769230769, 'test_acc': 0.8755400123431393}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9615384615384616, 'test_acc': 0.9063978605225262}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9961538461538462, 'test_acc': 0.900637728862374}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9538461538461539, 'test_acc': 0.9066035795103888}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9807692307692307, 'test_acc': 0.8977576630322979}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.9923076923076923, 'test_acc': 0.8998148529109237}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 0.9807692307692307, 'test_acc': 0.9096893643283275}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 0.3769230769230769, 'test_acc': 0.3497222793663855}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 0.9730769230769231, 'test_acc': 0.9074264554618391}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 0.9692307692307692, 'test_acc': 0.8987862579716108}, {'lr': 0.001, 'sampled_percentage': 0.01, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 0.9692307692307692, 'test_acc': 0.8998148529109237}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9272727272727272, 'test_acc': 0.9150380580127546}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9477272727272728, 'test_acc': 0.9300555441267229}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.928030303030303, 'test_acc': 0.9193581567578688}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9363636363636364, 'test_acc': 0.9255297263937461}, {'lr': 0.001, 'sampled_percentage': 0.05, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.943939393939394, 'test_acc': 0.9249125694301584}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9255198487712666, 'test_acc': 0.9197695947335939}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9417769376181474, 'test_acc': 0.9331413289446616}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.924007561436673, 'test_acc': 0.9193581567578688}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9285444234404537, 'test_acc': 0.9191524377700062}, {'lr': 0.001, 'sampled_percentage': 0.1, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.9402646502835539, 'test_acc': 0.9288212301995474}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9624448645242596, 'test_acc': 0.9547418226702324}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9648393194706995, 'test_acc': 0.9582390454638963}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9603024574669187, 'test_acc': 0.9555646986216828}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 0.9638311279143037, 'test_acc': 0.9576218885003086}, {'lr': 0.001, 'sampled_percentage': 0.3, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 0.9608065532451165, 'test_acc': 0.9545361036823699}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.981103552532124, 'test_acc': 0.9790166632380168}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9820861678004535, 'test_acc': 0.9831310429952684}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9781557067271353, 'test_acc': 0.9786052252622917}, {'lr': 0.001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9826169107227208, 'test_acc': 0.9812795721045052}, {'lr': 0.001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.9888993859234766, 'test_acc': 0.9864225468010698}, {'lr': 0.001, 'sampled_percentage': 0.8, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.987954652810581, 'test_acc': 0.9860111088253446}, {'lr': 0.001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 0.9877486750134419, 'test_acc': 0.9849825138860316}, {'lr': 0.001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 0.991666026576542, 'test_acc': 0.9884797366796956}, {'lr': 0.001, 'sampled_percentage': 1, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 0.9905138643521008, 'test_acc': 0.9876568607282452}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7395597613659741}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7377082904752109}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7683604196667353}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 3, 'train_acc': 1.0, 'test_acc': 0.768977576630323}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 4, 'train_acc': 1.0, 'test_acc': 0.7603373791400946}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 5, 'train_acc': 1.0, 'test_acc': 0.7080847562229994}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 6, 'train_acc': 1.0, 'test_acc': 0.7669203867516972}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 7, 'train_acc': 1.0, 'test_acc': 0.7307138448878832}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 8, 'train_acc': 1.0, 'test_acc': 0.7903723513680313}, {'lr': 0.001, 'sampled_percentage': 0.001, 'sampled_cut_point': -1, 'repeat': 9, 'train_acc': 1.0, 'test_acc': 0.714667763834602}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 0, 'train_acc': 1.0, 'test_acc': 0.7833779057807035}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 1, 'train_acc': 1.0, 'test_acc': 0.7628060069944456}, {'lr': 0.001, 'sampled_percentage': 0.002, 'sampled_cut_point': -1, 'repeat': 2, 'train_acc': 1.0, 'test_acc': 0.7953096070767331}]\n"]}],"source":["print(results)"]},{"cell_type":"markdown","metadata":{"id":"gcNE-dVg7uK-"},"source":["### The Results Table and 3D plot (both go into the report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["{\"lr\":lr, \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["{'lr': 0.001,\n"," 'sampled_percentage': 0.002,\n"," 'sampled_cut_point': -1,\n"," 'repeat': 0,\n"," 'train_acc': 1.0,\n"," 'test_acc': 0.7833779057807035}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["results[10]"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2023-11-12T18:30:01.609498Z","iopub.status.busy":"2023-11-12T18:30:01.608625Z","iopub.status.idle":"2023-11-12T18:30:01.659272Z","shell.execute_reply":"2023-11-12T18:30:01.658364Z","shell.execute_reply.started":"2023-11-12T18:30:01.609455Z"},"id":"qhGdMh3o7x2y","outputId":"a978e1ba-9bb5-4ac9-f8e9-7002898c9214","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["i:  10 repeat:  0\n","i:  10 repeat:  0\n","i:  10 repeat:  0\n","i:  10 repeat:  0\n","i:  20 repeat:  0\n","i:  20 repeat:  0\n","i:  20 repeat:  0\n","i:  20 repeat:  0\n","i:  30 repeat:  0\n","i:  30 repeat:  0\n","i:  30 repeat:  0\n","i:  30 repeat:  0\n","i:  40 repeat:  0\n","i:  40 repeat:  0\n","i:  40 repeat:  0\n","i:  40 repeat:  0\n","i:  45 repeat:  5\n","i:  45 repeat:  0\n","i:  45 repeat:  0\n","i:  45 repeat:  0\n","i:  45 repeat:  0\n","i:  50 repeat:  5\n","i:  50 repeat:  0\n","i:  50 repeat:  0\n","i:  50 repeat:  0\n","i:  50 repeat:  0\n","i:  55 repeat:  5\n","i:  55 repeat:  0\n","i:  55 repeat:  0\n","i:  55 repeat:  0\n","i:  55 repeat:  0\n","i:  58 repeat:  3\n","i:  58 repeat:  0\n","i:  58 repeat:  0\n","i:  58 repeat:  0\n","i:  58 repeat:  0\n","i:  61 repeat:  3\n","i:  61 repeat:  0\n","i:  61 repeat:  0\n","i:  61 repeat:  0\n","i:  61 repeat:  0\n","i:  64 repeat:  3\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n","i:  64 repeat:  0\n"]},{"name":"stderr","output_type":"stream","text":["/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n","  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n","  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n","/Users/davidguzman/miniforge3/envs/pytorch/lib/python3.11/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Percentage</th>\n","      <th>Cut Point</th>\n","      <th>Learning Rate</th>\n","      <th>Mean Train Accuracy</th>\n","      <th>Std Train Accuracy</th>\n","      <th>Mean Test Accuracy</th>\n","      <th>Std Test Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.001</td>\n","      <td>-1</td>\n","      <td>0.0010</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.74857</td>\n","      <td>0.025174</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.001</td>\n","      <td>0</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.001</td>\n","      <td>1</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.001</td>\n","      <td>2</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.001</td>\n","      <td>3</td>\n","      <td>0.0010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>1.000</td>\n","      <td>-1</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>1.000</td>\n","      <td>0</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>1.000</td>\n","      <td>1</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>1.000</td>\n","      <td>2</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>1.000</td>\n","      <td>3</td>\n","      <td>0.0001</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows  7 columns</p>\n","</div>"],"text/plain":["    Percentage  Cut Point  Learning Rate  Mean Train Accuracy   \n","0        0.001         -1         0.0010                  1.0  \\\n","1        0.001          0         0.0010                  NaN   \n","2        0.001          1         0.0010                  NaN   \n","3        0.001          2         0.0010                  NaN   \n","4        0.001          3         0.0010                  NaN   \n","..         ...        ...            ...                  ...   \n","95       1.000         -1         0.0001                  NaN   \n","96       1.000          0         0.0001                  NaN   \n","97       1.000          1         0.0001                  NaN   \n","98       1.000          2         0.0001                  NaN   \n","99       1.000          3         0.0001                  NaN   \n","\n","    Std Train Accuracy  Mean Test Accuracy  Std Test Accuracy  \n","0                  0.0             0.74857           0.025174  \n","1                  NaN                 NaN                NaN  \n","2                  NaN                 NaN                NaN  \n","3                  NaN                 NaN                NaN  \n","4                  NaN                 NaN                NaN  \n","..                 ...                 ...                ...  \n","95                 NaN                 NaN                NaN  \n","96                 NaN                 NaN                NaN  \n","97                 NaN                 NaN                NaN  \n","98                 NaN                 NaN                NaN  \n","99                 NaN                 NaN                NaN  \n","\n","[100 rows x 7 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# first of all convert results to df and calculate the mean and std of repats\n","repeats_mean = []\n","i = 0\n","for lr in learning_rates:\n","    for sampled_percentage in percentages:\n","        for sampled_cut_point in [-1]+cuts:\n","            \n","            train, test = [], []\n","            for repeat in range(repeats):\n","                if results[i][\"repeat\"] != repeat or results[i][\"sampled_percentage\"] != sampled_percentage or results[i][\"sampled_cut_point\"] != sampled_cut_point or results[i][\"lr\"] != lr:\n","                    print(\"i: \", i, \"repeat: \", repeat)\n","                    break\n","                train.append(results[i][\"train_acc\"])\n","                test.append(results[i][\"test_acc\"])\n","                i += 1\n","            repeats_mean.append((sampled_percentage, sampled_cut_point, lr, np.mean(train), np.std(train), np.mean(test), np.std(test)))\n","df = pd.DataFrame(repeats_mean, columns=['Percentage', 'Cut Point', 'Learning Rate', 'Mean Train Accuracy', 'Std Train Accuracy', 'Mean Test Accuracy', 'Std Test Accuracy'])\n","df"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":4}

{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Architecture Search"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyperparameters\n","num_epochs = 10\n","batch_size = 64\n","learning_rate = 0.001\n","\n","# CIFAR-10 dataset (images and labels)\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d429b6e7a6d43bd9d54598b51b363e2","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Epoch [1/10], Step [100/782], Loss: 1.8975\n","Epoch [1/10], Step [200/782], Loss: 1.1866\n","Epoch [1/10], Step [300/782], Loss: 1.5947\n","Epoch [1/10], Step [400/782], Loss: 1.1908\n","Epoch [1/10], Step [500/782], Loss: 1.2909\n","Epoch [1/10], Step [600/782], Loss: 1.4519\n","Epoch [1/10], Step [700/782], Loss: 1.2809\n","Epoch [2/10], Step [100/782], Loss: 1.3379\n","Epoch [2/10], Step [200/782], Loss: 0.9116\n","Epoch [2/10], Step [300/782], Loss: 0.7973\n","Epoch [2/10], Step [400/782], Loss: 1.0004\n","Epoch [2/10], Step [500/782], Loss: 0.9603\n","Epoch [2/10], Step [600/782], Loss: 0.8637\n","Epoch [2/10], Step [700/782], Loss: 0.7086\n","Epoch [3/10], Step [100/782], Loss: 1.0356\n","Epoch [3/10], Step [200/782], Loss: 0.8289\n","Epoch [3/10], Step [300/782], Loss: 0.8743\n","Epoch [3/10], Step [400/782], Loss: 0.8731\n","Epoch [3/10], Step [500/782], Loss: 0.8518\n","Epoch [3/10], Step [600/782], Loss: 0.7563\n","Epoch [3/10], Step [700/782], Loss: 0.5964\n","Epoch [4/10], Step [100/782], Loss: 0.7970\n","Epoch [4/10], Step [200/782], Loss: 0.5507\n","Epoch [4/10], Step [300/782], Loss: 0.7267\n","Epoch [4/10], Step [400/782], Loss: 0.5258\n","Epoch [4/10], Step [500/782], Loss: 0.7763\n","Epoch [4/10], Step [600/782], Loss: 0.6715\n","Epoch [4/10], Step [700/782], Loss: 0.5392\n","Epoch [5/10], Step [100/782], Loss: 0.5625\n","Epoch [5/10], Step [200/782], Loss: 0.7407\n","Epoch [5/10], Step [300/782], Loss: 0.4589\n","Epoch [5/10], Step [400/782], Loss: 0.4866\n","Epoch [5/10], Step [500/782], Loss: 0.6701\n","Epoch [5/10], Step [600/782], Loss: 0.3245\n","Epoch [5/10], Step [700/782], Loss: 0.5035\n","Epoch [6/10], Step [100/782], Loss: 0.3549\n","Epoch [6/10], Step [200/782], Loss: 0.4950\n","Epoch [6/10], Step [300/782], Loss: 0.5575\n","Epoch [6/10], Step [400/782], Loss: 0.5744\n","Epoch [6/10], Step [500/782], Loss: 0.6047\n","Epoch [6/10], Step [600/782], Loss: 0.4485\n","Epoch [6/10], Step [700/782], Loss: 0.6036\n","Epoch [7/10], Step [100/782], Loss: 0.2456\n","Epoch [7/10], Step [200/782], Loss: 0.4242\n","Epoch [7/10], Step [300/782], Loss: 0.6449\n","Epoch [7/10], Step [400/782], Loss: 0.3632\n","Epoch [7/10], Step [500/782], Loss: 0.3833\n","Epoch [7/10], Step [600/782], Loss: 0.5235\n","Epoch [7/10], Step [700/782], Loss: 0.5207\n","Epoch [8/10], Step [100/782], Loss: 0.2203\n","Epoch [8/10], Step [200/782], Loss: 0.1420\n","Epoch [8/10], Step [300/782], Loss: 0.3056\n","Epoch [8/10], Step [400/782], Loss: 0.3272\n","Epoch [8/10], Step [500/782], Loss: 0.3383\n","Epoch [8/10], Step [600/782], Loss: 0.4063\n","Epoch [8/10], Step [700/782], Loss: 0.4723\n","Epoch [9/10], Step [100/782], Loss: 0.2841\n","Epoch [9/10], Step [200/782], Loss: 0.2894\n","Epoch [9/10], Step [300/782], Loss: 0.3901\n","Epoch [9/10], Step [400/782], Loss: 0.2805\n","Epoch [9/10], Step [500/782], Loss: 0.4347\n","Epoch [9/10], Step [600/782], Loss: 0.2706\n","Epoch [9/10], Step [700/782], Loss: 0.3393\n","Epoch [10/10], Step [100/782], Loss: 0.1052\n","Epoch [10/10], Step [200/782], Loss: 0.3434\n","Epoch [10/10], Step [300/782], Loss: 0.2630\n","Epoch [10/10], Step [400/782], Loss: 0.2408\n","Epoch [10/10], Step [500/782], Loss: 0.2738\n","Epoch [10/10], Step [600/782], Loss: 0.2533\n","Epoch [10/10], Step [700/782], Loss: 0.2724\n","Accuracy of the network on the 10000 test images: 77.08 %\n"]}],"source":["# CNN model (Deep but Narrow)\n","class DeepButNarrowCNN(nn.Module):\n","    def __init__(self):\n","        super(DeepButNarrowCNN, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.layer2 = nn.Conv2d(32, 32, 3, padding=1)\n","        self.layer3 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.layer4 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.layer5 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.layer6 = nn.Conv2d(128, 128, 3, padding=1)\n","        self.fc = nn.Linear(128 * 4 * 4, 10)\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = F.max_pool2d(out, 2)\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = F.max_pool2d(out, 2)\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = F.max_pool2d(out, 2)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model = DeepButNarrowCNN().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n","# Save the model checkpoint\n","torch.save(model.state_dict(), 'model.ckpt')\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 1.9773\n","Epoch [1/10], Step [200/782], Loss: 1.7463\n","Epoch [1/10], Step [300/782], Loss: 1.8459\n","Epoch [1/10], Step [400/782], Loss: 1.5274\n","Epoch [1/10], Step [500/782], Loss: 1.5453\n","Epoch [1/10], Step [600/782], Loss: 1.5219\n","Epoch [1/10], Step [700/782], Loss: 1.3501\n","Epoch [2/10], Step [100/782], Loss: 1.1609\n","Epoch [2/10], Step [200/782], Loss: 1.2708\n","Epoch [2/10], Step [300/782], Loss: 1.4547\n","Epoch [2/10], Step [400/782], Loss: 1.0678\n","Epoch [2/10], Step [500/782], Loss: 1.1947\n","Epoch [2/10], Step [600/782], Loss: 1.2415\n","Epoch [2/10], Step [700/782], Loss: 1.1550\n","Epoch [3/10], Step [100/782], Loss: 0.9440\n","Epoch [3/10], Step [200/782], Loss: 1.1037\n","Epoch [3/10], Step [300/782], Loss: 1.0770\n","Epoch [3/10], Step [400/782], Loss: 1.1476\n","Epoch [3/10], Step [500/782], Loss: 1.1093\n","Epoch [3/10], Step [600/782], Loss: 0.9168\n","Epoch [3/10], Step [700/782], Loss: 0.8647\n","Epoch [4/10], Step [100/782], Loss: 0.7568\n","Epoch [4/10], Step [200/782], Loss: 0.7014\n","Epoch [4/10], Step [300/782], Loss: 0.6771\n","Epoch [4/10], Step [400/782], Loss: 0.8738\n","Epoch [4/10], Step [500/782], Loss: 0.9832\n","Epoch [4/10], Step [600/782], Loss: 0.9485\n","Epoch [4/10], Step [700/782], Loss: 0.9037\n","Epoch [5/10], Step [100/782], Loss: 0.6728\n","Epoch [5/10], Step [200/782], Loss: 0.6200\n","Epoch [5/10], Step [300/782], Loss: 0.7682\n","Epoch [5/10], Step [400/782], Loss: 0.7001\n","Epoch [5/10], Step [500/782], Loss: 0.5981\n","Epoch [5/10], Step [600/782], Loss: 0.6794\n","Epoch [5/10], Step [700/782], Loss: 0.7517\n","Epoch [6/10], Step [100/782], Loss: 0.4256\n","Epoch [6/10], Step [200/782], Loss: 0.6595\n","Epoch [6/10], Step [300/782], Loss: 0.4099\n","Epoch [6/10], Step [400/782], Loss: 0.8292\n","Epoch [6/10], Step [500/782], Loss: 0.5797\n","Epoch [6/10], Step [600/782], Loss: 0.4866\n","Epoch [6/10], Step [700/782], Loss: 0.7239\n","Epoch [7/10], Step [100/782], Loss: 0.3088\n","Epoch [7/10], Step [200/782], Loss: 0.4798\n","Epoch [7/10], Step [300/782], Loss: 0.4268\n","Epoch [7/10], Step [400/782], Loss: 0.3805\n","Epoch [7/10], Step [500/782], Loss: 0.4144\n","Epoch [7/10], Step [600/782], Loss: 0.3183\n","Epoch [7/10], Step [700/782], Loss: 0.3151\n","Epoch [8/10], Step [100/782], Loss: 0.2907\n","Epoch [8/10], Step [200/782], Loss: 0.1069\n","Epoch [8/10], Step [300/782], Loss: 0.1659\n","Epoch [8/10], Step [400/782], Loss: 0.3495\n","Epoch [8/10], Step [500/782], Loss: 0.3269\n","Epoch [8/10], Step [600/782], Loss: 0.3006\n","Epoch [8/10], Step [700/782], Loss: 0.2152\n","Epoch [9/10], Step [100/782], Loss: 0.3250\n","Epoch [9/10], Step [200/782], Loss: 0.1813\n","Epoch [9/10], Step [300/782], Loss: 0.1609\n","Epoch [9/10], Step [400/782], Loss: 0.1676\n","Epoch [9/10], Step [500/782], Loss: 0.2945\n","Epoch [9/10], Step [600/782], Loss: 0.3133\n","Epoch [9/10], Step [700/782], Loss: 0.1620\n","Epoch [10/10], Step [100/782], Loss: 0.0380\n","Epoch [10/10], Step [200/782], Loss: 0.0712\n","Epoch [10/10], Step [300/782], Loss: 0.0634\n","Epoch [10/10], Step [400/782], Loss: 0.1931\n","Epoch [10/10], Step [500/782], Loss: 0.1139\n","Epoch [10/10], Step [600/782], Loss: 0.1078\n","Epoch [10/10], Step [700/782], Loss: 0.1197\n","Accuracy of the network on the 10000 test images: 65.13 %\n"]}],"source":["class DeepCNNNoPoolingNoStriding(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNNoPoolingNoStriding, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","        self.layer3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.layer5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","        # Keeping the spatial dimension same throughout, so 32x32 input results in 32x32 output after conv layers\n","        self.fc = nn.Linear(128 * 32 * 32, 10)  # Large number of input features to the FC layer\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = out.view(out.size(0), -1)  # Flatten the output for the fully connected layer\n","        out = self.fc(out)\n","        return out\n","\n","model_no_pooling_no_striding = DeepCNNNoPoolingNoStriding().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_no_pooling_no_striding.parameters(), lr=learning_rate)\n","\n","# Train the model_no_pooling_no_striding\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_no_pooling_no_striding(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_no_pooling_no_striding\n","model_no_pooling_no_striding.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_no_pooling_no_striding(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 2.0367\n","Epoch [1/10], Step [200/782], Loss: 1.6069\n","Epoch [1/10], Step [300/782], Loss: 1.4365\n","Epoch [1/10], Step [400/782], Loss: 1.6237\n","Epoch [1/10], Step [500/782], Loss: 1.1624\n","Epoch [1/10], Step [600/782], Loss: 1.4353\n","Epoch [1/10], Step [700/782], Loss: 1.2655\n","Epoch [2/10], Step [100/782], Loss: 1.2112\n","Epoch [2/10], Step [200/782], Loss: 0.9067\n","Epoch [2/10], Step [300/782], Loss: 1.0452\n","Epoch [2/10], Step [400/782], Loss: 1.0410\n","Epoch [2/10], Step [500/782], Loss: 1.0729\n","Epoch [2/10], Step [600/782], Loss: 0.9605\n","Epoch [2/10], Step [700/782], Loss: 1.0249\n","Epoch [3/10], Step [100/782], Loss: 0.9521\n","Epoch [3/10], Step [200/782], Loss: 0.6517\n","Epoch [3/10], Step [300/782], Loss: 0.9917\n","Epoch [3/10], Step [400/782], Loss: 0.8162\n","Epoch [3/10], Step [500/782], Loss: 0.9734\n","Epoch [3/10], Step [600/782], Loss: 0.7849\n","Epoch [3/10], Step [700/782], Loss: 0.7072\n","Epoch [4/10], Step [100/782], Loss: 0.9017\n","Epoch [4/10], Step [200/782], Loss: 0.6867\n","Epoch [4/10], Step [300/782], Loss: 0.7483\n","Epoch [4/10], Step [400/782], Loss: 0.7454\n","Epoch [4/10], Step [500/782], Loss: 0.7394\n","Epoch [4/10], Step [600/782], Loss: 0.9175\n","Epoch [4/10], Step [700/782], Loss: 0.5986\n","Epoch [5/10], Step [100/782], Loss: 0.3952\n","Epoch [5/10], Step [200/782], Loss: 0.4902\n","Epoch [5/10], Step [300/782], Loss: 0.3068\n","Epoch [5/10], Step [400/782], Loss: 0.6012\n","Epoch [5/10], Step [500/782], Loss: 0.5243\n","Epoch [5/10], Step [600/782], Loss: 0.2964\n","Epoch [5/10], Step [700/782], Loss: 0.5442\n","Epoch [6/10], Step [100/782], Loss: 0.2081\n","Epoch [6/10], Step [200/782], Loss: 0.4744\n","Epoch [6/10], Step [300/782], Loss: 0.2634\n","Epoch [6/10], Step [400/782], Loss: 0.3251\n","Epoch [6/10], Step [500/782], Loss: 0.3825\n","Epoch [6/10], Step [600/782], Loss: 0.2036\n","Epoch [6/10], Step [700/782], Loss: 0.3983\n","Epoch [7/10], Step [100/782], Loss: 0.1330\n","Epoch [7/10], Step [200/782], Loss: 0.1858\n","Epoch [7/10], Step [300/782], Loss: 0.1252\n","Epoch [7/10], Step [400/782], Loss: 0.2864\n","Epoch [7/10], Step [500/782], Loss: 0.4974\n","Epoch [7/10], Step [600/782], Loss: 0.1724\n","Epoch [7/10], Step [700/782], Loss: 0.3095\n","Epoch [8/10], Step [100/782], Loss: 0.0608\n","Epoch [8/10], Step [200/782], Loss: 0.1783\n","Epoch [8/10], Step [300/782], Loss: 0.1748\n","Epoch [8/10], Step [400/782], Loss: 0.2356\n","Epoch [8/10], Step [500/782], Loss: 0.2500\n","Epoch [8/10], Step [600/782], Loss: 0.1716\n","Epoch [8/10], Step [700/782], Loss: 0.2325\n","Epoch [9/10], Step [100/782], Loss: 0.0293\n","Epoch [9/10], Step [200/782], Loss: 0.0573\n","Epoch [9/10], Step [300/782], Loss: 0.2919\n","Epoch [9/10], Step [400/782], Loss: 0.1470\n","Epoch [9/10], Step [500/782], Loss: 0.1174\n","Epoch [9/10], Step [600/782], Loss: 0.1176\n","Epoch [9/10], Step [700/782], Loss: 0.2339\n","Epoch [10/10], Step [100/782], Loss: 0.0147\n","Epoch [10/10], Step [200/782], Loss: 0.2225\n","Epoch [10/10], Step [300/782], Loss: 0.1783\n","Epoch [10/10], Step [400/782], Loss: 0.0471\n","Epoch [10/10], Step [500/782], Loss: 0.2047\n","Epoch [10/10], Step [600/782], Loss: 0.1681\n","Epoch [10/10], Step [700/782], Loss: 0.1110\n","Accuracy of the network on the 10000 test images: 63.29 %\n"]}],"source":["class DeepCNNNoPoolingNoStriding(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNNoPoolingNoStriding, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.layer3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.layer5 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        # Keeping the spatial dimension same throughout, so 32x32 input results in 32x32 output after conv layers\n","        self.fc = nn.Linear(64 * 32 * 32, 10)  # Large number of input features to the FC layer\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = out.view(out.size(0), -1)  # Flatten the output for the fully connected layer\n","        out = self.fc(out)\n","        return out\n","\n","model_no_pooling_no_striding = DeepCNNNoPoolingNoStriding().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_no_pooling_no_striding.parameters(), lr=learning_rate)\n","\n","# Train the model_no_pooling_no_striding\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_no_pooling_no_striding(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_no_pooling_no_striding\n","model_no_pooling_no_striding.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_no_pooling_no_striding(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Epoch [1/10], Step [100/782], Loss: 1.8552\n","Epoch [1/10], Step [200/782], Loss: 1.6673\n","Epoch [1/10], Step [300/782], Loss: 1.6695\n","Epoch [1/10], Step [400/782], Loss: 1.5474\n","Epoch [1/10], Step [500/782], Loss: 1.5634\n","Epoch [1/10], Step [600/782], Loss: 1.3211\n","Epoch [1/10], Step [700/782], Loss: 1.3915\n","Epoch [2/10], Step [100/782], Loss: 1.0290\n","Epoch [2/10], Step [200/782], Loss: 1.3137\n","Epoch [2/10], Step [300/782], Loss: 1.1727\n","Epoch [2/10], Step [400/782], Loss: 1.1137\n","Epoch [2/10], Step [500/782], Loss: 0.9542\n","Epoch [2/10], Step [600/782], Loss: 1.1167\n","Epoch [2/10], Step [700/782], Loss: 0.9335\n","Epoch [3/10], Step [100/782], Loss: 0.8416\n","Epoch [3/10], Step [200/782], Loss: 0.9012\n","Epoch [3/10], Step [300/782], Loss: 0.9940\n","Epoch [3/10], Step [400/782], Loss: 1.1360\n","Epoch [3/10], Step [500/782], Loss: 0.8969\n","Epoch [3/10], Step [600/782], Loss: 0.6574\n","Epoch [3/10], Step [700/782], Loss: 1.0711\n","Epoch [4/10], Step [100/782], Loss: 0.7665\n","Epoch [4/10], Step [200/782], Loss: 0.7378\n","Epoch [4/10], Step [300/782], Loss: 0.6775\n","Epoch [4/10], Step [400/782], Loss: 0.5846\n","Epoch [4/10], Step [500/782], Loss: 0.7512\n","Epoch [4/10], Step [600/782], Loss: 0.8147\n","Epoch [4/10], Step [700/782], Loss: 0.9046\n","Epoch [5/10], Step [100/782], Loss: 0.6880\n","Epoch [5/10], Step [200/782], Loss: 0.8577\n","Epoch [5/10], Step [300/782], Loss: 0.6510\n","Epoch [5/10], Step [400/782], Loss: 1.0149\n","Epoch [5/10], Step [500/782], Loss: 0.8643\n","Epoch [5/10], Step [600/782], Loss: 0.6030\n","Epoch [5/10], Step [700/782], Loss: 0.6522\n","Epoch [6/10], Step [100/782], Loss: 0.7157\n","Epoch [6/10], Step [200/782], Loss: 0.7456\n","Epoch [6/10], Step [300/782], Loss: 0.9751\n","Epoch [6/10], Step [400/782], Loss: 0.6500\n","Epoch [6/10], Step [500/782], Loss: 0.9516\n","Epoch [6/10], Step [600/782], Loss: 0.5382\n","Epoch [6/10], Step [700/782], Loss: 0.4088\n","Epoch [7/10], Step [100/782], Loss: 0.4057\n","Epoch [7/10], Step [200/782], Loss: 0.3734\n","Epoch [7/10], Step [300/782], Loss: 0.4265\n","Epoch [7/10], Step [400/782], Loss: 0.5600\n","Epoch [7/10], Step [500/782], Loss: 0.5469\n","Epoch [7/10], Step [600/782], Loss: 0.6427\n","Epoch [7/10], Step [700/782], Loss: 0.6977\n","Epoch [8/10], Step [100/782], Loss: 0.3077\n","Epoch [8/10], Step [200/782], Loss: 0.3024\n","Epoch [8/10], Step [300/782], Loss: 0.4967\n","Epoch [8/10], Step [400/782], Loss: 0.5492\n","Epoch [8/10], Step [500/782], Loss: 0.4738\n","Epoch [8/10], Step [600/782], Loss: 0.3751\n","Epoch [8/10], Step [700/782], Loss: 0.4538\n","Epoch [9/10], Step [100/782], Loss: 0.2466\n","Epoch [9/10], Step [200/782], Loss: 0.4761\n","Epoch [9/10], Step [300/782], Loss: 0.3063\n","Epoch [9/10], Step [400/782], Loss: 0.4731\n","Epoch [9/10], Step [500/782], Loss: 0.3674\n","Epoch [9/10], Step [600/782], Loss: 0.2062\n","Epoch [9/10], Step [700/782], Loss: 0.4161\n","Epoch [10/10], Step [100/782], Loss: 0.1994\n","Epoch [10/10], Step [200/782], Loss: 0.2863\n","Epoch [10/10], Step [300/782], Loss: 0.2513\n","Epoch [10/10], Step [400/782], Loss: 0.1926\n","Epoch [10/10], Step [500/782], Loss: 0.3684\n","Epoch [10/10], Step [600/782], Loss: 0.4092\n","Epoch [10/10], Step [700/782], Loss: 0.3942\n","Accuracy of the network on the 10000 test images: 72.25 %\n"]}],"source":["class DeepButNarrowCNNNoPooling(nn.Module):\n","    def __init__(self):\n","        super(DeepButNarrowCNNNoPooling, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n","        self.layer2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)  # Strided convolution for downsampling\n","        self.layer3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.layer4 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)  # Strided convolution for downsampling\n","        self.layer5 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.layer6 = nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1)  # Strided convolution for downsampling\n","        self.fc = nn.Linear(128 * 4 * 4, 10)  # Adjusted for the downsampling\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model_no_pooling = DeepButNarrowCNNNoPooling().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_no_pooling.parameters(), lr=learning_rate)\n","\n","# Train the model_no_pooling\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_no_pooling(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_no_pooling\n","model_no_pooling.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_no_pooling(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 1.8212\n","Epoch [1/10], Step [200/782], Loss: 1.5978\n","Epoch [1/10], Step [300/782], Loss: 1.6023\n","Epoch [1/10], Step [400/782], Loss: 1.3932\n","Epoch [1/10], Step [500/782], Loss: 1.4105\n","Epoch [1/10], Step [600/782], Loss: 1.4241\n","Epoch [1/10], Step [700/782], Loss: 1.3741\n","Epoch [2/10], Step [100/782], Loss: 1.1217\n","Epoch [2/10], Step [200/782], Loss: 1.1096\n","Epoch [2/10], Step [300/782], Loss: 1.0970\n","Epoch [2/10], Step [400/782], Loss: 1.1788\n","Epoch [2/10], Step [500/782], Loss: 1.0956\n","Epoch [2/10], Step [600/782], Loss: 0.9277\n","Epoch [2/10], Step [700/782], Loss: 1.0410\n","Epoch [3/10], Step [100/782], Loss: 1.0196\n","Epoch [3/10], Step [200/782], Loss: 1.1829\n","Epoch [3/10], Step [300/782], Loss: 1.0102\n","Epoch [3/10], Step [400/782], Loss: 1.0232\n","Epoch [3/10], Step [500/782], Loss: 0.8163\n","Epoch [3/10], Step [600/782], Loss: 0.9078\n","Epoch [3/10], Step [700/782], Loss: 0.7252\n","Epoch [4/10], Step [100/782], Loss: 0.7129\n","Epoch [4/10], Step [200/782], Loss: 0.7875\n","Epoch [4/10], Step [300/782], Loss: 0.8188\n","Epoch [4/10], Step [400/782], Loss: 0.9854\n","Epoch [4/10], Step [500/782], Loss: 0.8585\n","Epoch [4/10], Step [600/782], Loss: 0.8220\n","Epoch [4/10], Step [700/782], Loss: 0.7367\n","Epoch [5/10], Step [100/782], Loss: 0.4597\n","Epoch [5/10], Step [200/782], Loss: 0.7902\n","Epoch [5/10], Step [300/782], Loss: 0.5878\n","Epoch [5/10], Step [400/782], Loss: 0.7139\n","Epoch [5/10], Step [500/782], Loss: 0.4123\n","Epoch [5/10], Step [600/782], Loss: 0.4062\n","Epoch [5/10], Step [700/782], Loss: 0.7669\n","Epoch [6/10], Step [100/782], Loss: 0.5204\n","Epoch [6/10], Step [200/782], Loss: 0.5028\n","Epoch [6/10], Step [300/782], Loss: 0.6717\n","Epoch [6/10], Step [400/782], Loss: 0.4982\n","Epoch [6/10], Step [500/782], Loss: 0.6322\n","Epoch [6/10], Step [600/782], Loss: 0.4896\n","Epoch [6/10], Step [700/782], Loss: 0.5200\n","Epoch [7/10], Step [100/782], Loss: 0.6957\n","Epoch [7/10], Step [200/782], Loss: 0.6545\n","Epoch [7/10], Step [300/782], Loss: 0.4161\n","Epoch [7/10], Step [400/782], Loss: 0.3884\n","Epoch [7/10], Step [500/782], Loss: 0.6727\n","Epoch [7/10], Step [600/782], Loss: 0.6419\n","Epoch [7/10], Step [700/782], Loss: 0.3610\n","Epoch [8/10], Step [100/782], Loss: 0.3517\n","Epoch [8/10], Step [200/782], Loss: 0.4286\n","Epoch [8/10], Step [300/782], Loss: 0.4180\n","Epoch [8/10], Step [400/782], Loss: 0.3073\n","Epoch [8/10], Step [500/782], Loss: 0.4370\n","Epoch [8/10], Step [600/782], Loss: 0.3148\n","Epoch [8/10], Step [700/782], Loss: 0.4266\n","Epoch [9/10], Step [100/782], Loss: 0.3016\n","Epoch [9/10], Step [200/782], Loss: 0.3489\n","Epoch [9/10], Step [300/782], Loss: 0.3338\n","Epoch [9/10], Step [400/782], Loss: 0.4739\n","Epoch [9/10], Step [500/782], Loss: 0.4232\n","Epoch [9/10], Step [600/782], Loss: 0.4409\n","Epoch [9/10], Step [700/782], Loss: 0.4635\n","Epoch [10/10], Step [100/782], Loss: 0.3107\n","Epoch [10/10], Step [200/782], Loss: 0.3565\n","Epoch [10/10], Step [300/782], Loss: 0.3112\n","Epoch [10/10], Step [400/782], Loss: 0.4557\n","Epoch [10/10], Step [500/782], Loss: 0.2711\n","Epoch [10/10], Step [600/782], Loss: 0.4861\n","Epoch [10/10], Step [700/782], Loss: 0.3281\n","Accuracy of the network on the 10000 test images: 79.14 %\n"]}],"source":["class DeepCNNWithAvgPooling(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNWithAvgPooling, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","        self.avgpool1 = nn.AvgPool2d(2, stride=2)\n","        self.layer3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.avgpool2 = nn.AvgPool2d(2, stride=2)\n","        self.layer5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","        self.avgpool3 = nn.AvgPool2d(2, stride=2)\n","        self.fc = nn.Linear(128 * 4 * 4, 10)\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = self.avgpool1(out)\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = self.avgpool2(out)\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = self.avgpool3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model_with_avg_pooling = DeepCNNWithAvgPooling().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_with_avg_pooling.parameters(), lr=learning_rate)\n","\n","# Train the model_with_avg_pooling\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_with_avg_pooling(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_with_avg_pooling\n","model_with_avg_pooling.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_with_avg_pooling(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 1.7938\n","Epoch [1/10], Step [200/782], Loss: 1.7104\n","Epoch [1/10], Step [300/782], Loss: 1.4952\n","Epoch [1/10], Step [400/782], Loss: 1.3783\n","Epoch [1/10], Step [500/782], Loss: 1.2984\n","Epoch [1/10], Step [600/782], Loss: 1.3925\n","Epoch [1/10], Step [700/782], Loss: 1.5976\n","Epoch [2/10], Step [100/782], Loss: 1.1288\n","Epoch [2/10], Step [200/782], Loss: 1.0793\n","Epoch [2/10], Step [300/782], Loss: 1.0554\n","Epoch [2/10], Step [400/782], Loss: 1.0934\n","Epoch [2/10], Step [500/782], Loss: 0.7481\n","Epoch [2/10], Step [600/782], Loss: 0.8244\n","Epoch [2/10], Step [700/782], Loss: 0.8229\n","Epoch [3/10], Step [100/782], Loss: 0.6758\n","Epoch [3/10], Step [200/782], Loss: 0.9416\n","Epoch [3/10], Step [300/782], Loss: 0.5464\n","Epoch [3/10], Step [400/782], Loss: 0.6421\n","Epoch [3/10], Step [500/782], Loss: 0.7798\n","Epoch [3/10], Step [600/782], Loss: 0.7156\n","Epoch [3/10], Step [700/782], Loss: 0.7198\n","Epoch [4/10], Step [100/782], Loss: 0.5683\n","Epoch [4/10], Step [200/782], Loss: 0.5603\n","Epoch [4/10], Step [300/782], Loss: 0.6880\n","Epoch [4/10], Step [400/782], Loss: 0.9283\n","Epoch [4/10], Step [500/782], Loss: 0.6627\n","Epoch [4/10], Step [600/782], Loss: 0.6969\n","Epoch [4/10], Step [700/782], Loss: 0.6717\n","Epoch [5/10], Step [100/782], Loss: 0.4796\n","Epoch [5/10], Step [200/782], Loss: 0.3855\n","Epoch [5/10], Step [300/782], Loss: 0.4431\n","Epoch [5/10], Step [400/782], Loss: 0.4767\n","Epoch [5/10], Step [500/782], Loss: 0.4764\n","Epoch [5/10], Step [600/782], Loss: 0.5688\n","Epoch [5/10], Step [700/782], Loss: 0.5120\n","Epoch [6/10], Step [100/782], Loss: 0.3842\n","Epoch [6/10], Step [200/782], Loss: 0.4726\n","Epoch [6/10], Step [300/782], Loss: 0.3526\n","Epoch [6/10], Step [400/782], Loss: 0.4104\n","Epoch [6/10], Step [500/782], Loss: 0.4886\n","Epoch [6/10], Step [600/782], Loss: 0.3424\n","Epoch [6/10], Step [700/782], Loss: 0.3129\n","Epoch [7/10], Step [100/782], Loss: 0.4038\n","Epoch [7/10], Step [200/782], Loss: 0.1894\n","Epoch [7/10], Step [300/782], Loss: 0.5020\n","Epoch [7/10], Step [400/782], Loss: 0.3879\n","Epoch [7/10], Step [500/782], Loss: 0.4616\n","Epoch [7/10], Step [600/782], Loss: 0.2535\n","Epoch [7/10], Step [700/782], Loss: 0.2992\n","Epoch [8/10], Step [100/782], Loss: 0.1918\n","Epoch [8/10], Step [200/782], Loss: 0.1556\n","Epoch [8/10], Step [300/782], Loss: 0.2697\n","Epoch [8/10], Step [400/782], Loss: 0.1886\n","Epoch [8/10], Step [500/782], Loss: 0.2306\n","Epoch [8/10], Step [600/782], Loss: 0.1655\n","Epoch [8/10], Step [700/782], Loss: 0.2616\n","Epoch [9/10], Step [100/782], Loss: 0.1187\n","Epoch [9/10], Step [200/782], Loss: 0.1024\n","Epoch [9/10], Step [300/782], Loss: 0.0796\n","Epoch [9/10], Step [400/782], Loss: 0.0667\n","Epoch [9/10], Step [500/782], Loss: 0.1111\n","Epoch [9/10], Step [600/782], Loss: 0.3198\n","Epoch [9/10], Step [700/782], Loss: 0.1081\n","Epoch [10/10], Step [100/782], Loss: 0.2456\n","Epoch [10/10], Step [200/782], Loss: 0.0825\n","Epoch [10/10], Step [300/782], Loss: 0.1336\n","Epoch [10/10], Step [400/782], Loss: 0.3270\n","Epoch [10/10], Step [500/782], Loss: 0.1498\n","Epoch [10/10], Step [600/782], Loss: 0.0785\n","Epoch [10/10], Step [700/782], Loss: 0.1090\n","Accuracy of the network on the 10000 test images: 79.16 %\n"]}],"source":["class DeepCNNWithAvgPoolingConstantChannels(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNWithAvgPoolingConstantChannels, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 256, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","        self.avgpool1 = nn.AvgPool2d(2, stride=2)\n","        self.layer3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","        self.avgpool2 = nn.AvgPool2d(2, stride=2)\n","        self.layer5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n","        self.avgpool3 = nn.AvgPool2d(2, stride=2)\n","        self.fc = nn.Linear(256 * 4 * 4, 10)\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = self.avgpool1(out)\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = self.avgpool2(out)\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = self.avgpool3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model_with_avg_pooling_constant_channels = DeepCNNWithAvgPoolingConstantChannels().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_with_avg_pooling_constant_channels.parameters(), lr=learning_rate)\n","\n","# Train the model_with_avg_pooling_constant_channels\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_with_avg_pooling_constant_channels\n","model_with_avg_pooling_constant_channels.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 1.8975\n","Epoch [1/10], Step [200/782], Loss: 1.7205\n","Epoch [1/10], Step [300/782], Loss: 1.6065\n","Epoch [1/10], Step [400/782], Loss: 1.3666\n","Epoch [1/10], Step [500/782], Loss: 1.3453\n","Epoch [1/10], Step [600/782], Loss: 1.4118\n","Epoch [1/10], Step [700/782], Loss: 1.2491\n","Epoch [2/10], Step [100/782], Loss: 1.0472\n","Epoch [2/10], Step [200/782], Loss: 1.1361\n","Epoch [2/10], Step [300/782], Loss: 1.0448\n","Epoch [2/10], Step [400/782], Loss: 1.0611\n","Epoch [2/10], Step [500/782], Loss: 0.7402\n","Epoch [2/10], Step [600/782], Loss: 0.7919\n","Epoch [2/10], Step [700/782], Loss: 0.9403\n","Epoch [3/10], Step [100/782], Loss: 0.7273\n","Epoch [3/10], Step [200/782], Loss: 0.7532\n","Epoch [3/10], Step [300/782], Loss: 0.6992\n","Epoch [3/10], Step [400/782], Loss: 0.7046\n","Epoch [3/10], Step [500/782], Loss: 0.6826\n","Epoch [3/10], Step [600/782], Loss: 0.6004\n","Epoch [3/10], Step [700/782], Loss: 0.7906\n","Epoch [4/10], Step [100/782], Loss: 0.6320\n","Epoch [4/10], Step [200/782], Loss: 0.8736\n","Epoch [4/10], Step [300/782], Loss: 0.7374\n","Epoch [4/10], Step [400/782], Loss: 0.5420\n","Epoch [4/10], Step [500/782], Loss: 0.7543\n","Epoch [4/10], Step [600/782], Loss: 0.8816\n","Epoch [4/10], Step [700/782], Loss: 0.8019\n","Epoch [5/10], Step [100/782], Loss: 0.5738\n","Epoch [5/10], Step [200/782], Loss: 0.7160\n","Epoch [5/10], Step [300/782], Loss: 0.6855\n","Epoch [5/10], Step [400/782], Loss: 0.4233\n","Epoch [5/10], Step [500/782], Loss: 0.6680\n","Epoch [5/10], Step [600/782], Loss: 0.5670\n","Epoch [5/10], Step [700/782], Loss: 0.6530\n","Epoch [6/10], Step [100/782], Loss: 0.4392\n","Epoch [6/10], Step [200/782], Loss: 0.4722\n","Epoch [6/10], Step [300/782], Loss: 0.4909\n","Epoch [6/10], Step [400/782], Loss: 0.6309\n","Epoch [6/10], Step [500/782], Loss: 0.4777\n","Epoch [6/10], Step [600/782], Loss: 0.4129\n","Epoch [6/10], Step [700/782], Loss: 0.4614\n","Epoch [7/10], Step [100/782], Loss: 0.3433\n","Epoch [7/10], Step [200/782], Loss: 0.3347\n","Epoch [7/10], Step [300/782], Loss: 0.2604\n","Epoch [7/10], Step [400/782], Loss: 0.3304\n","Epoch [7/10], Step [500/782], Loss: 0.3873\n","Epoch [7/10], Step [600/782], Loss: 0.5890\n","Epoch [7/10], Step [700/782], Loss: 0.3918\n","Epoch [8/10], Step [100/782], Loss: 0.2134\n","Epoch [8/10], Step [200/782], Loss: 0.3094\n","Epoch [8/10], Step [300/782], Loss: 0.2806\n","Epoch [8/10], Step [400/782], Loss: 0.4127\n","Epoch [8/10], Step [500/782], Loss: 0.3620\n","Epoch [8/10], Step [600/782], Loss: 0.3030\n","Epoch [8/10], Step [700/782], Loss: 0.5680\n","Epoch [9/10], Step [100/782], Loss: 0.2065\n","Epoch [9/10], Step [200/782], Loss: 0.3810\n","Epoch [9/10], Step [300/782], Loss: 0.2623\n","Epoch [9/10], Step [400/782], Loss: 0.3004\n","Epoch [9/10], Step [500/782], Loss: 0.1756\n","Epoch [9/10], Step [600/782], Loss: 0.1135\n","Epoch [9/10], Step [700/782], Loss: 0.3115\n","Epoch [10/10], Step [100/782], Loss: 0.3220\n","Epoch [10/10], Step [200/782], Loss: 0.1750\n","Epoch [10/10], Step [300/782], Loss: 0.2615\n","Epoch [10/10], Step [400/782], Loss: 0.1942\n","Epoch [10/10], Step [500/782], Loss: 0.2804\n","Epoch [10/10], Step [600/782], Loss: 0.2364\n","Epoch [10/10], Step [700/782], Loss: 0.3471\n","Accuracy of the network on the 10000 test images: 79.49 %\n"]}],"source":["class DeepCNNWithAvgPoolingConstantChannels(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNWithAvgPoolingConstantChannels, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","        self.avgpool1 = nn.AvgPool2d(2, stride=2)\n","        self.layer3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","        self.avgpool2 = nn.AvgPool2d(2, stride=2)\n","        self.layer5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","        self.avgpool3 = nn.AvgPool2d(2, stride=2)\n","        self.fc = nn.Linear(128 * 4 * 4, 10)\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = self.avgpool1(out)\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = self.avgpool2(out)\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = self.avgpool3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model_with_avg_pooling_constant_channels = DeepCNNWithAvgPoolingConstantChannels().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_with_avg_pooling_constant_channels.parameters(), lr=learning_rate)\n","\n","# Train the model_with_avg_pooling_constant_channels\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_with_avg_pooling_constant_channels\n","model_with_avg_pooling_constant_channels.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 1.5930\n","Epoch [1/10], Step [200/782], Loss: 1.5423\n","Epoch [1/10], Step [300/782], Loss: 1.4887\n","Epoch [1/10], Step [400/782], Loss: 1.3591\n","Epoch [1/10], Step [500/782], Loss: 1.2652\n","Epoch [1/10], Step [600/782], Loss: 1.3295\n","Epoch [1/10], Step [700/782], Loss: 1.1923\n","Epoch [2/10], Step [100/782], Loss: 1.2057\n","Epoch [2/10], Step [200/782], Loss: 1.2615\n","Epoch [2/10], Step [300/782], Loss: 1.1962\n","Epoch [2/10], Step [400/782], Loss: 0.9189\n","Epoch [2/10], Step [500/782], Loss: 1.0666\n","Epoch [2/10], Step [600/782], Loss: 0.9643\n","Epoch [2/10], Step [700/782], Loss: 1.1659\n","Epoch [3/10], Step [100/782], Loss: 0.9411\n","Epoch [3/10], Step [200/782], Loss: 0.8487\n","Epoch [3/10], Step [300/782], Loss: 1.0320\n","Epoch [3/10], Step [400/782], Loss: 0.8592\n","Epoch [3/10], Step [500/782], Loss: 0.8117\n","Epoch [3/10], Step [600/782], Loss: 0.8880\n","Epoch [3/10], Step [700/782], Loss: 0.9210\n","Epoch [4/10], Step [100/782], Loss: 0.6578\n","Epoch [4/10], Step [200/782], Loss: 1.0378\n","Epoch [4/10], Step [300/782], Loss: 0.7496\n","Epoch [4/10], Step [400/782], Loss: 0.4724\n","Epoch [4/10], Step [500/782], Loss: 0.9637\n","Epoch [4/10], Step [600/782], Loss: 0.9463\n","Epoch [4/10], Step [700/782], Loss: 0.8298\n","Epoch [5/10], Step [100/782], Loss: 0.7465\n","Epoch [5/10], Step [200/782], Loss: 0.7363\n","Epoch [5/10], Step [300/782], Loss: 0.6493\n","Epoch [5/10], Step [400/782], Loss: 0.6113\n","Epoch [5/10], Step [500/782], Loss: 0.6368\n","Epoch [5/10], Step [600/782], Loss: 0.7477\n","Epoch [5/10], Step [700/782], Loss: 0.6160\n","Epoch [6/10], Step [100/782], Loss: 0.8060\n","Epoch [6/10], Step [200/782], Loss: 0.5328\n","Epoch [6/10], Step [300/782], Loss: 0.6036\n","Epoch [6/10], Step [400/782], Loss: 0.7279\n","Epoch [6/10], Step [500/782], Loss: 0.8569\n","Epoch [6/10], Step [600/782], Loss: 0.6821\n","Epoch [6/10], Step [700/782], Loss: 0.6713\n","Epoch [7/10], Step [100/782], Loss: 0.7616\n","Epoch [7/10], Step [200/782], Loss: 0.5410\n","Epoch [7/10], Step [300/782], Loss: 0.5784\n","Epoch [7/10], Step [400/782], Loss: 0.4719\n","Epoch [7/10], Step [500/782], Loss: 0.6623\n","Epoch [7/10], Step [600/782], Loss: 0.4585\n","Epoch [7/10], Step [700/782], Loss: 0.5467\n","Epoch [8/10], Step [100/782], Loss: 0.5419\n","Epoch [8/10], Step [200/782], Loss: 0.5390\n","Epoch [8/10], Step [300/782], Loss: 0.4537\n","Epoch [8/10], Step [400/782], Loss: 0.5544\n","Epoch [8/10], Step [500/782], Loss: 0.5579\n","Epoch [8/10], Step [600/782], Loss: 0.2570\n","Epoch [8/10], Step [700/782], Loss: 0.4135\n","Epoch [9/10], Step [100/782], Loss: 0.6127\n","Epoch [9/10], Step [200/782], Loss: 0.4552\n","Epoch [9/10], Step [300/782], Loss: 0.4736\n","Epoch [9/10], Step [400/782], Loss: 0.5206\n","Epoch [9/10], Step [500/782], Loss: 0.5806\n","Epoch [9/10], Step [600/782], Loss: 0.4338\n","Epoch [9/10], Step [700/782], Loss: 0.3500\n","Epoch [10/10], Step [100/782], Loss: 0.5206\n","Epoch [10/10], Step [200/782], Loss: 0.3948\n","Epoch [10/10], Step [300/782], Loss: 0.3075\n","Epoch [10/10], Step [400/782], Loss: 0.3532\n","Epoch [10/10], Step [500/782], Loss: 0.4115\n","Epoch [10/10], Step [600/782], Loss: 0.2827\n","Epoch [10/10], Step [700/782], Loss: 0.3621\n","Accuracy of the network on the 10000 test images: 78.38 %\n"]}],"source":["class DeepCNNWithAvgPoolingConstantChannels(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNWithAvgPoolingConstantChannels, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.avgpool1 = nn.AvgPool2d(2, stride=2)\n","        self.layer3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.avgpool2 = nn.AvgPool2d(2, stride=2)\n","        self.layer5 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","        self.avgpool3 = nn.AvgPool2d(2, stride=2)\n","        self.fc = nn.Linear(64 * 4 * 4, 10)\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = self.avgpool1(out)\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = self.avgpool2(out)\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = self.avgpool3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model_with_avg_pooling_constant_channels = DeepCNNWithAvgPoolingConstantChannels().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_with_avg_pooling_constant_channels.parameters(), lr=learning_rate)\n","\n","# Train the model_with_avg_pooling_constant_channels\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_with_avg_pooling_constant_channels\n","model_with_avg_pooling_constant_channels.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 2.1611\n","Epoch [1/10], Step [200/782], Loss: 1.7804\n","Epoch [1/10], Step [300/782], Loss: 1.5337\n","Epoch [1/10], Step [400/782], Loss: 1.4270\n","Epoch [1/10], Step [500/782], Loss: 1.7451\n","Epoch [1/10], Step [600/782], Loss: 1.5150\n","Epoch [1/10], Step [700/782], Loss: 1.1501\n","Epoch [2/10], Step [100/782], Loss: 1.5442\n","Epoch [2/10], Step [200/782], Loss: 1.3839\n","Epoch [2/10], Step [300/782], Loss: 1.3410\n","Epoch [2/10], Step [400/782], Loss: 1.3856\n","Epoch [2/10], Step [500/782], Loss: 1.2276\n","Epoch [2/10], Step [600/782], Loss: 1.4093\n","Epoch [2/10], Step [700/782], Loss: 1.2505\n","Epoch [3/10], Step [100/782], Loss: 1.1723\n","Epoch [3/10], Step [200/782], Loss: 1.0134\n","Epoch [3/10], Step [300/782], Loss: 1.3111\n","Epoch [3/10], Step [400/782], Loss: 0.8358\n","Epoch [3/10], Step [500/782], Loss: 1.3744\n","Epoch [3/10], Step [600/782], Loss: 0.9760\n","Epoch [3/10], Step [700/782], Loss: 0.9385\n","Epoch [4/10], Step [100/782], Loss: 1.0020\n","Epoch [4/10], Step [200/782], Loss: 0.8384\n","Epoch [4/10], Step [300/782], Loss: 1.1434\n","Epoch [4/10], Step [400/782], Loss: 0.9036\n","Epoch [4/10], Step [500/782], Loss: 0.9193\n","Epoch [4/10], Step [600/782], Loss: 1.1434\n","Epoch [4/10], Step [700/782], Loss: 1.1675\n","Epoch [5/10], Step [100/782], Loss: 1.0291\n","Epoch [5/10], Step [200/782], Loss: 0.8527\n","Epoch [5/10], Step [300/782], Loss: 1.0410\n","Epoch [5/10], Step [400/782], Loss: 0.9541\n","Epoch [5/10], Step [500/782], Loss: 0.9452\n","Epoch [5/10], Step [600/782], Loss: 1.0644\n","Epoch [5/10], Step [700/782], Loss: 0.8275\n","Epoch [6/10], Step [100/782], Loss: 0.8495\n","Epoch [6/10], Step [200/782], Loss: 1.0549\n","Epoch [6/10], Step [300/782], Loss: 0.7717\n","Epoch [6/10], Step [400/782], Loss: 0.7781\n","Epoch [6/10], Step [500/782], Loss: 0.8349\n","Epoch [6/10], Step [600/782], Loss: 0.7022\n","Epoch [6/10], Step [700/782], Loss: 0.8217\n","Epoch [7/10], Step [100/782], Loss: 0.8034\n","Epoch [7/10], Step [200/782], Loss: 0.9558\n","Epoch [7/10], Step [300/782], Loss: 0.4686\n","Epoch [7/10], Step [400/782], Loss: 0.8200\n","Epoch [7/10], Step [500/782], Loss: 0.5730\n","Epoch [7/10], Step [600/782], Loss: 0.9220\n","Epoch [7/10], Step [700/782], Loss: 0.6884\n","Epoch [8/10], Step [100/782], Loss: 0.6510\n","Epoch [8/10], Step [200/782], Loss: 0.7949\n","Epoch [8/10], Step [300/782], Loss: 0.6325\n","Epoch [8/10], Step [400/782], Loss: 0.9204\n","Epoch [8/10], Step [500/782], Loss: 0.6611\n","Epoch [8/10], Step [600/782], Loss: 0.7119\n","Epoch [8/10], Step [700/782], Loss: 0.6833\n","Epoch [9/10], Step [100/782], Loss: 0.4211\n","Epoch [9/10], Step [200/782], Loss: 0.8050\n","Epoch [9/10], Step [300/782], Loss: 0.8577\n","Epoch [9/10], Step [400/782], Loss: 0.7276\n","Epoch [9/10], Step [500/782], Loss: 0.8021\n","Epoch [9/10], Step [600/782], Loss: 0.8368\n","Epoch [9/10], Step [700/782], Loss: 0.5350\n","Epoch [10/10], Step [100/782], Loss: 0.4306\n","Epoch [10/10], Step [200/782], Loss: 0.5681\n","Epoch [10/10], Step [300/782], Loss: 0.5450\n","Epoch [10/10], Step [400/782], Loss: 0.6611\n","Epoch [10/10], Step [500/782], Loss: 0.6180\n","Epoch [10/10], Step [600/782], Loss: 0.8373\n","Epoch [10/10], Step [700/782], Loss: 0.6898\n","Accuracy of the network on the 10000 test images: 73.71 %\n"]}],"source":["class DeepCNNWithAvgPoolingConstantChannels(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNWithAvgPoolingConstantChannels, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","        self.avgpool1 = nn.AvgPool2d(2, stride=2)\n","        self.layer3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","        self.avgpool2 = nn.AvgPool2d(2, stride=2)\n","        self.layer5 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","        self.avgpool3 = nn.AvgPool2d(2, stride=2)\n","        self.fc = nn.Linear(32 * 4 * 4, 10)\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = self.avgpool1(out)\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = self.avgpool2(out)\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = self.avgpool3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model_with_avg_pooling_constant_channels = DeepCNNWithAvgPoolingConstantChannels().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_with_avg_pooling_constant_channels.parameters(), lr=learning_rate)\n","\n","# Train the model_with_avg_pooling_constant_channels\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_with_avg_pooling_constant_channels\n","model_with_avg_pooling_constant_channels.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/782], Loss: 2.1601\n","Epoch [1/10], Step [200/782], Loss: 1.7929\n","Epoch [1/10], Step [300/782], Loss: 1.8409\n","Epoch [1/10], Step [400/782], Loss: 1.5978\n","Epoch [1/10], Step [500/782], Loss: 1.7161\n","Epoch [1/10], Step [600/782], Loss: 1.5679\n","Epoch [1/10], Step [700/782], Loss: 1.5398\n","Epoch [2/10], Step [100/782], Loss: 1.5118\n","Epoch [2/10], Step [200/782], Loss: 1.4132\n","Epoch [2/10], Step [300/782], Loss: 1.5023\n","Epoch [2/10], Step [400/782], Loss: 1.4884\n","Epoch [2/10], Step [500/782], Loss: 1.3626\n","Epoch [2/10], Step [600/782], Loss: 1.6282\n","Epoch [2/10], Step [700/782], Loss: 1.4192\n","Epoch [3/10], Step [100/782], Loss: 1.4644\n","Epoch [3/10], Step [200/782], Loss: 1.4361\n","Epoch [3/10], Step [300/782], Loss: 1.5522\n","Epoch [3/10], Step [400/782], Loss: 1.3692\n","Epoch [3/10], Step [500/782], Loss: 1.2385\n","Epoch [3/10], Step [600/782], Loss: 1.3618\n","Epoch [3/10], Step [700/782], Loss: 1.6945\n","Epoch [4/10], Step [100/782], Loss: 1.3187\n","Epoch [4/10], Step [200/782], Loss: 1.2664\n","Epoch [4/10], Step [300/782], Loss: 1.1774\n","Epoch [4/10], Step [400/782], Loss: 1.6808\n","Epoch [4/10], Step [500/782], Loss: 1.2801\n","Epoch [4/10], Step [600/782], Loss: 1.4243\n","Epoch [4/10], Step [700/782], Loss: 1.2941\n","Epoch [5/10], Step [100/782], Loss: 1.3676\n","Epoch [5/10], Step [200/782], Loss: 1.1911\n","Epoch [5/10], Step [300/782], Loss: 1.3005\n","Epoch [5/10], Step [400/782], Loss: 1.3747\n","Epoch [5/10], Step [500/782], Loss: 1.3645\n","Epoch [5/10], Step [600/782], Loss: 1.2897\n","Epoch [5/10], Step [700/782], Loss: 1.1065\n","Epoch [6/10], Step [100/782], Loss: 1.2238\n","Epoch [6/10], Step [200/782], Loss: 1.2217\n","Epoch [6/10], Step [300/782], Loss: 1.1648\n","Epoch [6/10], Step [400/782], Loss: 1.2043\n","Epoch [6/10], Step [500/782], Loss: 1.0576\n","Epoch [6/10], Step [600/782], Loss: 1.1140\n","Epoch [6/10], Step [700/782], Loss: 0.9799\n","Epoch [7/10], Step [100/782], Loss: 1.1134\n","Epoch [7/10], Step [200/782], Loss: 1.1400\n","Epoch [7/10], Step [300/782], Loss: 1.0659\n","Epoch [7/10], Step [400/782], Loss: 0.9402\n","Epoch [7/10], Step [500/782], Loss: 1.0390\n","Epoch [7/10], Step [600/782], Loss: 1.1925\n","Epoch [7/10], Step [700/782], Loss: 1.2459\n","Epoch [8/10], Step [100/782], Loss: 0.9708\n","Epoch [8/10], Step [200/782], Loss: 0.9726\n","Epoch [8/10], Step [300/782], Loss: 1.1207\n","Epoch [8/10], Step [400/782], Loss: 0.9667\n","Epoch [8/10], Step [500/782], Loss: 1.0047\n","Epoch [8/10], Step [600/782], Loss: 1.0191\n","Epoch [8/10], Step [700/782], Loss: 1.1941\n","Epoch [9/10], Step [100/782], Loss: 0.9936\n","Epoch [9/10], Step [200/782], Loss: 1.1897\n","Epoch [9/10], Step [300/782], Loss: 1.1180\n","Epoch [9/10], Step [400/782], Loss: 0.9127\n","Epoch [9/10], Step [500/782], Loss: 0.8822\n","Epoch [9/10], Step [600/782], Loss: 1.2101\n","Epoch [9/10], Step [700/782], Loss: 1.1205\n","Epoch [10/10], Step [100/782], Loss: 1.1138\n","Epoch [10/10], Step [200/782], Loss: 0.9152\n","Epoch [10/10], Step [300/782], Loss: 1.0236\n","Epoch [10/10], Step [400/782], Loss: 1.1366\n","Epoch [10/10], Step [500/782], Loss: 1.0253\n","Epoch [10/10], Step [600/782], Loss: 1.0872\n","Epoch [10/10], Step [700/782], Loss: 1.0344\n","Accuracy of the network on the 10000 test images: 64.27 %\n"]}],"source":["class DeepCNNWithAvgPoolingConstantChannels(nn.Module):\n","    def __init__(self):\n","        super(DeepCNNWithAvgPoolingConstantChannels, self).__init__()\n","        self.layer1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n","        self.layer2 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n","        self.avgpool1 = nn.AvgPool2d(2, stride=2)\n","        self.layer3 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n","        self.layer4 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n","        self.avgpool2 = nn.AvgPool2d(2, stride=2)\n","        self.layer5 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n","        self.layer6 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n","        self.avgpool3 = nn.AvgPool2d(2, stride=2)\n","        self.fc = nn.Linear(16 * 4 * 4, 10)\n","\n","    def forward(self, x):\n","        out = F.relu(self.layer1(x))\n","        out = F.relu(self.layer2(out))\n","        out = self.avgpool1(out)\n","        out = F.relu(self.layer3(out))\n","        out = F.relu(self.layer4(out))\n","        out = self.avgpool2(out)\n","        out = F.relu(self.layer5(out))\n","        out = F.relu(self.layer6(out))\n","        out = self.avgpool3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc(out)\n","        return out\n","\n","model_with_avg_pooling_constant_channels = DeepCNNWithAvgPoolingConstantChannels().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model_with_avg_pooling_constant_channels.parameters(), lr=learning_rate)\n","\n","# Train the model_with_avg_pooling_constant_channels\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n","\n","# Test the model_with_avg_pooling_constant_channels\n","model_with_avg_pooling_constant_channels.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model_with_avg_pooling_constant_channels(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which gpu\n",
    "import os\n",
    "gpu_id = 7\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arnisaf/mp-tl-study\n",
      "/home/arnisaf/mp-tl-study/CIFAR\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from utils import *\n",
    "%cd CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)  # if using multi-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THEORETICAL EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "#percentages = [0.001, 0.002, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# cuts=0 means: end-to-end model if we are reinitializing\n",
    "cuts = [0,1,2,3,4,5,6]\n",
    "#seed_set = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]  # currently not being used\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import math\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, params, output_dim):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.params = params\n",
    "\n",
    "        # Change initial number of input channels for RGB images\n",
    "        in_channels = 3\n",
    "\n",
    "        for i in range(params[\"depth\"]):\n",
    "            setattr(self, f\"conv{i}\", nn.Conv2d(in_channels, params[\"num_channels\"], kernel_size=params[\"kernel_size\"], padding=math.floor(params[\"kernel_size\"]/2)))\n",
    "            setattr(self, f\"act{i}\", params[\"activation_function\"]())\n",
    "\n",
    "            if params[\"use_pooling\"] and (i+1) % 2 == 0:\n",
    "                setattr(self, f\"pool{i}\", nn.AvgPool2d(2, stride=2))\n",
    "\n",
    "            in_channels = params[\"num_channels\"]\n",
    "\n",
    "        self.calculate_to_linear_size()\n",
    "\n",
    "        self.fc = nn.Linear(self._to_linear, output_dim)\n",
    "\n",
    "    def calculate_to_linear_size(self):\n",
    "        # Adjust the dummy input tensor for CIFAR-10\n",
    "        x = torch.zeros(1, 3, 32, 32)\n",
    "        for layer_name, layer in self.named_children():\n",
    "            if \"conv\" in layer_name or \"act\" in layer_name:\n",
    "                x = layer(x)\n",
    "            elif \"pool\" in layer_name:\n",
    "                x = layer(x)\n",
    "            elif isinstance(layer, nn.Linear):\n",
    "                break\n",
    "        self._to_linear = x.view(x.size(0), -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer_name, layer in self.named_children():\n",
    "            if \"conv\" in layer_name or \"act\" in layer_name:\n",
    "                x = layer(x)\n",
    "            elif \"pool\" in layer_name:\n",
    "                x = layer(x)\n",
    "            elif isinstance(layer, nn.Linear):\n",
    "                break\n",
    "\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "def eval(model, device, dataset_loader, debug=False, classification_report_flag=False, is_cnn=True, logger=print):\n",
    "    model.eval()\n",
    "    test_loss, correct = 0., 0.\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataset_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # Changed to cross_entropy\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    num_data = len(dataset_loader.dataset)\n",
    "    test_loss /= num_data\n",
    "    acc = correct / num_data\n",
    "\n",
    "    if debug:\n",
    "        logger('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, num_data, 100. * acc))\n",
    "\n",
    "    if classification_report_flag:\n",
    "        unique_labels = np.unique(all_labels).tolist()\n",
    "        logger(classification_report(all_labels, all_preds, labels=unique_labels, target_names=[f'Class {i}' for i in unique_labels]))\n",
    "\n",
    "    return acc\n",
    "\n",
    "def cut_custom_cnn_model(model, cut_point, params, output_dim):\n",
    "    \"\"\"\n",
    "    Cut the CustomCNN model at a specific layer and reinitialize the weights for layers after cut_point.\n",
    "\n",
    "    Parameters:\n",
    "    - model (CustomCNN): Original CustomCNN model.\n",
    "    - cut_point (int): Layer index (in terms of conv layers) at which to modify the model.\n",
    "    - freeze (bool): If True, layers before cut_point will have their weights frozen (from params)\n",
    "    - reinitialize (bool): If True, layers after cut_point will have their weights reinitialized (from params)\n",
    "    - output_dim (int): for the final linear layer that is used for classification\n",
    "\n",
    "    Returns:\n",
    "    - new_model (CustomCNN): Modified model.\n",
    "    \"\"\"\n",
    "\n",
    "    new_model = copy.deepcopy(model).to(\"cpu\")\n",
    "\n",
    "    # Get names of layers in the model\n",
    "    layer_names = list(new_model._modules.keys())\n",
    "\n",
    "    # Find indices of Conv layers\n",
    "    conv_indices = [i for i, name in enumerate(layer_names) if 'conv' in name]\n",
    "    #print(conv_indices)\n",
    "\n",
    "    # If freeze is True, set requires_grad to False for layers before cut_point\n",
    "    if params[\"freeze\"]:\n",
    "        for idx in conv_indices[:cut_point]:\n",
    "            for param in getattr(new_model, layer_names[idx]).parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    for idx in conv_indices[cut_point:]:\n",
    "        layer = getattr(new_model, layer_names[idx])\n",
    "\n",
    "        # Reinitialize layers after cut_point\n",
    "        if params[\"reinit\"]:\n",
    "            layer.reset_parameters()\n",
    "            \"\"\"\n",
    "            nn.init.kaiming_uniform_(layer.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "            if layer.bias is not None:\n",
    "                nn.init.constant_(layer.bias, 0)\n",
    "            \"\"\"\n",
    "\n",
    "        # Delete the layers after cut_point\n",
    "        if params[\"truncate\"]:\n",
    "            delattr(new_model, layer_names[idx])\n",
    "            # also delete the activation after this conv layer\n",
    "            delattr(new_model, layer_names[idx+1])\n",
    "            if \"pool\" in layer_names[idx+2]:\n",
    "                delattr(new_model, layer_names[idx+2])\n",
    "\n",
    "    \"\"\"# if reinit_both_dense: reinit the one before the last one too\n",
    "    if params[\"reinit_both_dense\"]:\n",
    "        new_model.fc_1.reset_parameters()\"\"\"\n",
    "\n",
    "    # reinit the final dense layer anyway\n",
    "    # new_model.fc.reset_parameters()\n",
    "    new_model.calculate_to_linear_size()\n",
    "    new_model.fc = nn.Linear(new_model._to_linear, output_dim)\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloader, lr, params):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.params = params\n",
    "        self.device = torch.device(params['device'])\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "        self.max_val_acc = 0.\n",
    "        self.no_improve_epochs = 0\n",
    "        self.is_cnn = params.get('is_cnn', False)\n",
    "        self.is_debug = params.get('is_debug', False)\n",
    "        self.classification_report_flag = params.get('classification_report_flag', False)\n",
    "        self.logger = params.get('logger', print)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(self.dataloader.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = F.cross_entropy(output, target) # Changed to cross_entropy for CIFAR-10\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.is_debug and batch_idx % 20 == 0:\n",
    "                self.logger(f\"Batch: {batch_idx}, Loss: {loss.item()}\")\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        return eval(self.model, self.device, loader, self.is_debug, self.classification_report_flag, self.is_cnn)\n",
    "\n",
    "    def save_best_model(self):\n",
    "        torch.save(self.model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    def save_checkpoint(self, epoch, train_acc, val_acc):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_acc': train_acc,\n",
    "            'val_acc': val_acc\n",
    "        }\n",
    "        torch.save(checkpoint, f'checkpoint_epoch_{epoch}.pth')\n",
    "        return checkpoint\n",
    "\n",
    "    def early_stopping_check(self, val_acc):\n",
    "        if val_acc > self.max_val_acc:\n",
    "            self.max_val_acc = val_acc\n",
    "            self.no_improve_epochs = 0\n",
    "            # Deep copy the model's state\n",
    "            self.best_model_state = copy.deepcopy(self.model.state_dict())\n",
    "            if self.params.get('save_best', False):\n",
    "                self.save_best_model()\n",
    "        else:\n",
    "            self.no_improve_epochs += 1\n",
    "            if self.no_improve_epochs >= self.params['early_stop_patience']:\n",
    "                self.logger(\"Early stopping invoked.\")\n",
    "                # Only load if best_model_state has been set\n",
    "                if self.best_model_state is not None:\n",
    "                    self.model.load_state_dict(self.best_model_state)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def train(self, verbose=1):\n",
    "        effective_epochs = 0\n",
    "        checkpoints = []\n",
    "\n",
    "        for epoch in range(self.params['num_train']):\n",
    "            effective_epochs += 1\n",
    "            self.train_epoch()\n",
    "\n",
    "            train_acc = self.evaluate(self.dataloader.train_loader)\n",
    "            val_acc = self.evaluate(self.dataloader.val_loader)\n",
    "            if verbose >= 1:\n",
    "                self.logger(f'Epoch: {epoch} \\tTraining Accuracy: {train_acc*100:.2f}%')\n",
    "                self.logger(f'Validation Accuracy: {val_acc*100:.2f}%')\n",
    "\n",
    "            if self.params.get('early_stop_patience', None):\n",
    "                if self.early_stopping_check(val_acc):\n",
    "                    self.model.load_state_dict(self.best_model_state)\n",
    "                    break\n",
    "\n",
    "            if self.params.get('save_checkpoints', False):\n",
    "                checkpoint = self.save_checkpoint(epoch, train_acc, val_acc)\n",
    "                checkpoints.append(checkpoint)\n",
    "\n",
    "        # Final evaluations\n",
    "        train_acc = self.evaluate(self.dataloader.train_loader)\n",
    "        test_acc = self.evaluate(self.dataloader.test_loader)\n",
    "\n",
    "        return train_acc, test_acc, effective_epochs, checkpoints\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes Here for the experiments\n",
    "params = {\n",
    "      # MODEL ARCHITECTURE PARAMS\n",
    "      'depth': 6,\n",
    "      'num_channels': 64,\n",
    "      'width':64,\n",
    "      # 'hidden_dim_lin': 128,\n",
    "      'activation_function': nn.ReLU,\n",
    "      'kernel_size': 3,\n",
    "      # TRAINING PARAMS\n",
    "      'device': device,\n",
    "      'lr_pretrain': 0.001,   \n",
    "      'lr_fine_tune': 0.001,  # CHANGE: if no layer-wise lr\n",
    "      # 'lr_fine_tune_reinit': 0.001,         # CHANGE: if no layer-wise lr\n",
    "      # 'lr_fine_tune_no_reinit': 0.0001,     # CHANGE: if layer-wise lr\n",
    "      'num_train': 10,\n",
    "      'early_stop_patience': 5,\n",
    "      'save_best': False,\n",
    "      'save_checkpoints': False,\n",
    "      'is_cnn': True,\n",
    "      'is_debug': False,\n",
    "      'classification_report_flag': False,\n",
    "      'batch_size':batch_size,\n",
    "      # DATASET PARAMS\n",
    "      'pre_train_classes': [0, 1, 8, 9], #[2, 3, 4, 5, 6, 7]\n",
    "      'fine_tune_classes': [2, 3, 4, 5, 6, 7],\n",
    "        'val_split': 0.1,\n",
    "      'num_workers': 0,\n",
    "      'generate_dataset_seed': 42,\n",
    "      # EXPERIMENT SETTING PARAMS\n",
    "      'percentages':percentages,\n",
    "      'use_pooling': True,   # CHANGE\n",
    "      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n",
    "      'reinit': True,         # CHANGE: reinit the conv lyers only after the cut\n",
    "      'reinit_both_dense': True,   # CHANGE: True for reinitialize both dense layers, False for reinit only the last dense layer\n",
    "      'truncate': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root_dir = './data'  # Specify your data directory here\n",
    "transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "dataloader_wrapped = TransferLearningWrapper(params, datasets.CIFAR10, datasets.CIFAR10, root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act0): ReLU()\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act3): ReLU()\n",
       "  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act4): ReLU()\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act5): ReLU()\n",
       "  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act0): ReLU()\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act3): ReLU()\n",
       "  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act4): ReLU()\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act5): ReLU()\n",
       "  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.load_state_dict(torch.load('pretrained_models/pretrained_model_Vehicles_constant_channels/modelcifar10_vehicles_cpu.pth'))\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.1832, Accuracy: 18689.0/20000 (93%)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.91      0.95      0.93      5000\n",
      "     Class 1       0.97      0.92      0.95      5000\n",
      "     Class 2       0.94      0.93      0.93      5000\n",
      "     Class 3       0.92      0.94      0.93      5000\n",
      "\n",
      "    accuracy                           0.93     20000\n",
      "   macro avg       0.94      0.93      0.93     20000\n",
      "weighted avg       0.94      0.93      0.93     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93445"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(pretrained_model, device, dataloader_wrapped.test_loader, debug=True, classification_report_flag=True, is_cnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act0): ReLU()\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (fc): Linear(in_features=16384, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new = cut_custom_cnn_model(pretrained_model, cut_point=3, params=params, output_dim=dataloader_wrapped.output_dim)\n",
    "model_new.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# percentages = [0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.3, 0.5, 0.8, 1]\n",
    "percentages = [1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 0, Lr: 0.001, Repeat: 0\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.4103, Test Accuracy: 0.4083\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 0, Lr: 0.001, Repeat: 1\n",
      "Training Accuracy: 0.4319, Test Accuracy: 0.4270\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 0, Lr: 0.001, Repeat: 2\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.4010, Test Accuracy: 0.3994\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 0, Lr: 0.001, Repeat: 3\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.4290, Test Accuracy: 0.4262\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 0, Lr: 0.001, Repeat: 4\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.4190, Test Accuracy: 0.4159\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 1, Lr: 0.001, Repeat: 0\n",
      "Training Accuracy: 0.6019, Test Accuracy: 0.5878\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 1, Lr: 0.001, Repeat: 1\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.7260, Test Accuracy: 0.7083\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 1, Lr: 0.001, Repeat: 2\n",
      "Training Accuracy: 0.6710, Test Accuracy: 0.6535\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 1, Lr: 0.001, Repeat: 3\n",
      "Training Accuracy: 0.7807, Test Accuracy: 0.7573\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 1, Lr: 0.001, Repeat: 4\n",
      "Training Accuracy: 0.7884, Test Accuracy: 0.7645\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 2, Lr: 0.001, Repeat: 0\n",
      "Training Accuracy: 0.7760, Test Accuracy: 0.7591\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 2, Lr: 0.001, Repeat: 1\n",
      "Training Accuracy: 0.7755, Test Accuracy: 0.7590\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 2, Lr: 0.001, Repeat: 2\n",
      "Training Accuracy: 0.7918, Test Accuracy: 0.7750\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 2, Lr: 0.001, Repeat: 3\n",
      "Training Accuracy: 0.7902, Test Accuracy: 0.7725\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 2, Lr: 0.001, Repeat: 4\n",
      "Training Accuracy: 0.7913, Test Accuracy: 0.7739\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 3, Lr: 0.001, Repeat: 0\n",
      "Training Accuracy: 0.7660, Test Accuracy: 0.7496\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 3, Lr: 0.001, Repeat: 1\n",
      "Training Accuracy: 0.8155, Test Accuracy: 0.7958\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 3, Lr: 0.001, Repeat: 2\n",
      "Training Accuracy: 0.7726, Test Accuracy: 0.7556\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 3, Lr: 0.001, Repeat: 3\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.7156, Test Accuracy: 0.7048\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 3, Lr: 0.001, Repeat: 4\n",
      "Training Accuracy: 0.8179, Test Accuracy: 0.7985\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 4, Lr: 0.001, Repeat: 0\n",
      "Training Accuracy: 0.6961, Test Accuracy: 0.6888\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 4, Lr: 0.001, Repeat: 1\n",
      "Training Accuracy: 0.6936, Test Accuracy: 0.6858\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 4, Lr: 0.001, Repeat: 2\n",
      "Training Accuracy: 0.6981, Test Accuracy: 0.6901\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 4, Lr: 0.001, Repeat: 3\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.6790, Test Accuracy: 0.6734\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 4, Lr: 0.001, Repeat: 4\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.6864, Test Accuracy: 0.6807\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 5, Lr: 0.001, Repeat: 0\n",
      "Training Accuracy: 0.6828, Test Accuracy: 0.6719\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 5, Lr: 0.001, Repeat: 1\n",
      "Training Accuracy: 0.7049, Test Accuracy: 0.6949\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 5, Lr: 0.001, Repeat: 2\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.6819, Test Accuracy: 0.6742\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 5, Lr: 0.001, Repeat: 3\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.6520, Test Accuracy: 0.6468\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 5, Lr: 0.001, Repeat: 4\n",
      "Early stopping invoked.\n",
      "Training Accuracy: 0.6827, Test Accuracy: 0.6754\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 6, Lr: 0.001, Repeat: 0\n",
      "Training Accuracy: 0.6210, Test Accuracy: 0.6174\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 6, Lr: 0.001, Repeat: 1\n",
      "Training Accuracy: 0.6174, Test Accuracy: 0.6133\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 6, Lr: 0.001, Repeat: 2\n",
      "Training Accuracy: 0.6167, Test Accuracy: 0.6136\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 6, Lr: 0.001, Repeat: 3\n",
      "Training Accuracy: 0.6194, Test Accuracy: 0.6155\n",
      "\n",
      "Sampled Percentage: 1.0, Sampled Cut Point: 6, Lr: 0.001, Repeat: 4\n",
      "Training Accuracy: 0.6212, Test Accuracy: 0.6174\n"
     ]
    }
   ],
   "source": [
    "dataloader_wrapped.update_phase('finetune')\n",
    "\n",
    "for sampled_percentage in percentages:\n",
    "\n",
    "    if sampled_percentage <= 0.01:\n",
    "        repeats = 25\n",
    "    elif sampled_percentage < 0.5:\n",
    "        repeats = 20\n",
    "    else:\n",
    "        repeats = 5\n",
    "        \n",
    "    for sampled_cut_point in cuts:\n",
    "\n",
    "        for repeat in range(repeats):\n",
    "            # Add the combination to the tested set\n",
    "            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n",
    "\n",
    "            # Print or log the sampled values for transparency\n",
    "            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n",
    "\n",
    "            # Reduce the dataset\n",
    "            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n",
    "            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n",
    "            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n",
    "            \n",
    "            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n",
    "            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n",
    "            model_new.to(device)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n",
    "            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n",
    "            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "            # Store the results\n",
    "            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 0, 'repeat': 0, 'train_acc': 0.4102649743932309, 'test_acc': 0.40826666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 0, 'repeat': 1, 'train_acc': 0.431900838714466, 'test_acc': 0.427}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 0, 'repeat': 2, 'train_acc': 0.4009500482446374, 'test_acc': 0.3994333333333333}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 0, 'repeat': 3, 'train_acc': 0.4290432717286425, 'test_acc': 0.4261666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 0, 'repeat': 4, 'train_acc': 0.41902323164848215, 'test_acc': 0.4159}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 1, 'repeat': 0, 'train_acc': 0.6019075187411861, 'test_acc': 0.5877666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 1, 'repeat': 1, 'train_acc': 0.7260075706969494, 'test_acc': 0.7083}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 1, 'repeat': 2, 'train_acc': 0.6710086840347361, 'test_acc': 0.6535}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 1, 'repeat': 3, 'train_acc': 0.7807095672827136, 'test_acc': 0.7572666666666666}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 1, 'repeat': 4, 'train_acc': 0.7883915980108365, 'test_acc': 0.7644666666666666}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 2, 'repeat': 0, 'train_acc': 0.7759964373190826, 'test_acc': 0.7590666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 2, 'repeat': 1, 'train_acc': 0.7754768796852965, 'test_acc': 0.7589666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 2, 'repeat': 2, 'train_acc': 0.7918058338900023, 'test_acc': 0.775}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 2, 'repeat': 3, 'train_acc': 0.7902100497290878, 'test_acc': 0.7724666666666666}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 2, 'repeat': 4, 'train_acc': 0.7913233875157722, 'test_acc': 0.7738666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 3, 'repeat': 0, 'train_acc': 0.7659763972389223, 'test_acc': 0.7496}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 3, 'repeat': 1, 'train_acc': 0.8155199287463817, 'test_acc': 0.7958}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 3, 'repeat': 2, 'train_acc': 0.772619312699473, 'test_acc': 0.7556333333333334}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 3, 'repeat': 3, 'train_acc': 0.7155793067616715, 'test_acc': 0.7047666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 3, 'repeat': 4, 'train_acc': 0.8179321606175314, 'test_acc': 0.7985333333333333}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 4, 'repeat': 0, 'train_acc': 0.6960587842351369, 'test_acc': 0.6887666666666666}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 4, 'repeat': 1, 'train_acc': 0.6936465523639872, 'test_acc': 0.6858333333333333}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 4, 'repeat': 2, 'train_acc': 0.698062792251169, 'test_acc': 0.6901}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 4, 'repeat': 3, 'train_acc': 0.6789876048393082, 'test_acc': 0.6733666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 4, 'repeat': 4, 'train_acc': 0.6864469680100943, 'test_acc': 0.6807}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 5, 'repeat': 0, 'train_acc': 0.6827729533140354, 'test_acc': 0.6719333333333334}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 5, 'repeat': 1, 'train_acc': 0.7049283752690566, 'test_acc': 0.6949}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 5, 'repeat': 2, 'train_acc': 0.6818822830846879, 'test_acc': 0.6742}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 5, 'repeat': 3, 'train_acc': 0.6520077191419876, 'test_acc': 0.6468333333333334}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 5, 'repeat': 4, 'train_acc': 0.6826987307949232, 'test_acc': 0.6754333333333333}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 6, 'repeat': 0, 'train_acc': 0.6209827061530468, 'test_acc': 0.6174}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 6, 'repeat': 1, 'train_acc': 0.6173829139761003, 'test_acc': 0.6133333333333333}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 6, 'repeat': 2, 'train_acc': 0.6166778000445335, 'test_acc': 0.6135666666666667}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 6, 'repeat': 3, 'train_acc': 0.6193869219921324, 'test_acc': 0.6155333333333334}, {'lr': 0.001, 'sampled_percentage': 1.0, 'sampled_cut_point': 6, 'repeat': 4, 'train_acc': 0.6212424849699398, 'test_acc': 0.6173666666666666}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save baseline results\n",
    "params_tmp = copy.deepcopy(params)\n",
    "del params_tmp[\"device\"]\n",
    "params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n",
    "results = [params_tmp] + results\n",
    "\n",
    "with open(f'results_jsons/results_freeze_{params[\"freeze\"]}_pool_{params[\"use_pooling\"]}_lr_{params[\"lr_fine_tune\"]}_{percentages[0]}_to_{percentages[-1]}.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

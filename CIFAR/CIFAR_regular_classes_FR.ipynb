{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for:\n",
    "Transfer Learning Empirical Experiment from Vehicles (pretraining) to Animals (finetuning) classes of CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which gpu\n",
    "import os\n",
    "gpu_id = 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/Arnisa/Desktop/MP/mp-tl-study')\n",
    "from functions.utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)  # if using multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "cuts = [0,1,2,3,4,5,6]\n",
    "params = {\n",
    "      # MODEL ARCHITECTURE PARAMS\n",
    "      'depth': 6,\n",
    "      'num_channels': 64,\n",
    "      'activation_function': nn.ReLU,\n",
    "      'kernel_size': 3,\n",
    "      # TRAINING PARAMS\n",
    "      'device': device,\n",
    "      'lr_pretrain': 0.001,   \n",
    "      'lr_fine_tune': 0.001, \n",
    "      'num_train': 40,\n",
    "      'early_stop_patience': 6,\n",
    "      'save_best': False,\n",
    "      'save_checkpoints': False,\n",
    "      'is_cnn': True,\n",
    "      'is_debug': False,\n",
    "      'classification_report_flag': False,\n",
    "      'batch_size':64,\n",
    "      # DATASET PARAMS\n",
    "      'pre_train_classes': [0, 1, 8, 9],\n",
    "      'fine_tune_classes': [2, 3, 4, 5, 6, 7],\n",
    "      'val_split': 0.1,\n",
    "      'num_workers': 0,\n",
    "      'generate_dataset_seed': 42,\n",
    "      # EXPERIMENT SETTING PARAMS\n",
    "      'use_pooling': True,  \n",
    "      'pooling_every_n_layers': 2, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n",
    "      'pooling_stride': 2,\n",
    "      'freeze': True,         # VARIABLE\n",
    "      'reinit': True,         # VARIABLE\n",
    "      'truncate': False,      # VARIABLE\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root_dir = './data' \n",
    "transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "dataloader_wrapped = TransferLearningWrapper(params, datasets.CIFAR10, datasets.CIFAR10, root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act0): ReLU()\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act3): ReLU()\n",
       "  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act4): ReLU()\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act5): ReLU()\n",
       "  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim, tuple(dataloader_wrapped.finetune_test_loader.dataset[0][0].shape))\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Accuracy: 44.91%\n",
      "Validation Accuracy: 43.40%\n",
      "Epoch: 1 \tTraining Accuracy: 53.14%\n",
      "Validation Accuracy: 50.33%\n",
      "Epoch: 2 \tTraining Accuracy: 63.49%\n",
      "Validation Accuracy: 60.30%\n",
      "Epoch: 3 \tTraining Accuracy: 68.63%\n",
      "Validation Accuracy: 65.00%\n",
      "Epoch: 4 \tTraining Accuracy: 70.95%\n",
      "Validation Accuracy: 67.07%\n",
      "Epoch: 5 \tTraining Accuracy: 76.44%\n",
      "Validation Accuracy: 70.37%\n",
      "Epoch: 6 \tTraining Accuracy: 78.74%\n",
      "Validation Accuracy: 71.53%\n",
      "Epoch: 7 \tTraining Accuracy: 81.48%\n",
      "Validation Accuracy: 72.73%\n",
      "Epoch: 8 \tTraining Accuracy: 83.88%\n",
      "Validation Accuracy: 73.43%\n",
      "Epoch: 9 \tTraining Accuracy: 87.08%\n",
      "Validation Accuracy: 74.83%\n",
      "Final Training Accuracy: 0.8708\n",
      "Final Test Accuracy: 0.8586\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate - Skip if loading saved model!\n",
    "trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n",
    "train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n",
    "\n",
    "print(f\"Final Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act0): ReLU()\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act3): ReLU()\n",
       "  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act4): ReLU()\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act5): ReLU()\n",
       "  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc): Linear(in_features=1024, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.load_state_dict(torch.load('pretrained_models/regular_classes.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average loss: 0.1832, Accuracy: 18689.0/20000 (93%)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.91      0.95      0.93      5000\n",
      "     Class 1       0.97      0.92      0.95      5000\n",
      "     Class 2       0.94      0.93      0.93      5000\n",
      "     Class 3       0.92      0.94      0.93      5000\n",
      "\n",
      "    accuracy                           0.93     20000\n",
      "   macro avg       0.94      0.93      0.93     20000\n",
      "weighted avg       0.94      0.93      0.93     20000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93445"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(pretrained_model, device, dataloader_wrapped.test_loader, debug=True, classification_report_flag=True, is_cnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for later use\n",
    "torch.save(pretrained_model.state_dict(), 'pretrained_models/regular_classes.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "We also reuse the baselines a lot! so skip if we already have the jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_results = []\n",
    "percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_wrapped.update_phase('finetune')\n",
    "\n",
    "for sampled_percentage in percentages:      \n",
    "    if sampled_percentage <= 0.01:\n",
    "        repeats = 25\n",
    "    elif sampled_percentage < 0.5:\n",
    "        repeats = 20\n",
    "    else:\n",
    "        repeats = 5\n",
    "    \n",
    "    for repeat in range(repeats):\n",
    "        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n",
    "\n",
    "        # Reduce the dataset\n",
    "        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n",
    "        torch.manual_seed(repeat)\n",
    "        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n",
    "\n",
    "        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n",
    "        params_tmp = copy.deepcopy(params)\n",
    "        params_tmp[\"reinit\"] = True\n",
    "        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n",
    "        model_new.to(device)\n",
    "\n",
    "        # Train and evaluate\n",
    "        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n",
    "        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n",
    "        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        # Store the results\n",
    "        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save baseline results\n",
    "params_tmp = copy.deepcopy(params)\n",
    "del params_tmp[\"device\"]\n",
    "params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n",
    "results = [params_tmp] + baselines_results\n",
    "\n",
    "with open(f'results/baselines_regular_classes.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_wrapped.update_phase('finetune')\n",
    "\n",
    "for sampled_percentage in percentages:\n",
    "\n",
    "    if sampled_percentage <= 0.01:\n",
    "        repeats = 25\n",
    "    elif sampled_percentage < 0.5:\n",
    "        repeats = 20\n",
    "    else:\n",
    "        repeats = 5\n",
    "        \n",
    "    for sampled_cut_point in cuts:\n",
    "\n",
    "        for repeat in range(repeats):\n",
    "            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n",
    "\n",
    "            # Reduce the dataset\n",
    "            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n",
    "            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n",
    "            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n",
    "            \n",
    "            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n",
    "            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n",
    "            model_new.to(device)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n",
    "            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n",
    "            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "            # Store the results\n",
    "            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fine-tuning results\n",
    "params_tmp = copy.deepcopy(params)\n",
    "del params_tmp[\"device\"]\n",
    "params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n",
    "results = [params_tmp] + results\n",
    "\n",
    "with open(f'results/cuts_regular_classes_FR.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

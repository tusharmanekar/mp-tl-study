{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport datasets\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define the CNN Model\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_channels, use_avg_pooling, kernel_size, padding):\n        super(SimpleCNN, self).__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(1, num_channels, kernel_size=kernel_size, padding=padding)\n        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=kernel_size, padding=padding)\n        self.conv3 = nn.Conv2d(num_channels, num_channels, kernel_size=kernel_size, padding=padding)\n        self.conv4 = nn.Conv2d(num_channels, num_channels, kernel_size=kernel_size, padding=padding)\n        self.conv5 = nn.Conv2d(num_channels, num_channels, kernel_size=kernel_size, padding=padding)\n\n        self.use_avg_pooling = use_avg_pooling\n        if self.use_avg_pooling:\n            self.pool = nn.AvgPool2d(2, 2)\n        else:\n            self.pool = None\n\n        # Dummy input for size calculation\n        self._to_linear = None\n        self.calculate_to_linear_size()\n\n        self.fc = nn.Linear(self._to_linear, 10)\n\n    def calculate_to_linear_size(self):\n        dummy_input = torch.zeros(1, 1, 28, 28)\n        x = self.conv1(dummy_input)\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = self.conv2(x)\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = self.conv3(x)\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = self.conv4(x)\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = self.conv5(x)\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        self._to_linear = x.view(x.size(0), -1).size(1)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = F.relu(self.conv3(x))\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = F.relu(self.conv4(x))\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = F.relu(self.conv5(x))\n        if self.use_avg_pooling:\n            x = self.pool(x)\n        x = x.view(-1, self._to_linear) # Flatten\n        x = self.fc(x)\n        return F.log_softmax(x, dim=1)\n\n\n# Function for Training and Evaluating the Model\ndef train_and_evaluate(model, train_loader, test_loader, epochs=10, lr=0.001):\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    model.train()\n\n    for epoch in range(epochs):\n        total_loss = 0\n        for data, target in train_loader:\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        average_loss = total_loss / len(train_loader)\n        print(f'Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}')\n\n\n    correct = 0\n    total = 0\n    model.eval()\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)  # Move data and target to the device\n            outputs = model(data)\n            _, predicted = torch.max(outputs.data, 1)\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    accuracy = correct / total\n    return accuracy\n\n\n# Random Search Hyperparameter Tuning\ndef random_search_hyperparameters(num_trials, train_loader, test_loader):\n    trial_results = {}\n\n    for trial in range(num_trials):\n        print(f\"currently in trial {trial}\")\n        num_channels = random.choice([10, 20, 30, 40, 50])\n        #use_avg_pooling = random.choice([True, False])\n        use_avg_pooling = random.choice([False])\n        kernel_size, padding = random.choice([(3, 1), (5, 2), (7, 3)])\n\n        model = SimpleCNN(num_channels, use_avg_pooling, kernel_size, padding)\n        model.to(device)\n        \n        accuracy = train_and_evaluate(model, train_loader, test_loader, epochs=10, lr=0.001)\n\n        trial_results[trial] = {\n            'num_channels': num_channels,\n            'use_avg_pooling': use_avg_pooling,\n            'kernel_size': kernel_size,\n            'padding': padding,\n            'accuracy': accuracy\n        }\n\n    return trial_results\n\n# Define the transformation for the dataset\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load and transform the dataset\ntrain_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n# Perform Random Search\ntrial_results = random_search_hyperparameters(20, train_loader, test_loader)\nfor trial, results in trial_results.items():\n    print(f\"Trial {trial}, Results: {results}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-20T21:06:12.265350Z","iopub.execute_input":"2023-12-20T21:06:12.265765Z","iopub.status.idle":"2023-12-20T22:24:36.217639Z","shell.execute_reply.started":"2023-12-20T21:06:12.265731Z","shell.execute_reply":"2023-12-20T22:24:36.216576Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"currently in trial 0\nEpoch 1/10, Loss: 0.4730\nEpoch 2/10, Loss: 0.3110\nEpoch 3/10, Loss: 0.2713\nEpoch 4/10, Loss: 0.2470\nEpoch 5/10, Loss: 0.2257\nEpoch 6/10, Loss: 0.2086\nEpoch 7/10, Loss: 0.1920\nEpoch 8/10, Loss: 0.1775\nEpoch 9/10, Loss: 0.1662\nEpoch 10/10, Loss: 0.1555\ncurrently in trial 1\nEpoch 1/10, Loss: 0.3949\nEpoch 2/10, Loss: 0.2394\nEpoch 3/10, Loss: 0.1887\nEpoch 4/10, Loss: 0.1493\nEpoch 5/10, Loss: 0.1155\nEpoch 6/10, Loss: 0.0880\nEpoch 7/10, Loss: 0.0661\nEpoch 8/10, Loss: 0.0532\nEpoch 9/10, Loss: 0.0413\nEpoch 10/10, Loss: 0.0337\ncurrently in trial 2\nEpoch 1/10, Loss: 0.4216\nEpoch 2/10, Loss: 0.2718\nEpoch 3/10, Loss: 0.2234\nEpoch 4/10, Loss: 0.1919\nEpoch 5/10, Loss: 0.1647\nEpoch 6/10, Loss: 0.1405\nEpoch 7/10, Loss: 0.1195\nEpoch 8/10, Loss: 0.0992\nEpoch 9/10, Loss: 0.0840\nEpoch 10/10, Loss: 0.0723\ncurrently in trial 3\nEpoch 1/10, Loss: 0.4230\nEpoch 2/10, Loss: 0.2531\nEpoch 3/10, Loss: 0.2058\nEpoch 4/10, Loss: 0.1701\nEpoch 5/10, Loss: 0.1372\nEpoch 6/10, Loss: 0.1130\nEpoch 7/10, Loss: 0.0879\nEpoch 8/10, Loss: 0.0726\nEpoch 9/10, Loss: 0.0568\nEpoch 10/10, Loss: 0.0479\ncurrently in trial 4\nEpoch 1/10, Loss: 0.4554\nEpoch 2/10, Loss: 0.2902\nEpoch 3/10, Loss: 0.2510\nEpoch 4/10, Loss: 0.2259\nEpoch 5/10, Loss: 0.2072\nEpoch 6/10, Loss: 0.1932\nEpoch 7/10, Loss: 0.1771\nEpoch 8/10, Loss: 0.1602\nEpoch 9/10, Loss: 0.1509\nEpoch 10/10, Loss: 0.1384\ncurrently in trial 5\nEpoch 1/10, Loss: 0.4580\nEpoch 2/10, Loss: 0.2997\nEpoch 3/10, Loss: 0.2575\nEpoch 4/10, Loss: 0.2322\nEpoch 5/10, Loss: 0.2088\nEpoch 6/10, Loss: 0.1860\nEpoch 7/10, Loss: 0.1686\nEpoch 8/10, Loss: 0.1491\nEpoch 9/10, Loss: 0.1335\nEpoch 10/10, Loss: 0.1190\ncurrently in trial 6\nEpoch 1/10, Loss: 0.4190\nEpoch 2/10, Loss: 0.2563\nEpoch 3/10, Loss: 0.2024\nEpoch 4/10, Loss: 0.1653\nEpoch 5/10, Loss: 0.1384\nEpoch 6/10, Loss: 0.1117\nEpoch 7/10, Loss: 0.0887\nEpoch 8/10, Loss: 0.0700\nEpoch 9/10, Loss: 0.0573\nEpoch 10/10, Loss: 0.0505\ncurrently in trial 7\nEpoch 1/10, Loss: 0.4077\nEpoch 2/10, Loss: 0.2605\nEpoch 3/10, Loss: 0.2183\nEpoch 4/10, Loss: 0.1870\nEpoch 5/10, Loss: 0.1588\nEpoch 6/10, Loss: 0.1310\nEpoch 7/10, Loss: 0.1071\nEpoch 8/10, Loss: 0.0913\nEpoch 9/10, Loss: 0.0744\nEpoch 10/10, Loss: 0.0649\ncurrently in trial 8\nEpoch 1/10, Loss: 0.4058\nEpoch 2/10, Loss: 0.2473\nEpoch 3/10, Loss: 0.1985\nEpoch 4/10, Loss: 0.1590\nEpoch 5/10, Loss: 0.1252\nEpoch 6/10, Loss: 0.0972\nEpoch 7/10, Loss: 0.0746\nEpoch 8/10, Loss: 0.0574\nEpoch 9/10, Loss: 0.0458\nEpoch 10/10, Loss: 0.0398\ncurrently in trial 9\nEpoch 1/10, Loss: 0.3858\nEpoch 2/10, Loss: 0.2271\nEpoch 3/10, Loss: 0.1755\nEpoch 4/10, Loss: 0.1387\nEpoch 5/10, Loss: 0.1058\nEpoch 6/10, Loss: 0.0781\nEpoch 7/10, Loss: 0.0564\nEpoch 8/10, Loss: 0.0455\nEpoch 9/10, Loss: 0.0358\nEpoch 10/10, Loss: 0.0319\ncurrently in trial 10\nEpoch 1/10, Loss: 0.4131\nEpoch 2/10, Loss: 0.2452\nEpoch 3/10, Loss: 0.1920\nEpoch 4/10, Loss: 0.1562\nEpoch 5/10, Loss: 0.1239\nEpoch 6/10, Loss: 0.1012\nEpoch 7/10, Loss: 0.0804\nEpoch 8/10, Loss: 0.0633\nEpoch 9/10, Loss: 0.0530\nEpoch 10/10, Loss: 0.0454\ncurrently in trial 11\nEpoch 1/10, Loss: 0.4375\nEpoch 2/10, Loss: 0.2911\nEpoch 3/10, Loss: 0.2506\nEpoch 4/10, Loss: 0.2269\nEpoch 5/10, Loss: 0.2020\nEpoch 6/10, Loss: 0.1815\nEpoch 7/10, Loss: 0.1656\nEpoch 8/10, Loss: 0.1458\nEpoch 9/10, Loss: 0.1319\nEpoch 10/10, Loss: 0.1145\ncurrently in trial 12\nEpoch 1/10, Loss: 0.4764\nEpoch 2/10, Loss: 0.3020\nEpoch 3/10, Loss: 0.2619\nEpoch 4/10, Loss: 0.2335\nEpoch 5/10, Loss: 0.2085\nEpoch 6/10, Loss: 0.1924\nEpoch 7/10, Loss: 0.1696\nEpoch 8/10, Loss: 0.1489\nEpoch 9/10, Loss: 0.1296\nEpoch 10/10, Loss: 0.1171\ncurrently in trial 13\nEpoch 1/10, Loss: 0.4115\nEpoch 2/10, Loss: 0.2627\nEpoch 3/10, Loss: 0.2231\nEpoch 4/10, Loss: 0.1913\nEpoch 5/10, Loss: 0.1645\nEpoch 6/10, Loss: 0.1434\nEpoch 7/10, Loss: 0.1235\nEpoch 8/10, Loss: 0.1041\nEpoch 9/10, Loss: 0.0901\nEpoch 10/10, Loss: 0.0779\ncurrently in trial 14\nEpoch 1/10, Loss: 0.4154\nEpoch 2/10, Loss: 0.2471\nEpoch 3/10, Loss: 0.1903\nEpoch 4/10, Loss: 0.1514\nEpoch 5/10, Loss: 0.1187\nEpoch 6/10, Loss: 0.0927\nEpoch 7/10, Loss: 0.0707\nEpoch 8/10, Loss: 0.0555\nEpoch 9/10, Loss: 0.0466\nEpoch 10/10, Loss: 0.0416\ncurrently in trial 15\nEpoch 1/10, Loss: 0.4833\nEpoch 2/10, Loss: 0.3190\nEpoch 3/10, Loss: 0.2748\nEpoch 4/10, Loss: 0.2476\nEpoch 5/10, Loss: 0.2274\nEpoch 6/10, Loss: 0.2108\nEpoch 7/10, Loss: 0.1962\nEpoch 8/10, Loss: 0.1810\nEpoch 9/10, Loss: 0.1686\nEpoch 10/10, Loss: 0.1562\ncurrently in trial 16\nEpoch 1/10, Loss: 0.4127\nEpoch 2/10, Loss: 0.2605\nEpoch 3/10, Loss: 0.2164\nEpoch 4/10, Loss: 0.1805\nEpoch 5/10, Loss: 0.1526\nEpoch 6/10, Loss: 0.1295\nEpoch 7/10, Loss: 0.1077\nEpoch 8/10, Loss: 0.0882\nEpoch 9/10, Loss: 0.0724\nEpoch 10/10, Loss: 0.0618\ncurrently in trial 17\nEpoch 1/10, Loss: 0.4408\nEpoch 2/10, Loss: 0.2756\nEpoch 3/10, Loss: 0.2303\nEpoch 4/10, Loss: 0.1982\nEpoch 5/10, Loss: 0.1754\nEpoch 6/10, Loss: 0.1532\nEpoch 7/10, Loss: 0.1345\nEpoch 8/10, Loss: 0.1129\nEpoch 9/10, Loss: 0.1004\nEpoch 10/10, Loss: 0.0873\ncurrently in trial 18\nEpoch 1/10, Loss: 0.4149\nEpoch 2/10, Loss: 0.2640\nEpoch 3/10, Loss: 0.2151\nEpoch 4/10, Loss: 0.1822\nEpoch 5/10, Loss: 0.1533\nEpoch 6/10, Loss: 0.1246\nEpoch 7/10, Loss: 0.1017\nEpoch 8/10, Loss: 0.0844\nEpoch 9/10, Loss: 0.0706\nEpoch 10/10, Loss: 0.0630\ncurrently in trial 19\nEpoch 1/10, Loss: 0.4113\nEpoch 2/10, Loss: 0.2550\nEpoch 3/10, Loss: 0.2130\nEpoch 4/10, Loss: 0.1789\nEpoch 5/10, Loss: 0.1500\nEpoch 6/10, Loss: 0.1237\nEpoch 7/10, Loss: 0.1002\nEpoch 8/10, Loss: 0.0801\nEpoch 9/10, Loss: 0.0676\nEpoch 10/10, Loss: 0.0584\nTrial 0, Results: {'num_channels': 10, 'use_avg_pooling': False, 'kernel_size': 7, 'padding': 3, 'accuracy': 0.8962}\nTrial 1, Results: {'num_channels': 50, 'use_avg_pooling': False, 'kernel_size': 3, 'padding': 1, 'accuracy': 0.9118}\nTrial 2, Results: {'num_channels': 30, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9055}\nTrial 3, Results: {'num_channels': 40, 'use_avg_pooling': False, 'kernel_size': 3, 'padding': 1, 'accuracy': 0.9098}\nTrial 4, Results: {'num_channels': 10, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9068}\nTrial 5, Results: {'num_channels': 40, 'use_avg_pooling': False, 'kernel_size': 7, 'padding': 3, 'accuracy': 0.901}\nTrial 6, Results: {'num_channels': 30, 'use_avg_pooling': False, 'kernel_size': 3, 'padding': 1, 'accuracy': 0.9057}\nTrial 7, Results: {'num_channels': 30, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9057}\nTrial 8, Results: {'num_channels': 50, 'use_avg_pooling': False, 'kernel_size': 3, 'padding': 1, 'accuracy': 0.9074}\nTrial 9, Results: {'num_channels': 50, 'use_avg_pooling': False, 'kernel_size': 3, 'padding': 1, 'accuracy': 0.9115}\nTrial 10, Results: {'num_channels': 30, 'use_avg_pooling': False, 'kernel_size': 3, 'padding': 1, 'accuracy': 0.9053}\nTrial 11, Results: {'num_channels': 40, 'use_avg_pooling': False, 'kernel_size': 7, 'padding': 3, 'accuracy': 0.9001}\nTrial 12, Results: {'num_channels': 50, 'use_avg_pooling': False, 'kernel_size': 7, 'padding': 3, 'accuracy': 0.894}\nTrial 13, Results: {'num_channels': 20, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9085}\nTrial 14, Results: {'num_channels': 50, 'use_avg_pooling': False, 'kernel_size': 3, 'padding': 1, 'accuracy': 0.9039}\nTrial 15, Results: {'num_channels': 10, 'use_avg_pooling': False, 'kernel_size': 7, 'padding': 3, 'accuracy': 0.9026}\nTrial 16, Results: {'num_channels': 50, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9033}\nTrial 17, Results: {'num_channels': 30, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9109}\nTrial 18, Results: {'num_channels': 40, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9058}\nTrial 19, Results: {'num_channels': 40, 'use_avg_pooling': False, 'kernel_size': 5, 'padding': 2, 'accuracy': 0.9019}\n","output_type":"stream"}]},{"cell_type":"code","source":"model = SimpleCNN(40, False, 3, 1)\nmodel.to(device)\n        \naccuracy = train_and_evaluate(model, train_loader, test_loader, epochs=40, lr=0.001)\n\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T23:39:34.178130Z","iopub.execute_input":"2023-12-20T23:39:34.178552Z","iopub.status.idle":"2023-12-20T23:50:47.933470Z","shell.execute_reply.started":"2023-12-20T23:39:34.178517Z","shell.execute_reply":"2023-12-20T23:50:47.932434Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/40, Loss: 0.3882\nEpoch 2/40, Loss: 0.2347\nEpoch 3/40, Loss: 0.1858\nEpoch 4/40, Loss: 0.1494\nEpoch 5/40, Loss: 0.1183\nEpoch 6/40, Loss: 0.0921\nEpoch 7/40, Loss: 0.0707\nEpoch 8/40, Loss: 0.0543\nEpoch 9/40, Loss: 0.0425\nEpoch 10/40, Loss: 0.0373\nEpoch 11/40, Loss: 0.0324\nEpoch 12/40, Loss: 0.0303\nEpoch 13/40, Loss: 0.0284\nEpoch 14/40, Loss: 0.0225\nEpoch 15/40, Loss: 0.0199\nEpoch 16/40, Loss: 0.0234\nEpoch 17/40, Loss: 0.0231\nEpoch 18/40, Loss: 0.0184\nEpoch 19/40, Loss: 0.0183\nEpoch 20/40, Loss: 0.0171\nEpoch 21/40, Loss: 0.0153\nEpoch 22/40, Loss: 0.0175\nEpoch 23/40, Loss: 0.0150\nEpoch 24/40, Loss: 0.0167\nEpoch 25/40, Loss: 0.0136\nEpoch 26/40, Loss: 0.0165\nEpoch 27/40, Loss: 0.0120\nEpoch 28/40, Loss: 0.0149\nEpoch 29/40, Loss: 0.0138\nEpoch 30/40, Loss: 0.0125\nEpoch 31/40, Loss: 0.0147\nEpoch 32/40, Loss: 0.0112\nEpoch 33/40, Loss: 0.0145\nEpoch 34/40, Loss: 0.0148\nEpoch 35/40, Loss: 0.0132\nEpoch 36/40, Loss: 0.0091\nEpoch 37/40, Loss: 0.0152\nEpoch 38/40, Loss: 0.0149\nEpoch 39/40, Loss: 0.0122\nEpoch 40/40, Loss: 0.0097\n0.9075\n","output_type":"stream"}]}]}
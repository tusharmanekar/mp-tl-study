{"cells":[{"cell_type":"markdown","metadata":{"id":"Tnr5Tf1Qa1H-"},"source":["# Example for:\n","Transfer Learning Empirical Experiment from all other classes of FashionMNIST to shoes (Sandal, Sneaker, Ankle boot) classes in FashionMNIST"]},{"cell_type":"markdown","metadata":{},"source":["### Setup and Hyperparams"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Specify which gpu\n","import os\n","gpu_id = 1\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","\n","import sys\n","sys.path.append('/home/arnisaf/mp-tl-study')\n","from functions.utils import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(0)\n","    torch.cuda.manual_seed_all(0)  # if using multi-GPU"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3, 4, 5]"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 5,\n","      'num_channels': 30, # num channels for CNN\n","      # 'hidden_dim_lin': 128,\n","      'activation_function': nn.ReLU,\n","      'kernel_size': 3,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001,  # CHANGE: if no layer-wise lr\n","      # 'lr_fine_tune_reinit': 0.001,         # CHANGE: if no layer-wise lr\n","      # 'lr_fine_tune_no_reinit': 0.0001,     # CHANGE: if layer-wise lr\n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'save_best': False,\n","      'save_checkpoints': False,\n","      'is_cnn': True,\n","      'is_debug': False,\n","      'classification_report_flag': False,\n","      'batch_size':4096,\n","      # DATASET PARAMS\n","      'pre_train_classes': [0, 1, 2, 3, 4, 6, 8],\n","      'fine_tune_classes': [5, 7, 9],\n","      'val_split': 0.1,\n","      'num_workers': 0,\n","      'generate_dataset_seed': 42,\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': False,   # CHANGE\n","      'pooling_every_n_layers': 2, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n","      'pooling_stride': 2,\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': True,         # CHANGE: reinit the conv lyers only after the cut\n","      'reinit_both_dense': True,   # CHANGE: True for reinitialize both dense layers, False for reinit only the last dense layer\n","      'truncate': False\n","    }"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["root_dir = './data'  # Specify your data directory here\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","dataloader_wrapped = TransferLearningWrapper(params, datasets.FashionMNIST, datasets.FashionMNIST, root_dir, transform=transform)## Pretraining"]},{"cell_type":"markdown","metadata":{},"source":["## Pretraining"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (conv2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (conv4): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (fc): Linear(in_features=23520, out_features=7, bias=True)\n",")"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#Create DNN model\n","pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 85.60%\n","Validation Accuracy: 83.24%\n","Epoch: 1 \tTraining Accuracy: 89.10%\n","Validation Accuracy: 86.24%\n","Epoch: 2 \tTraining Accuracy: 90.89%\n","Validation Accuracy: 87.55%\n","Epoch: 3 \tTraining Accuracy: 92.12%\n","Validation Accuracy: 88.14%\n","Epoch: 4 \tTraining Accuracy: 92.62%\n","Validation Accuracy: 88.64%\n","Epoch: 5 \tTraining Accuracy: 92.89%\n","Validation Accuracy: 88.62%\n","Epoch: 6 \tTraining Accuracy: 93.30%\n","Validation Accuracy: 88.86%\n","Epoch: 7 \tTraining Accuracy: 93.62%\n","Validation Accuracy: 89.02%\n","Epoch: 8 \tTraining Accuracy: 93.84%\n","Validation Accuracy: 89.12%\n","Epoch: 9 \tTraining Accuracy: 93.81%\n","Validation Accuracy: 88.62%\n","Epoch: 10 \tTraining Accuracy: 94.22%\n","Validation Accuracy: 89.02%\n","Epoch: 11 \tTraining Accuracy: 94.16%\n","Validation Accuracy: 89.19%\n","Epoch: 12 \tTraining Accuracy: 94.35%\n","Validation Accuracy: 88.81%\n","Epoch: 13 \tTraining Accuracy: 94.43%\n","Validation Accuracy: 88.98%\n","Epoch: 14 \tTraining Accuracy: 94.51%\n","Validation Accuracy: 88.86%\n","Epoch: 15 \tTraining Accuracy: 94.67%\n","Validation Accuracy: 88.98%\n","Epoch: 16 \tTraining Accuracy: 95.04%\n","Validation Accuracy: 89.07%\n","Epoch: 17 \tTraining Accuracy: 94.97%\n","Validation Accuracy: 88.83%\n","Early stopping invoked.\n","Final Training Accuracy: 0.9416\n","Final Test Accuracy: 0.9367\n"]}],"source":["# Train and evaluate - Skip if loading saved model!\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (conv2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (conv4): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (fc): Linear(in_features=23520, out_features=7, bias=True)\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model.load_state_dict(torch.load('pretrained_models/pretrained_normal_classes_new/pretrained_model.pth'))\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.3532, Accuracy: 3746.0/4200 (89%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.86      0.85      0.85       560\n","     Class 1       0.97      0.99      0.98       638\n","     Class 2       0.87      0.88      0.88       595\n","     Class 3       0.93      0.90      0.92       615\n","     Class 4       0.86      0.88      0.87       579\n","     Class 5       0.77      0.77      0.77       626\n","     Class 6       0.99      0.97      0.98       587\n","\n","    accuracy                           0.89      4200\n","   macro avg       0.89      0.89      0.89      4200\n","weighted avg       0.89      0.89      0.89      4200\n","\n"]},{"data":{"text/plain":["0.8919047619047619"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.val_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# save model for later use\n","foldername = \"pretrained_models/pretrained_normal_classes_new\"\n","os.mkdir(foldername)\n","torch.save(pretrained_model.state_dict(), os.path.join(foldername, 'pretrained_model.pth'))\n","\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","#save params as well\n","with open(os.path.join(foldername, 'params.json'), 'w') as fp:\n","    json.dump(params_tmp, fp)"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"markdown","metadata":{},"source":["### Baselines (End-to-end models trained on subsets of fine-tuning dataset)\n","We also reuse the baselines a lot! so skip if we already have the jsons"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["baselines_results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:      \n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","    \n","    for repeat in range(repeats):\n","        # Print or log the sampled values for transparency\n","        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","        # Reduce the dataset\n","        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        torch.manual_seed(repeat)\n","        #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","        params_tmp = copy.deepcopy(params)\n","        params_tmp[\"reinit\"] = True\n","        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n","        model_new.to(device)\n","\n","        # Train and evaluate\n","        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","        # Store the results\n","        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# save baseline results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + baselines_results\n","\n","with open(f'results_jsons/baselines_freeze_{params[\"freeze\"]}_pool_{params[\"use_pooling\"]}_truncate_{params[\"truncate\"]}.json', 'w') as f:\n","    json.dump(results, f)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# save fine-tuning results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/results_freeze_{params[\"freeze\"]}_reinit_{params[\"reinit\"]}_pool_{params[\"use_pooling\"]}_truncate_{params[\"truncate\"]}.json', 'w') as f:\n","    json.dump(results, f)\n","results = results[1:]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}

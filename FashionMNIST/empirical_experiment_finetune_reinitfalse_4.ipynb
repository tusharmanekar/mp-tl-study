{"cells":[{"cell_type":"markdown","metadata":{"id":"Tnr5Tf1Qa1H-"},"source":["# Example for:\n","Transfer Learning Empirical Experiment from all other classes of FashionMNIST to shoes (Sandal, Sneaker, Ankle boot) classes in FashionMNIST"]},{"cell_type":"markdown","metadata":{},"source":["### Setup and Hyperparams"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Specify which gpu\n","import os\n","gpu_id = 1\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","\n","import sys\n","sys.path.append('/home/arnisaf/mp-tl-study')\n","from functions.utils import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(0)\n","    torch.cuda.manual_seed_all(0)  # if using multi-GPU"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3,4,5,6]"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","metadata":{},"outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 6,\n","      'num_channels': 64, # num channels for CNN\n","      'two_linear_layers': False,\n","      'hidden_dim_lin': 128,  # if two_linear_layers == True\n","      'activation_function': nn.ReLU,\n","      'kernel_size': 3,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001,  # CHANGE: if no layer-wise lr\n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'save_best': False,\n","      'save_checkpoints': False,\n","      'is_cnn': True,\n","      'is_debug': False,\n","      'classification_report_flag': False,\n","      'batch_size':4096,\n","      # DATASET PARAMS\n","      'pre_train_classes': [0, 1, 2, 3, 4, 6, 8],\n","      'fine_tune_classes': [5, 7, 9],\n","      'val_split': 0.1,\n","      'num_workers': 0,\n","      'generate_dataset_seed': 42,\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': True,   # CHANGE\n","      'pooling_every_n_layers': 2, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n","      # default value for pooling_every_n_layers is 1 (after each cnn layer)\n","      'pooling_stride': 2,\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': False,         # CHANGE: reinit the conv lyers only after the cut\n","      'reinit_both_dense': True   # CHANGE: True for reinitialize both dense layers, False for reinit only the last dense layer\n","    }"]},{"cell_type":"code","execution_count":5,"metadata":{"metadata":{}},"outputs":[],"source":["root_dir = './data'  # Specify your data directory here\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","dataloader_wrapped = TransferLearningWrapper(params, datasets.FashionMNIST, datasets.FashionMNIST, root_dir, transform=transform)## Pretraining"]},{"cell_type":"code","execution_count":6,"metadata":{"metadata":{}},"outputs":[{"data":{"text/plain":["37800"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dataloader_wrapped.pretrain_train_loader.dataset.__len__()"]},{"cell_type":"markdown","metadata":{},"source":["## Pretraining"]},{"cell_type":"code","execution_count":7,"metadata":{"metadata":{}},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act5): ReLU()\n","  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc): Linear(in_features=576, out_features=7, bias=True)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#Create DNN model\n","pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","metadata":{},"outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 35.97%\n","Validation Accuracy: 36.63%\n","Epoch: 1 \tTraining Accuracy: 59.17%\n","Validation Accuracy: 59.93%\n","Epoch: 2 \tTraining Accuracy: 69.57%\n","Validation Accuracy: 69.97%\n","Epoch: 3 \tTraining Accuracy: 76.40%\n","Validation Accuracy: 76.27%\n","Epoch: 4 \tTraining Accuracy: 79.24%\n","Validation Accuracy: 79.20%\n","Epoch: 5 \tTraining Accuracy: 79.97%\n","Validation Accuracy: 79.83%\n","Epoch: 6 \tTraining Accuracy: 78.35%\n","Validation Accuracy: 78.00%\n","Epoch: 7 \tTraining Accuracy: 82.17%\n","Validation Accuracy: 82.20%\n","Epoch: 8 \tTraining Accuracy: 83.48%\n","Validation Accuracy: 83.03%\n","Epoch: 9 \tTraining Accuracy: 83.65%\n","Validation Accuracy: 82.93%\n","Epoch: 10 \tTraining Accuracy: 84.15%\n","Validation Accuracy: 83.87%\n","Epoch: 11 \tTraining Accuracy: 84.84%\n","Validation Accuracy: 84.03%\n","Epoch: 12 \tTraining Accuracy: 85.16%\n","Validation Accuracy: 84.83%\n","Epoch: 13 \tTraining Accuracy: 85.78%\n","Validation Accuracy: 85.33%\n","Epoch: 14 \tTraining Accuracy: 86.27%\n","Validation Accuracy: 85.90%\n","Epoch: 15 \tTraining Accuracy: 86.53%\n","Validation Accuracy: 86.17%\n","Epoch: 16 \tTraining Accuracy: 86.79%\n","Validation Accuracy: 86.60%\n","Epoch: 17 \tTraining Accuracy: 87.10%\n","Validation Accuracy: 86.63%\n","Epoch: 18 \tTraining Accuracy: 87.24%\n","Validation Accuracy: 86.70%\n","Epoch: 19 \tTraining Accuracy: 87.77%\n","Validation Accuracy: 87.63%\n","Epoch: 20 \tTraining Accuracy: 87.26%\n","Validation Accuracy: 87.63%\n","Epoch: 21 \tTraining Accuracy: 88.08%\n","Validation Accuracy: 87.80%\n","Epoch: 22 \tTraining Accuracy: 87.80%\n","Validation Accuracy: 87.77%\n","Epoch: 23 \tTraining Accuracy: 88.02%\n","Validation Accuracy: 88.20%\n","Epoch: 24 \tTraining Accuracy: 88.96%\n","Validation Accuracy: 88.97%\n","Epoch: 25 \tTraining Accuracy: 88.87%\n","Validation Accuracy: 88.53%\n","Epoch: 26 \tTraining Accuracy: 88.94%\n","Validation Accuracy: 88.77%\n","Epoch: 27 \tTraining Accuracy: 89.42%\n","Validation Accuracy: 89.87%\n","Epoch: 28 \tTraining Accuracy: 89.82%\n","Validation Accuracy: 89.87%\n","Epoch: 29 \tTraining Accuracy: 90.07%\n","Validation Accuracy: 89.77%\n","Epoch: 30 \tTraining Accuracy: 89.88%\n","Validation Accuracy: 90.07%\n","Epoch: 31 \tTraining Accuracy: 89.55%\n","Validation Accuracy: 88.90%\n","Epoch: 32 \tTraining Accuracy: 90.00%\n","Validation Accuracy: 90.10%\n","Epoch: 33 \tTraining Accuracy: 90.83%\n","Validation Accuracy: 90.37%\n","Epoch: 34 \tTraining Accuracy: 91.00%\n","Validation Accuracy: 90.63%\n","Epoch: 35 \tTraining Accuracy: 91.24%\n","Validation Accuracy: 90.97%\n","Epoch: 36 \tTraining Accuracy: 91.13%\n","Validation Accuracy: 90.80%\n","Epoch: 37 \tTraining Accuracy: 91.55%\n","Validation Accuracy: 91.07%\n","Epoch: 38 \tTraining Accuracy: 91.48%\n","Validation Accuracy: 91.40%\n","Epoch: 39 \tTraining Accuracy: 91.56%\n","Validation Accuracy: 90.97%\n","Final Training Accuracy: 0.9156\n","Final Test Accuracy: 0.9150\n"]}],"source":["# Train and evaluate - Skip if loading saved model!\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["torch.save(pretrained_model.state_dict(), 'pretrained_models/pretrained_cifar_arc/pretrained_model_toshoes.pth')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act5): ReLU()\n","  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc): Linear(in_features=576, out_features=7, bias=True)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model.load_state_dict(torch.load('pretrained_models/pretrained_cifar_arc/pretrained_model_toshoes.pth'))\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"metadata":{}},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.3543, Accuracy: 3679.0/4200 (88%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.84      0.86      0.85       560\n","     Class 1       0.99      0.97      0.98       638\n","     Class 2       0.85      0.86      0.86       595\n","     Class 3       0.86      0.94      0.90       615\n","     Class 4       0.82      0.83      0.82       579\n","     Class 5       0.80      0.69      0.74       626\n","     Class 6       0.98      0.98      0.98       587\n","\n","    accuracy                           0.88      4200\n","   macro avg       0.87      0.88      0.87      4200\n","weighted avg       0.88      0.88      0.87      4200\n","\n"]},{"data":{"text/plain":["0.8759523809523809"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.val_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# save model for later use\n","foldername = \"pretrained_models/pretrained_normal_classes_new\"\n","os.mkdir(foldername)\n","torch.save(pretrained_model.state_dict(), os.path.join(foldername, 'pretrained_model.pth'))\n","\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","#save params as well\n","with open(os.path.join(foldername, 'params.json'), 'w') as fp:\n","    json.dump(params_tmp, fp)"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"markdown","metadata":{},"source":["### Baselines (End-to-end models trained on subsets of fine-tuning dataset)\n","We also reuse the baselines a lot! so skip if we already have the jsons"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["baselines_results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 0\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-4e7c4f54b795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Reduce the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtrain_loader_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_percentage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/mp-tl-study/functions/utils.py\u001b[0m in \u001b[0;36mreduce_dataset\u001b[0;34m(dataloader, percentage, balanced, seed)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;31m# Extract all data and labels from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;31m# Set the seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/mp-tl-study/functions/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;31m# Extract all data and labels from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;31m# Set the seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/mp-tl-study/functions/utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Transform the label using the fitted label encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:      \n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","    \n","    for repeat in range(repeats):\n","        # Print or log the sampled values for transparency\n","        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","        # Reduce the dataset\n","        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        torch.manual_seed(repeat)\n","        #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","        params_tmp = copy.deepcopy(params)\n","        params_tmp[\"reinit\"] = True\n","        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n","        model_new.to(device)\n","\n","        # Train and evaluate\n","        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","        # Store the results\n","        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(baselines_results)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# save baseline results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + baselines_results\n","\n","with open(f'results_jsons/baselines_freeze_{params[\"freeze\"]}_pool_{params[\"use_pooling\"]}_truncate_{params[\"truncate\"]}.json', 'w') as f:\n","    json.dump(results, f)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["results = []\n","#percentages = [0.001, 0.01, 0.1, 0.5, 1.0]\n","percentages = [0.5]\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9416, Test Accuracy: 0.9387\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9484, Test Accuracy: 0.9459\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9542, Test Accuracy: 0.9552\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9285, Test Accuracy: 0.9269\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9389, Test Accuracy: 0.9398\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9410, Test Accuracy: 0.9386\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9459, Test Accuracy: 0.9436\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9551, Test Accuracy: 0.9571\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9306, Test Accuracy: 0.9291\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9404, Test Accuracy: 0.9402\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.8552, Test Accuracy: 0.8557\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9409, Test Accuracy: 0.9392\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9527, Test Accuracy: 0.9554\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9412, Test Accuracy: 0.9386\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9349, Test Accuracy: 0.9349\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9443, Test Accuracy: 0.9413\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9409, Test Accuracy: 0.9390\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9547, Test Accuracy: 0.9557\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9370, Test Accuracy: 0.9359\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9354, Test Accuracy: 0.9354\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9336, Test Accuracy: 0.9334\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9390, Test Accuracy: 0.9361\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9527, Test Accuracy: 0.9536\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9273, Test Accuracy: 0.9251\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9331, Test Accuracy: 0.9328\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9341, Test Accuracy: 0.9326\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9331, Test Accuracy: 0.9312\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9495, Test Accuracy: 0.9501\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9227, Test Accuracy: 0.9212\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9321, Test Accuracy: 0.9322\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9051, Test Accuracy: 0.9065\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9167, Test Accuracy: 0.9145\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9264, Test Accuracy: 0.9286\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8915, Test Accuracy: 0.8896\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.8920, Test Accuracy: 0.8941\n"]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 0, 'train_acc': 0.941604938271605, 'test_acc': 0.9386666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 1, 'train_acc': 0.948395061728395, 'test_acc': 0.9459444444444445}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 2, 'train_acc': 0.9541975308641976, 'test_acc': 0.9552222222222222}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 3, 'train_acc': 0.9285185185185185, 'test_acc': 0.9268888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 4, 'train_acc': 0.9388888888888889, 'test_acc': 0.9398333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 0, 'train_acc': 0.9409876543209876, 'test_acc': 0.9385555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 1, 'train_acc': 0.945925925925926, 'test_acc': 0.9435555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 2, 'train_acc': 0.9550617283950618, 'test_acc': 0.9570555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 3, 'train_acc': 0.9306172839506173, 'test_acc': 0.9290555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 4, 'train_acc': 0.9403703703703704, 'test_acc': 0.9402222222222222}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 0, 'train_acc': 0.8551851851851852, 'test_acc': 0.8557222222222223}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 1, 'train_acc': 0.9408641975308641, 'test_acc': 0.9391666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 2, 'train_acc': 0.952716049382716, 'test_acc': 0.9553888888888888}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 3, 'train_acc': 0.9412345679012346, 'test_acc': 0.9385555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 4, 'train_acc': 0.9349382716049383, 'test_acc': 0.9349444444444445}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 0, 'train_acc': 0.944320987654321, 'test_acc': 0.9412777777777778}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 1, 'train_acc': 0.9408641975308641, 'test_acc': 0.939}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 2, 'train_acc': 0.9546913580246914, 'test_acc': 0.9556666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 3, 'train_acc': 0.937037037037037, 'test_acc': 0.9358888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 4, 'train_acc': 0.9354320987654321, 'test_acc': 0.9353888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 0, 'train_acc': 0.9335802469135802, 'test_acc': 0.9333888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 1, 'train_acc': 0.9390123456790124, 'test_acc': 0.9360555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 2, 'train_acc': 0.952716049382716, 'test_acc': 0.9536111111111111}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 3, 'train_acc': 0.927283950617284, 'test_acc': 0.9251111111111111}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 4, 'train_acc': 0.9330864197530864, 'test_acc': 0.9328333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 0, 'train_acc': 0.9340740740740741, 'test_acc': 0.9325555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 1, 'train_acc': 0.9330864197530864, 'test_acc': 0.9311666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 2, 'train_acc': 0.9495061728395062, 'test_acc': 0.9501111111111111}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 3, 'train_acc': 0.922716049382716, 'test_acc': 0.9212222222222223}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 4, 'train_acc': 0.9320987654320988, 'test_acc': 0.9322222222222222}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 0, 'train_acc': 0.9050617283950617, 'test_acc': 0.9065}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 1, 'train_acc': 0.9166666666666666, 'test_acc': 0.9145}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 2, 'train_acc': 0.9264197530864198, 'test_acc': 0.9285555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 3, 'train_acc': 0.8914814814814814, 'test_acc': 0.8895555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 4, 'train_acc': 0.8919753086419753, 'test_acc': 0.8941111111111111}]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 0, 'train_acc': 0.941604938271605, 'test_acc': 0.9386666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 1, 'train_acc': 0.948395061728395, 'test_acc': 0.9459444444444445}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 2, 'train_acc': 0.9541975308641976, 'test_acc': 0.9552222222222222}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 3, 'train_acc': 0.9285185185185185, 'test_acc': 0.9268888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 4, 'train_acc': 0.9388888888888889, 'test_acc': 0.9398333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 0, 'train_acc': 0.9409876543209876, 'test_acc': 0.9385555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 1, 'train_acc': 0.945925925925926, 'test_acc': 0.9435555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 2, 'train_acc': 0.9550617283950618, 'test_acc': 0.9570555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 3, 'train_acc': 0.9306172839506173, 'test_acc': 0.9290555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 4, 'train_acc': 0.9403703703703704, 'test_acc': 0.9402222222222222}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 0, 'train_acc': 0.8551851851851852, 'test_acc': 0.8557222222222223}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 1, 'train_acc': 0.9408641975308641, 'test_acc': 0.9391666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 2, 'train_acc': 0.952716049382716, 'test_acc': 0.9553888888888888}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 3, 'train_acc': 0.9412345679012346, 'test_acc': 0.9385555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 4, 'train_acc': 0.9349382716049383, 'test_acc': 0.9349444444444445}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 0, 'train_acc': 0.944320987654321, 'test_acc': 0.9412777777777778}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 1, 'train_acc': 0.9408641975308641, 'test_acc': 0.939}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 2, 'train_acc': 0.9546913580246914, 'test_acc': 0.9556666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 3, 'train_acc': 0.937037037037037, 'test_acc': 0.9358888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 4, 'train_acc': 0.9354320987654321, 'test_acc': 0.9353888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 0, 'train_acc': 0.9335802469135802, 'test_acc': 0.9333888888888889}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 1, 'train_acc': 0.9390123456790124, 'test_acc': 0.9360555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 2, 'train_acc': 0.952716049382716, 'test_acc': 0.9536111111111111}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 3, 'train_acc': 0.927283950617284, 'test_acc': 0.9251111111111111}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 4, 'train_acc': 0.9330864197530864, 'test_acc': 0.9328333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 0, 'train_acc': 0.9340740740740741, 'test_acc': 0.9325555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 1, 'train_acc': 0.9330864197530864, 'test_acc': 0.9311666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 2, 'train_acc': 0.9495061728395062, 'test_acc': 0.9501111111111111}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 3, 'train_acc': 0.922716049382716, 'test_acc': 0.9212222222222223}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 4, 'train_acc': 0.9320987654320988, 'test_acc': 0.9322222222222222}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 0, 'train_acc': 0.9050617283950617, 'test_acc': 0.9065}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 1, 'train_acc': 0.9166666666666666, 'test_acc': 0.9145}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 2, 'train_acc': 0.9264197530864198, 'test_acc': 0.9285555555555556}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 3, 'train_acc': 0.8914814814814814, 'test_acc': 0.8895555555555555}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 4, 'train_acc': 0.8919753086419753, 'test_acc': 0.8941111111111111}]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# save fine-tuning results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/results_freeze_{params[\"freeze\"]}_reinit_{params[\"reinit\"]}_pool_{params[\"use_pooling\"]}_truncate_{params[\"truncate\"]}.json', 'w') as f:\n","    json.dump(results, f)\n","results = results[1:]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}

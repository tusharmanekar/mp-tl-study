{"cells":[{"cell_type":"markdown","metadata":{"id":"Tnr5Tf1Qa1H-"},"source":["# Example for:\n","Transfer Learning Empirical Experiment from all 10 classes of FashionMNIST into all 10 classes of MNIST "]},{"cell_type":"markdown","metadata":{},"source":["### Setup and Hyperparams"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Specify which gpu\n","import os\n","gpu_id = 1\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","\n","import sys\n","sys.path.append('/home/arnisaf/mp-tl-study')\n","from functions.utils import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(0)\n","    torch.cuda.manual_seed_all(0)  # if using multi-GPU"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3,4,5,6]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 6,\n","      'num_channels': 64, # num channels for CNN\n","      'two_linear_layers': False,\n","      'hidden_dim_lin': 128,  # if two_linear_layers == True\n","      'activation_function': nn.ReLU,\n","      'kernel_size': 3,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001,  # CHANGE: if no layer-wise lr\n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'save_best': False,\n","      'save_checkpoints': False,\n","      'is_cnn': True,\n","      'is_debug': False,\n","      'classification_report_flag': False,\n","      'batch_size':4096,\n","      # DATASET PARAMS\n","      'pre_train_classes': [0, 1, 2, 4, 6, 7, 9],\n","      'fine_tune_classes': [3, 5, 8],\n","      'val_split': 0.1,\n","      'num_workers': 0,\n","      'generate_dataset_seed': 42,\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': True,   # CHANGE\n","      'pooling_every_n_layers': 2, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n","      # default value for pooling_every_n_layers is 1 (after each cnn layer)\n","      'pooling_stride': 2,\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': True,         # CHANGE: reinit the conv lyers only after the cut\n","      'reinit_both_dense': True   # CHANGE: True for reinitialize both dense layers, False for reinit only the last dense layer\n","    }"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 6,\n","      'num_channels': 64,\n","      'kernel_size': 3,\n","      'activation_function': nn.ReLU,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001, \n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'batch_size':4096,\n","      # DATASET PARAMS\n","      'pre_train_classes': list(range(10)),\n","      'fine_tune_classes': list(range(10)),\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': True,   # CHANGE\n","      'pooling_every_n_layers': 2, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n","      # default value for pooling_every_n_layers is 1 (after each cnn layer)\n","      'pooling_stride': 2,\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': True         # CHANGE: reinit the conv lyers only after the cut\n","      }"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["root_dir = './data'  # Specify your data directory here\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","dataloader_wrapped = TransferLearningWrapper(params, datasets.FashionMNIST, datasets.MNIST, root_dir, transform=transform)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["54000"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["dataloader_wrapped.pretrain_train_loader.dataset.__len__()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["50"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_loader_reduced = reduce_dataset(dataloader_wrapped.finetune_train_loader, 0.001, seed = 0)\n","train_loader_reduced.dataset.__len__()"]},{"cell_type":"markdown","metadata":{},"source":["## Pretraining"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act5): ReLU()\n","  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc): Linear(in_features=576, out_features=10, bias=True)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["#Create DNN model\n","pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 50.89%\n","Validation Accuracy: 50.18%\n","Epoch: 1 \tTraining Accuracy: 66.44%\n","Validation Accuracy: 65.82%\n","Epoch: 2 \tTraining Accuracy: 73.80%\n","Validation Accuracy: 73.12%\n","Epoch: 3 \tTraining Accuracy: 74.74%\n","Validation Accuracy: 74.50%\n","Epoch: 4 \tTraining Accuracy: 74.98%\n","Validation Accuracy: 74.92%\n","Epoch: 5 \tTraining Accuracy: 76.63%\n","Validation Accuracy: 76.57%\n","Epoch: 6 \tTraining Accuracy: 77.45%\n","Validation Accuracy: 77.40%\n","Epoch: 7 \tTraining Accuracy: 78.08%\n","Validation Accuracy: 77.83%\n","Epoch: 8 \tTraining Accuracy: 78.84%\n","Validation Accuracy: 78.67%\n","Epoch: 9 \tTraining Accuracy: 79.90%\n","Validation Accuracy: 79.78%\n","Epoch: 10 \tTraining Accuracy: 81.09%\n","Validation Accuracy: 80.85%\n","Epoch: 11 \tTraining Accuracy: 82.20%\n","Validation Accuracy: 81.83%\n","Epoch: 12 \tTraining Accuracy: 82.57%\n","Validation Accuracy: 82.25%\n","Epoch: 13 \tTraining Accuracy: 82.78%\n","Validation Accuracy: 82.53%\n","Epoch: 14 \tTraining Accuracy: 79.65%\n","Validation Accuracy: 79.30%\n","Epoch: 15 \tTraining Accuracy: 83.08%\n","Validation Accuracy: 82.82%\n","Epoch: 16 \tTraining Accuracy: 83.87%\n","Validation Accuracy: 83.80%\n","Epoch: 17 \tTraining Accuracy: 84.86%\n","Validation Accuracy: 84.55%\n","Epoch: 18 \tTraining Accuracy: 84.62%\n","Validation Accuracy: 84.32%\n","Epoch: 19 \tTraining Accuracy: 86.26%\n","Validation Accuracy: 85.90%\n","Epoch: 20 \tTraining Accuracy: 85.68%\n","Validation Accuracy: 85.37%\n","Epoch: 21 \tTraining Accuracy: 86.66%\n","Validation Accuracy: 86.25%\n","Epoch: 22 \tTraining Accuracy: 84.68%\n","Validation Accuracy: 84.28%\n","Epoch: 23 \tTraining Accuracy: 87.23%\n","Validation Accuracy: 86.58%\n","Epoch: 24 \tTraining Accuracy: 87.71%\n","Validation Accuracy: 87.08%\n","Epoch: 25 \tTraining Accuracy: 87.54%\n","Validation Accuracy: 87.07%\n","Epoch: 26 \tTraining Accuracy: 87.40%\n","Validation Accuracy: 86.60%\n","Epoch: 27 \tTraining Accuracy: 87.83%\n","Validation Accuracy: 87.55%\n","Epoch: 28 \tTraining Accuracy: 87.69%\n","Validation Accuracy: 87.30%\n","Epoch: 29 \tTraining Accuracy: 88.17%\n","Validation Accuracy: 87.55%\n","Epoch: 30 \tTraining Accuracy: 88.20%\n","Validation Accuracy: 87.55%\n","Epoch: 31 \tTraining Accuracy: 88.24%\n","Validation Accuracy: 87.68%\n","Epoch: 32 \tTraining Accuracy: 88.71%\n","Validation Accuracy: 87.83%\n","Epoch: 33 \tTraining Accuracy: 88.46%\n","Validation Accuracy: 87.72%\n","Epoch: 34 \tTraining Accuracy: 88.18%\n","Validation Accuracy: 87.97%\n","Epoch: 35 \tTraining Accuracy: 89.24%\n","Validation Accuracy: 88.52%\n","Epoch: 36 \tTraining Accuracy: 89.14%\n","Validation Accuracy: 88.05%\n","Epoch: 37 \tTraining Accuracy: 89.42%\n","Validation Accuracy: 88.45%\n","Epoch: 38 \tTraining Accuracy: 89.71%\n","Validation Accuracy: 88.92%\n","Epoch: 39 \tTraining Accuracy: 89.94%\n","Validation Accuracy: 89.17%\n","Final Training Accuracy: 0.8994\n","Final Test Accuracy: 0.8986\n"]}],"source":["# Train and evaluate - Skip if loading saved model!\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["torch.save(pretrained_model.state_dict(), 'pretrained_models/pretrained_model_only_fashion_new.pth')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act5): ReLU()\n","  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc): Linear(in_features=576, out_features=10, bias=True)\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model.load_state_dict(torch.load('pretrained_models/pretrained_model_only_fashion_new.pth'))\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.3068, Accuracy: 5350.0/6000 (89%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.84      0.81      0.83       658\n","     Class 1       0.99      0.99      0.99       611\n","     Class 2       0.83      0.88      0.86       612\n","     Class 3       0.84      0.91      0.88       562\n","     Class 4       0.86      0.81      0.83       607\n","     Class 5       0.96      0.97      0.96       613\n","     Class 6       0.74      0.70      0.72       600\n","     Class 7       0.94      0.95      0.94       537\n","     Class 8       0.96      0.96      0.96       598\n","     Class 9       0.97      0.95      0.96       602\n","\n","    accuracy                           0.89      6000\n","   macro avg       0.89      0.89      0.89      6000\n","weighted avg       0.89      0.89      0.89      6000\n","\n"]},{"data":{"text/plain":["0.8916666666666667"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.val_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# save model for later use\n","foldername = \"pretrained_models/pretrained_Fashion_all_classes\"\n","os.mkdir(foldername)\n","torch.save(pretrained_model.state_dict(), os.path.join(foldername, 'pretrained_model.pth'))\n","\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","#save params as well\n","with open(os.path.join(foldername, 'params.json'), 'w') as fp:\n","    json.dump(params_tmp, fp)"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"markdown","metadata":{},"source":["### Baselines (End-to-end models trained on subsets of fine-tuning dataset)\n","We also reuse the baselines a lot! so skip if we already have the jsons"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["baselines_results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 0\n"]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:      \n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","    \n","    for repeat in range(repeats):\n","        # Print or log the sampled values for transparency\n","        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","        # Reduce the dataset\n","        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        torch.manual_seed(repeat)\n","        #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","        params_tmp = copy.deepcopy(params)\n","        params_tmp[\"reinit\"] = True\n","        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n","        model_new.to(device)\n","\n","        # Train and evaluate\n","        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","        # Store the results\n","        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(baselines_results)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# save baseline results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + baselines_results\n","\n","with open(f'results_jsons/baselines_freeze_{params[\"freeze\"]}_pool_{params[\"use_pooling\"]}_truncate_{params[\"truncate\"]}.json', 'w') as f:\n","    json.dump(results, f)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# save fine-tuning results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/results_freeze_{params[\"freeze\"]}_reinit_{params[\"reinit\"]}_pool_{params[\"use_pooling\"]}_truncate_{params[\"truncate\"]}.json', 'w') as f:\n","    json.dump(results, f)\n","results = results[1:]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}

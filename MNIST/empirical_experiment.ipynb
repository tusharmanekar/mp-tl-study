{"cells":[{"cell_type":"markdown","metadata":{"id":"Tnr5Tf1Qa1H-"},"source":["# Example for:\n","Transfer Learning Empirical Experiment from first 5 classes of MNIST into final 5 classes of MNIST\n","- Almost all the details about optimizers, training, lr, ... are in the params dict!\n","- And all experiment design details too! reinit, freeze, .."]},{"cell_type":"markdown","metadata":{},"source":["### Setup and Hyperparams"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Specify which gpu\n","import os\n","gpu_id = 1\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","\n","import sys\n","sys.path.append('/home/arnisaf/mp-tl-study')\n","from functions.utils import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(0)\n","    torch.cuda.manual_seed_all(0)  # if using multi-GPU"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:41.121611Z","iopub.status.busy":"2023-11-12T15:26:41.121288Z","iopub.status.idle":"2023-11-12T15:26:47.333420Z","shell.execute_reply":"2023-11-12T15:26:47.332577Z","shell.execute_reply.started":"2023-11-12T15:26:41.121585Z"},"id":"L0eJ0XYWQHS6","trusted":true},"outputs":[],"source":["# We overwrite the CustomCNN module and  from utils.py to add another linear layer at the end\n","class CustomCNN(nn.Module):\n","    def __init__(self, params, output_dim):\n","        super(CustomCNN, self).__init__()\n","\n","        # Initial number of input channels, assuming grayscale images\n","        in_channels = 1\n","\n","        # Dynamically add convolutional and activation layers based on the specified depth\n","        for i in range(params[\"depth\"]):\n","            # Create a convolutional layer and add it to the model\n","            setattr(self, f\"conv{i}\", nn.Conv2d(in_channels, params[\"num_channels\"], kernel_size=params[\"kernel_size\"], padding=math.floor(params[\"kernel_size\"]/2)))\n","\n","            # Create an activation layer (e.g., ReLU) and add it to the model\n","            setattr(self, f\"act{i}\", params[\"activation_function\"]())\n","\n","            \n","            # Optionally add pooling layers to reduce spatial dimensions\n","            if params[\"use_pooling\"] and (i+1) % params[\"pooling_every_n_layers\"] == 0:\n","                setattr(self, f\"pool{i}\", nn.AvgPool2d(2, stride=params['pooling_stride']))\n","\n","            # Update the input channels for the next convolutional layer\n","            in_channels = params[\"num_channels\"]\n","\n","        # Compute the size of the flattened features for the fully connected layer\n","        self.calculate_to_linear_size()\n","\n","        # Add one fully connected layers for classification\n","        self.fc = nn.Linear(self._to_linear, params[\"hidden_dim_lin\"])\n","        self.act = params[\"activation_function\"]()\n","        self.fc_2 = nn.Linear(params[\"hidden_dim_lin\"], output_dim)\n","\n","    # calculate the input dimensions to the fully-connecting layer by forwarding a dummy input\n","    def calculate_to_linear_size(self):\n","        x = torch.zeros(1, 1, 28, 28)\n","        for layer_name, layer in self.named_children():\n","            # Process the input tensor through convolutional and activation layers\n","            if \"conv\" in layer_name or \"act\" in layer_name:\n","                x = layer(x)\n","            # Process the input tensor through pooling layers if they exist\n","            elif \"pool\" in layer_name:\n","                x = layer(x)\n","            # If reached fully connected layers, break the loop\n","            elif isinstance(layer, nn.Linear):\n","                break\n","        self._to_linear = x.view(x.size(0), -1).size(1)\n","\n","    def forward(self, x):\n","        # Iterate over each module in the CustomCNN class\n","        for layer_name, layer in self.named_children():\n","            # Process the input tensor through convolutional and activation layers\n","            if \"conv\" in layer_name or \"act\" in layer_name:\n","                x = layer(x)\n","            # Process the input tensor through pooling layers if they exist\n","            elif \"pool\" in layer_name:\n","                x = layer(x)\n","            # If reached fully connected layers, break the loop\n","            elif isinstance(layer, nn.Linear):\n","                break\n","\n","        x = x.view(-1, self._to_linear) # Flatten\n","        x = self.fc(x)\n","        x = self.act(x)\n","        x = self.fc_2(x)\n","        return F.log_softmax(x, dim=1)\n","    \n","def cut_custom_cnn_model(model, cut_point, params, output_dim):\n","    \"\"\"\n","    Cut the CustomCNN model at a specific layer and reinitialize the weights for layers after cut_point.\n","\n","    Parameters:\n","    - model (CustomCNN): Original CustomCNN model.\n","    - cut_point (int): Layer index (in terms of conv layers) at which to modify the model.\n","    - freeze (bool): If True, layers before cut_point will have their weights frozen (from params)\n","    - reinitialize (bool): If True, layers after cut_point will have their weights reinitialized (from params)\n","    - output_dim (int): for the final linear layer that is used for classification\n","\n","    Returns:\n","    - new_model (CustomCNN): Modified model.\n","    \"\"\"\n","\n","    new_model = copy.deepcopy(model).to(\"cpu\")\n","\n","    # Get names of layers in the model\n","    layer_names = list(new_model._modules.keys())\n","\n","    # Find indices of Conv layers\n","    conv_indices = [i for i, name in enumerate(layer_names) if 'conv' in name]\n","    #print(conv_indices)\n","\n","    # If freeze is True, set requires_grad to False for layers before cut_point\n","    if params[\"freeze\"]:\n","        for idx in conv_indices[:cut_point]:\n","            for param in getattr(new_model, layer_names[idx]).parameters():\n","                param.requires_grad = False\n","\n","    for idx in conv_indices[cut_point:]:\n","        layer = getattr(new_model, layer_names[idx])\n","\n","        # Reinitialize layers after cut_point\n","        if params[\"reinit\"]:\n","            layer.reset_parameters()\n","            \"\"\"\n","            nn.init.kaiming_uniform_(layer.weight, a=0, mode='fan_in', nonlinearity='relu')\n","            if layer.bias is not None:\n","                nn.init.constant_(layer.bias, 0)\n","            \"\"\"\n","\n","        # Delete the layers after cut_point\n","        if params[\"truncate\"]:\n","            delattr(new_model, layer_names[idx])\n","            # also delete the activation after this conv layer\n","            delattr(new_model, layer_names[idx+1])\n","\n","    \"\"\"# if reinit_both_dense: reinit the one before the last one too\n","    if params[\"reinit_both_dense\"]:\n","        new_model.fc_1.reset_parameters()\"\"\"\n","\n","    # reinit the final dense layer anyway\n","    # new_model.fc.reset_parameters()\n","    new_model.calculate_to_linear_size()\n","    new_model.fc = nn.Linear(new_model._to_linear, params[\"hidden_dim_lin\"])\n","    new_model.act = params[\"activation_function\"]()\n","    new_model.fc_2 = nn.Linear(params[\"hidden_dim_lin\"], output_dim)\n","    \n","    return new_model"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:47.336625Z","iopub.status.busy":"2023-11-12T15:26:47.335716Z","iopub.status.idle":"2023-11-12T15:26:47.341905Z","shell.execute_reply":"2023-11-12T15:26:47.340983Z","shell.execute_reply.started":"2023-11-12T15:26:47.336587Z"},"id":"FeWfmLUgswad","trusted":true},"outputs":[],"source":["# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 3,\n","      'num_channels': 10, # num channels for CNN\n","      'two_linear_layers': True,\n","      'hidden_dim_lin': 128,  # if two_linear_layers == True\n","      'activation_function': nn.ReLU,\n","      'kernel_size': 5,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001,  # CHANGE: if no layer-wise lr\n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'save_best': False,\n","      'save_checkpoints': False,\n","      'is_cnn': True,\n","      'is_debug': False,\n","      'classification_report_flag': False,\n","      'batch_size':4096,\n","      # DATASET PARAMS\n","      'pre_train_classes': [0, 1, 2, 3, 4],\n","      'fine_tune_classes': [5, 6, 7, 8, 9],\n","      'val_split': 0.1,\n","      'num_workers': 0,\n","      'generate_dataset_seed': 42,\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': False,   # CHANGE\n","      'pooling_every_n_layers': 5, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n","      'pooling_stride': 2,\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': True,         # CHANGE: reinit the conv lyers only after the cut\n","      'reinit_both_dense': True   # CHANGE: True for reinitialize both dense layers, False for reinit only the last dense layer\n","    }"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["root_dir = './data'  # Specify your data directory here\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","dataloader_wrapped = TransferLearningWrapper(params, datasets.MNIST, datasets.MNIST, root_dir, transform=transform)"]},{"cell_type":"markdown","metadata":{"id":"UbrS0kwrcHfE"},"source":["## Pretraining"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act0): ReLU()\n","  (conv1): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act1): ReLU()\n","  (conv2): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act2): ReLU()\n","  (fc): Linear(in_features=7840, out_features=128, bias=True)\n","  (act): ReLU()\n","  (fc_2): Linear(in_features=128, out_features=5, bias=True)\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#Create DNN model\n","pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 87.43%\n","Validation Accuracy: 86.66%\n","Epoch: 1 \tTraining Accuracy: 90.49%\n","Validation Accuracy: 90.19%\n","Epoch: 2 \tTraining Accuracy: 94.37%\n","Validation Accuracy: 93.43%\n","Epoch: 3 \tTraining Accuracy: 95.61%\n","Validation Accuracy: 94.80%\n","Epoch: 4 \tTraining Accuracy: 96.28%\n","Validation Accuracy: 95.52%\n","Epoch: 5 \tTraining Accuracy: 96.64%\n","Validation Accuracy: 96.11%\n","Epoch: 6 \tTraining Accuracy: 97.09%\n","Validation Accuracy: 96.31%\n","Epoch: 7 \tTraining Accuracy: 97.58%\n","Validation Accuracy: 97.03%\n","Epoch: 8 \tTraining Accuracy: 97.88%\n","Validation Accuracy: 97.19%\n","Epoch: 9 \tTraining Accuracy: 98.03%\n","Validation Accuracy: 97.38%\n","Epoch: 10 \tTraining Accuracy: 98.39%\n","Validation Accuracy: 97.61%\n","Epoch: 11 \tTraining Accuracy: 98.51%\n","Validation Accuracy: 97.94%\n","Epoch: 12 \tTraining Accuracy: 98.61%\n","Validation Accuracy: 97.94%\n","Epoch: 13 \tTraining Accuracy: 98.76%\n","Validation Accuracy: 98.23%\n","Epoch: 14 \tTraining Accuracy: 98.87%\n","Validation Accuracy: 98.27%\n","Epoch: 15 \tTraining Accuracy: 99.04%\n","Validation Accuracy: 98.59%\n","Epoch: 16 \tTraining Accuracy: 99.12%\n","Validation Accuracy: 98.53%\n","Epoch: 17 \tTraining Accuracy: 99.13%\n","Validation Accuracy: 98.63%\n","Epoch: 18 \tTraining Accuracy: 99.30%\n","Validation Accuracy: 98.76%\n","Epoch: 19 \tTraining Accuracy: 99.31%\n","Validation Accuracy: 98.79%\n","Epoch: 20 \tTraining Accuracy: 99.44%\n","Validation Accuracy: 99.02%\n","Epoch: 21 \tTraining Accuracy: 99.43%\n","Validation Accuracy: 99.02%\n","Epoch: 22 \tTraining Accuracy: 99.46%\n","Validation Accuracy: 98.99%\n","Epoch: 23 \tTraining Accuracy: 99.48%\n","Validation Accuracy: 99.12%\n","Epoch: 24 \tTraining Accuracy: 99.52%\n","Validation Accuracy: 99.08%\n","Epoch: 25 \tTraining Accuracy: 99.54%\n","Validation Accuracy: 99.08%\n","Epoch: 26 \tTraining Accuracy: 99.59%\n","Validation Accuracy: 99.15%\n","Epoch: 27 \tTraining Accuracy: 99.55%\n","Validation Accuracy: 99.12%\n","Epoch: 28 \tTraining Accuracy: 99.64%\n","Validation Accuracy: 99.28%\n","Epoch: 29 \tTraining Accuracy: 99.60%\n","Validation Accuracy: 99.05%\n","Epoch: 30 \tTraining Accuracy: 99.65%\n","Validation Accuracy: 99.18%\n","Epoch: 31 \tTraining Accuracy: 99.70%\n","Validation Accuracy: 99.15%\n","Epoch: 32 \tTraining Accuracy: 99.74%\n","Validation Accuracy: 99.25%\n","Epoch: 33 \tTraining Accuracy: 99.63%\n","Validation Accuracy: 99.12%\n","Epoch: 34 \tTraining Accuracy: 99.63%\n","Validation Accuracy: 99.28%\n","Early stopping invoked.\n","Final Training Accuracy: 0.9964\n","Final Test Accuracy: 0.9961\n"]}],"source":["# Train and evaluate\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act0): ReLU()\n","  (conv1): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act1): ReLU()\n","  (conv2): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (act2): ReLU()\n","  (fc_1): Linear(in_features=7840, out_features=128, bias=True)\n","  (act): ReLU()\n","  (fc_2): Linear(in_features=128, out_features=5, bias=True)\n",")"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model.load_state_dict(torch.load('pretrained_models/pretrained_mnist_final/pretrained_model.pth'))\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.0220, Accuracy: 3037.0/3059 (99%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       1.00      1.00      1.00       544\n","     Class 1       1.00      0.99      0.99       670\n","     Class 2       0.98      0.99      0.99       631\n","     Class 3       0.99      0.99      0.99       613\n","     Class 4       1.00      1.00      1.00       601\n","\n","    accuracy                           0.99      3059\n","   macro avg       0.99      0.99      0.99      3059\n","weighted avg       0.99      0.99      0.99      3059\n","\n"]},{"data":{"text/plain":["0.9928081072245832"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.val_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# save model for later use\n","foldername = \"pretrained_models/pretrained_mnist_final\"\n","os.mkdir(foldername)\n","torch.save(pretrained_model.state_dict(), os.path.join(foldername, 'pretrained_model.pth'))\n","\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","#save params as well\n","with open(os.path.join(foldername, 'params.json'), 'w') as fp:\n","    json.dump(params_tmp, fp)"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"markdown","metadata":{},"source":["### Baselines (End-to-end models trained on subsets of fine-tuning dataset)\n","We also reuse the baselines a lot! so skip if we already have the jsons"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["baselines_results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.8667, Test Accuracy: 0.8100\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.9333, Test Accuracy: 0.7890\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.9333, Test Accuracy: 0.8080\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.8667, Test Accuracy: 0.8120\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.9333, Test Accuracy: 0.8063\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.9667, Test Accuracy: 0.8487\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.8667, Test Accuracy: 0.8003\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 2\n","Early stopping invoked.\n","Training Accuracy: 0.8667, Test Accuracy: 0.8033\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.9000, Test Accuracy: 0.8470\n","\n","Sampled Percentage: 0.002, Lr: 0.001, Repeat: 4\n","Training Accuracy: 1.0000, Test Accuracy: 0.8337\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 0\n","Training Accuracy: 1.0000, Test Accuracy: 0.8680\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.9012, Test Accuracy: 0.8567\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9877, Test Accuracy: 0.8653\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.8889, Test Accuracy: 0.8597\n","\n","Sampled Percentage: 0.005, Lr: 0.001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.9383, Test Accuracy: 0.8503\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.8951, Test Accuracy: 0.8380\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 1\n","Early stopping invoked.\n","Training Accuracy: 0.9198, Test Accuracy: 0.8613\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9691, Test Accuracy: 0.8927\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 3\n","Early stopping invoked.\n","Training Accuracy: 0.9012, Test Accuracy: 0.8573\n","\n","Sampled Percentage: 0.01, Lr: 0.001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.8951, Test Accuracy: 0.8667\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9235, Test Accuracy: 0.8980\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9272, Test Accuracy: 0.9077\n","\n","Sampled Percentage: 0.05, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9284, Test Accuracy: 0.9160\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9148, Test Accuracy: 0.9143\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8728, Test Accuracy: 0.8713\n","\n","Sampled Percentage: 0.1, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8969, Test Accuracy: 0.9003\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9531, Test Accuracy: 0.9447\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9558, Test Accuracy: 0.9477\n","\n","Sampled Percentage: 0.3, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9444, Test Accuracy: 0.9440\n","\n","Sampled Percentage: 0.5, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9502, Test Accuracy: 0.9463\n","\n","Sampled Percentage: 0.8, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.9624, Test Accuracy: 0.9567\n","\n","Sampled Percentage: 1, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9714, Test Accuracy: 0.9647\n"]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:      \n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","    \n","    for repeat in range(repeats):\n","        # Print or log the sampled values for transparency\n","        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","        # Reduce the dataset\n","        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        torch.manual_seed(repeat)\n","        #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","        params_tmp = copy.deepcopy(params)\n","        params_tmp[\"reinit\"] = True\n","        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n","        model_new.to(device)\n","\n","        # Train and evaluate\n","        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","        # Store the results\n","        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# save baseline results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","baselines_results = [params_tmp] + baselines_results\n","\n","with open(f'results_jsons/baselines_freeze_{params[\"freeze\"]}_pool_{params[\"use_pooling\"]}.json', 'w') as f:\n","    json.dump(baselines_results, f)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.9608, Test Accuracy: 0.9531\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.9602, Test Accuracy: 0.9539\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.9598, Test Accuracy: 0.9525\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.9558, Test Accuracy: 0.9549\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.9613, Test Accuracy: 0.9568\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 5\n","Training Accuracy: 0.9582, Test Accuracy: 0.9564\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 6\n","Training Accuracy: 0.9583, Test Accuracy: 0.9543\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 7\n","Training Accuracy: 0.9629, Test Accuracy: 0.9512\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 8\n","Training Accuracy: 0.9650, Test Accuracy: 0.9527\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 9\n","Training Accuracy: 0.9628, Test Accuracy: 0.9531\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 10\n","Training Accuracy: 0.9611, Test Accuracy: 0.9545\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 11\n","Training Accuracy: 0.9618, Test Accuracy: 0.9529\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 12\n","Training Accuracy: 0.9595, Test Accuracy: 0.9531\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 13\n","Training Accuracy: 0.9590, Test Accuracy: 0.9541\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 14\n","Training Accuracy: 0.9590, Test Accuracy: 0.9547\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 15\n","Training Accuracy: 0.9614, Test Accuracy: 0.9562\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 16\n","Training Accuracy: 0.9597, Test Accuracy: 0.9568\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 17\n","Training Accuracy: 0.9587, Test Accuracy: 0.9543\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 18\n","Training Accuracy: 0.9618, Test Accuracy: 0.9572\n","\n","Sampled Percentage: 0.3, Sampled Cut Point: 3, Lr: 0.001, Repeat: 19\n","Training Accuracy: 0.9627, Test Accuracy: 0.9549\n"]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# save fine-tuning results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/results_freeze_{params[\"freeze\"]}_reinit_{params[\"reinit\"]}_pool_{params[\"use_pooling\"]}_truncate_{params[\"truncate\"]}.json', 'w') as f:\n","    json.dump(results, f)\n","results = results[1:]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}

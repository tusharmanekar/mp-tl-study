{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Example for:\n","Transfer Learning Empirical Experiment from all 10 classes of MNIST into all 10 classes of FashionMNIST "]},{"cell_type":"markdown","metadata":{},"source":["### Setup and Hyperparams"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:41.121611Z","iopub.status.busy":"2023-11-12T15:26:41.121288Z","iopub.status.idle":"2023-11-12T15:26:47.333420Z","shell.execute_reply":"2023-11-12T15:26:47.332577Z","shell.execute_reply.started":"2023-11-12T15:26:41.121585Z"},"id":"L0eJ0XYWQHS6","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/arnisa/anaconda3/envs/mp-env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# Specify which gpu\n","import os\n","gpu_id = 1\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","\n","import sys\n","sys.path.append('/mnt/c/Users/Arnisa/Desktop/MP/mp-tl-study')\n","from functions.utils import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(0)\n","    torch.cuda.manual_seed_all(0)  # if using multi-GPU"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:47.336625Z","iopub.status.busy":"2023-11-12T15:26:47.335716Z","iopub.status.idle":"2023-11-12T15:26:47.341905Z","shell.execute_reply":"2023-11-12T15:26:47.340983Z","shell.execute_reply.started":"2023-11-12T15:26:47.336587Z"},"id":"FeWfmLUgswad","trusted":true},"outputs":[],"source":["# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3,4,5]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","metadata":{},"outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 6,\n","      'num_channels': 64, # num channels for CNN\n","      'activation_function': nn.ReLU,\n","      'kernel_size': 3,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001,  #\n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'save_best': False,\n","      'save_checkpoints': False,\n","      'is_cnn': True,\n","      'is_debug': False,\n","      'classification_report_flag': False,\n","      'batch_size':64,\n","      # DATASET PARAMS\n","      'pre_train_classes': list(range(10)),\n","      'fine_tune_classes': list(range(10)),\n","      'val_split': 0.1,\n","      'num_workers': 0,\n","      'generate_dataset_seed': 42,\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': True,  \n","      'pooling_every_n_layers': 2, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n","      'pooling_stride': 2,\n","      'freeze': True,         # VARIABLE\n","      'reinit': True,         # VARIABLE\n","      'truncate': False,      # VARIABLE\n","    }"]},{"cell_type":"code","execution_count":8,"metadata":{"metadata":{}},"outputs":[],"source":["root_dir = './data'  # Specify your data directory here\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","dataloader_wrapped = TransferLearningWrapper(params, datasets.MNIST, datasets.FashionMNIST, root_dir, transform=transform)"]},{"cell_type":"markdown","metadata":{},"source":["## Pretraining"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act5): ReLU()\n","  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc): Linear(in_features=576, out_features=10, bias=True)\n",")"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 81.11%\n","Validation Accuracy: 80.80%\n","Epoch: 1 \tTraining Accuracy: 89.46%\n","Validation Accuracy: 89.38%\n","Epoch: 2 \tTraining Accuracy: 93.01%\n","Validation Accuracy: 92.27%\n","Epoch: 3 \tTraining Accuracy: 95.28%\n","Validation Accuracy: 94.85%\n","Epoch: 4 \tTraining Accuracy: 96.96%\n","Validation Accuracy: 96.70%\n","Epoch: 5 \tTraining Accuracy: 97.73%\n","Validation Accuracy: 97.32%\n","Epoch: 6 \tTraining Accuracy: 98.14%\n","Validation Accuracy: 97.73%\n","Epoch: 7 \tTraining Accuracy: 98.42%\n","Validation Accuracy: 97.98%\n","Epoch: 8 \tTraining Accuracy: 98.63%\n","Validation Accuracy: 98.13%\n","Epoch: 9 \tTraining Accuracy: 98.71%\n","Validation Accuracy: 98.05%\n","Epoch: 10 \tTraining Accuracy: 98.84%\n","Validation Accuracy: 98.00%\n","Epoch: 11 \tTraining Accuracy: 98.90%\n","Validation Accuracy: 97.98%\n","Epoch: 12 \tTraining Accuracy: 98.95%\n","Validation Accuracy: 98.27%\n","Epoch: 13 \tTraining Accuracy: 99.07%\n","Validation Accuracy: 98.27%\n","Epoch: 14 \tTraining Accuracy: 98.98%\n","Validation Accuracy: 98.22%\n","Epoch: 15 \tTraining Accuracy: 99.29%\n","Validation Accuracy: 98.17%\n","Epoch: 16 \tTraining Accuracy: 99.32%\n","Validation Accuracy: 98.37%\n","Epoch: 17 \tTraining Accuracy: 99.35%\n","Validation Accuracy: 98.22%\n","Epoch: 18 \tTraining Accuracy: 99.51%\n","Validation Accuracy: 98.37%\n","Epoch: 19 \tTraining Accuracy: 99.33%\n","Validation Accuracy: 98.33%\n","Epoch: 20 \tTraining Accuracy: 99.30%\n","Validation Accuracy: 98.33%\n","Epoch: 21 \tTraining Accuracy: 99.58%\n","Validation Accuracy: 98.48%\n","Epoch: 22 \tTraining Accuracy: 99.59%\n","Validation Accuracy: 98.53%\n","Epoch: 23 \tTraining Accuracy: 99.71%\n","Validation Accuracy: 98.52%\n","Epoch: 24 \tTraining Accuracy: 99.76%\n","Validation Accuracy: 98.37%\n","Epoch: 25 \tTraining Accuracy: 99.79%\n","Validation Accuracy: 98.50%\n","Epoch: 26 \tTraining Accuracy: 99.80%\n","Validation Accuracy: 98.50%\n","Epoch: 27 \tTraining Accuracy: 99.70%\n","Validation Accuracy: 98.53%\n","Epoch: 28 \tTraining Accuracy: 99.74%\n","Validation Accuracy: 98.60%\n","Epoch: 29 \tTraining Accuracy: 99.56%\n","Validation Accuracy: 98.37%\n","Epoch: 30 \tTraining Accuracy: 99.54%\n","Validation Accuracy: 98.07%\n","Epoch: 31 \tTraining Accuracy: 99.81%\n","Validation Accuracy: 98.43%\n","Epoch: 32 \tTraining Accuracy: 99.82%\n","Validation Accuracy: 98.55%\n","Epoch: 33 \tTraining Accuracy: 99.68%\n","Validation Accuracy: 98.25%\n","Epoch: 34 \tTraining Accuracy: 99.79%\n","Validation Accuracy: 98.48%\n","Early stopping invoked.\n","Final Training Accuracy: 0.9974\n","Final Test Accuracy: 0.9963\n"]}],"source":["# Train and evaluate\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model.load_state_dict(torch.load('pretrained_models/regular_classes.pth', map_location=device))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.0138, Accuracy: 59778.0/60000 (100%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       1.00      1.00      1.00      5923\n","     Class 1       1.00      1.00      1.00      6742\n","     Class 2       1.00      1.00      1.00      5958\n","     Class 3       1.00      1.00      1.00      6131\n","     Class 4       1.00      1.00      1.00      5842\n","     Class 5       1.00      0.99      0.99      5421\n","     Class 6       0.99      1.00      1.00      5918\n","     Class 7       1.00      1.00      1.00      6265\n","     Class 8       0.99      1.00      0.99      5851\n","     Class 9       1.00      0.99      0.99      5949\n","\n","    accuracy                           1.00     60000\n","   macro avg       1.00      1.00      1.00     60000\n","weighted avg       1.00      1.00      1.00     60000\n","\n"]},{"data":{"text/plain":["0.9963"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.test_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# save model for later use\n","torch.save(pretrained_model.state_dict(), 'pretrained_models/regular_classes.pth')"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"markdown","metadata":{},"source":["### Baselines\n","We also reuse the baselines a lot! so skip if we already have the jsons"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["baselines_results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:      \n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","    \n","    for repeat in range(repeats):\n","        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","        # Reduce the dataset\n","        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        torch.manual_seed(repeat)\n","        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","        params_tmp = copy.deepcopy(params)\n","        params_tmp[\"reinit\"] = True\n","        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n","        model_new.to(device)\n","\n","        # Train and evaluate\n","        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","        # Store the results\n","        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# save baseline results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + baselines_results\n","\n","with open(f'results/baselines_regular_classes.json', 'w') as f:\n","    json.dump(results, f)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# save fine-tuning results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results/cuts_regular_classes_FR.json', 'w') as f:\n","    json.dump(results, f)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}

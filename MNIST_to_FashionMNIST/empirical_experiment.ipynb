{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Example for:\n","Transfer Learning Empirical Experiment from all 10 classes of MNIST into all 10 classes of FashionMNIST \\\n","Note that here we are using the same architecture we used in FashionMNIST folder, with 5 CNN layers and 1 linear layer"]},{"cell_type":"markdown","metadata":{},"source":["### Setup and Hyperparams"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:41.121611Z","iopub.status.busy":"2023-11-12T15:26:41.121288Z","iopub.status.idle":"2023-11-12T15:26:47.333420Z","shell.execute_reply":"2023-11-12T15:26:47.332577Z","shell.execute_reply.started":"2023-11-12T15:26:41.121585Z"},"id":"L0eJ0XYWQHS6","trusted":true},"outputs":[],"source":["# Specify which gpu\n","import os\n","gpu_id = 1\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","\n","import sys\n","sys.path.append('/home/arnisaf/mp-tl-study')\n","from functions.utils import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(0)\n","    torch.cuda.manual_seed_all(0)  # if using multi-GPU"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:47.336625Z","iopub.status.busy":"2023-11-12T15:26:47.335716Z","iopub.status.idle":"2023-11-12T15:26:47.341905Z","shell.execute_reply":"2023-11-12T15:26:47.340983Z","shell.execute_reply.started":"2023-11-12T15:26:47.336587Z"},"id":"FeWfmLUgswad","trusted":true},"outputs":[],"source":["# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3,4,5]"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:47.343864Z","iopub.status.busy":"2023-11-12T15:26:47.343558Z","iopub.status.idle":"2023-11-12T15:26:54.538341Z","shell.execute_reply":"2023-11-12T15:26:54.537339Z","shell.execute_reply.started":"2023-11-12T15:26:47.343839Z"},"id":"6sK-eF2ucUDa","outputId":"f7f2e890-7c35-48ee-edab-dc0e97d5ce52","trusted":true},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 5,\n","      'num_channels': 30,\n","      'kernel_size': 3,\n","      'activation_function': nn.ReLU,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001, \n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'batch_size':4096,\n","      # DATASET PARAMS\n","      'pre_train_classes': list(range(10)),\n","      'fine_tune_classes': list(range(10)),\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': False,\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': True         # CHANGE: reinit the conv lyers only after the cut\n","      }"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["root_dir = './data'  # Specify your data directory here\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","dataloader_wrapped = TransferLearningWrapper(params, datasets.MNIST, datasets.FashionMNIST, root_dir, transform=transform)"]},{"cell_type":"markdown","metadata":{},"source":["## Pretraining"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (conv2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (conv4): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (fc): Linear(in_features=23520, out_features=10, bias=True)\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["#Create DNN model\n","pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 81.11%\n","Validation Accuracy: 80.80%\n","Epoch: 1 \tTraining Accuracy: 89.46%\n","Validation Accuracy: 89.38%\n","Epoch: 2 \tTraining Accuracy: 93.01%\n","Validation Accuracy: 92.27%\n","Epoch: 3 \tTraining Accuracy: 95.28%\n","Validation Accuracy: 94.85%\n","Epoch: 4 \tTraining Accuracy: 96.96%\n","Validation Accuracy: 96.70%\n","Epoch: 5 \tTraining Accuracy: 97.73%\n","Validation Accuracy: 97.32%\n","Epoch: 6 \tTraining Accuracy: 98.14%\n","Validation Accuracy: 97.73%\n","Epoch: 7 \tTraining Accuracy: 98.42%\n","Validation Accuracy: 97.98%\n","Epoch: 8 \tTraining Accuracy: 98.63%\n","Validation Accuracy: 98.13%\n","Epoch: 9 \tTraining Accuracy: 98.71%\n","Validation Accuracy: 98.05%\n","Epoch: 10 \tTraining Accuracy: 98.84%\n","Validation Accuracy: 98.00%\n","Epoch: 11 \tTraining Accuracy: 98.90%\n","Validation Accuracy: 97.98%\n","Epoch: 12 \tTraining Accuracy: 98.95%\n","Validation Accuracy: 98.27%\n","Epoch: 13 \tTraining Accuracy: 99.07%\n","Validation Accuracy: 98.27%\n","Epoch: 14 \tTraining Accuracy: 98.98%\n","Validation Accuracy: 98.22%\n","Epoch: 15 \tTraining Accuracy: 99.29%\n","Validation Accuracy: 98.17%\n","Epoch: 16 \tTraining Accuracy: 99.32%\n","Validation Accuracy: 98.37%\n","Epoch: 17 \tTraining Accuracy: 99.35%\n","Validation Accuracy: 98.22%\n","Epoch: 18 \tTraining Accuracy: 99.51%\n","Validation Accuracy: 98.37%\n","Epoch: 19 \tTraining Accuracy: 99.33%\n","Validation Accuracy: 98.33%\n","Epoch: 20 \tTraining Accuracy: 99.30%\n","Validation Accuracy: 98.33%\n","Epoch: 21 \tTraining Accuracy: 99.58%\n","Validation Accuracy: 98.48%\n","Epoch: 22 \tTraining Accuracy: 99.59%\n","Validation Accuracy: 98.53%\n","Epoch: 23 \tTraining Accuracy: 99.71%\n","Validation Accuracy: 98.52%\n","Epoch: 24 \tTraining Accuracy: 99.76%\n","Validation Accuracy: 98.37%\n","Epoch: 25 \tTraining Accuracy: 99.79%\n","Validation Accuracy: 98.50%\n","Epoch: 26 \tTraining Accuracy: 99.80%\n","Validation Accuracy: 98.50%\n","Epoch: 27 \tTraining Accuracy: 99.70%\n","Validation Accuracy: 98.53%\n","Epoch: 28 \tTraining Accuracy: 99.74%\n","Validation Accuracy: 98.60%\n","Epoch: 29 \tTraining Accuracy: 99.56%\n","Validation Accuracy: 98.37%\n","Epoch: 30 \tTraining Accuracy: 99.54%\n","Validation Accuracy: 98.07%\n","Epoch: 31 \tTraining Accuracy: 99.81%\n","Validation Accuracy: 98.43%\n","Epoch: 32 \tTraining Accuracy: 99.82%\n","Validation Accuracy: 98.55%\n","Epoch: 33 \tTraining Accuracy: 99.68%\n","Validation Accuracy: 98.25%\n","Epoch: 34 \tTraining Accuracy: 99.79%\n","Validation Accuracy: 98.48%\n","Early stopping invoked.\n","Final Training Accuracy: 0.9974\n","Final Test Accuracy: 0.9963\n"]}],"source":["# Train and evaluate\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (conv2): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (conv4): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (fc): Linear(in_features=23520, out_features=10, bias=True)\n",")"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model.load_state_dict(torch.load('pretrained_models/pretrained_mnist_to_fashion_all_classes/pretrained_model.pth'))\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.0138, Accuracy: 59778.0/60000 (100%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       1.00      1.00      1.00      5923\n","     Class 1       1.00      1.00      1.00      6742\n","     Class 2       1.00      1.00      1.00      5958\n","     Class 3       1.00      1.00      1.00      6131\n","     Class 4       1.00      1.00      1.00      5842\n","     Class 5       1.00      0.99      0.99      5421\n","     Class 6       0.99      1.00      1.00      5918\n","     Class 7       1.00      1.00      1.00      6265\n","     Class 8       0.99      1.00      0.99      5851\n","     Class 9       1.00      0.99      0.99      5949\n","\n","    accuracy                           1.00     60000\n","   macro avg       1.00      1.00      1.00     60000\n","weighted avg       1.00      1.00      1.00     60000\n","\n"]},{"data":{"text/plain":["0.9963"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.test_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# save model for later use\n","foldername = \"pretrained_models/pretrained_mnist_to_fashion_all_classes\"\n","os.mkdir(foldername)\n","torch.save(pretrained_model.state_dict(), os.path.join(foldername, 'pretrained_model.pth'))\n","\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp.get(\"activation_function\", nn.ReLU))\n","#save params as well\n","with open(os.path.join(foldername, 'params.json'), 'w') as fp:\n","    json.dump(params_tmp, fp)"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load results: to continue from a checkpoint (actually don't run)\n","with open('results.json', 'r') as f:\n","    results = json.load(f)"]},{"cell_type":"markdown","metadata":{},"source":["### Baselines (End-to-end models trained on subsets of fine-tuning dataset)\n","We also reuse the baselines a lot! so skip if we already have the jsons"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["baselines_results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:      \n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","    \n","    for repeat in range(repeats):\n","        # Print or log the sampled values for transparency\n","        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","        # Reduce the dataset\n","        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        torch.manual_seed(repeat)\n","        #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","        params_tmp = copy.deepcopy(params)\n","        params_tmp[\"reinit\"] = True\n","        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n","        model_new.to(device)\n","\n","        # Train and evaluate\n","        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","        # Store the results\n","        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# save baseline results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/baselines_freeze_{params[\"freeze\"]}_pool_{params[\"use_pooling\"]}_lr_{params[\"lr_fine_tune\"]}_dummy_run.json', 'w') as f:\n","    json.dump(results, f)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# save fine-tuning results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/results_freeze_{params[\"freeze\"]}_reinit_{params[\"reinit\"]}_pool_{params[\"use_pooling\"]}_lr_{params[\"lr_fine_tune\"]}_MNIST_to_Fashion_{percentages[0]}_to_{percentages[-1]}.json', 'w') as f:\n","    json.dump(results, f)\n","results = results[1:]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}

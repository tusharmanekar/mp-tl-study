{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Example for:\n","Transfer Learning Empirical Experiment from all 10 classes of MNIST into all 10 classes of FashionMNIST \\\n","Note that here we are using the same architecture we used in FashionMNIST folder, with 5 CNN layers and 1 linear layer"]},{"cell_type":"markdown","metadata":{},"source":["### Setup and Hyperparams"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:41.121611Z","iopub.status.busy":"2023-11-12T15:26:41.121288Z","iopub.status.idle":"2023-11-12T15:26:47.333420Z","shell.execute_reply":"2023-11-12T15:26:47.332577Z","shell.execute_reply.started":"2023-11-12T15:26:41.121585Z"},"id":"L0eJ0XYWQHS6","trusted":true},"outputs":[],"source":["# Specify which gpu\n","import os\n","gpu_id = 3\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n","\n","import sys\n","sys.path.append('/home/arnisaf/mp-tl-study')\n","from functions.utils import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(0)\n","    torch.cuda.manual_seed_all(0)  # if using multi-GPU"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-12T15:26:47.336625Z","iopub.status.busy":"2023-11-12T15:26:47.335716Z","iopub.status.idle":"2023-11-12T15:26:47.341905Z","shell.execute_reply":"2023-11-12T15:26:47.340983Z","shell.execute_reply.started":"2023-11-12T15:26:47.336587Z"},"id":"FeWfmLUgswad","trusted":true},"outputs":[],"source":["# cuts=0 means: end-to-end model if we are reinitializing\n","cuts = [0,1,2,3,4,5.6]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Changes Here for the experiments\n","params = {\n","      # MODEL ARCHITECTURE PARAMS\n","      'depth': 6,\n","      'num_channels': 64,\n","      'kernel_size': 3,\n","      'activation_function': nn.ReLU,\n","      # TRAINING PARAMS\n","      'device': device,\n","      'lr_pretrain': 0.001,   \n","      'lr_fine_tune': 0.001, \n","      'num_train': 40,\n","      'early_stop_patience': 6,\n","      'batch_size':4096,\n","      # DATASET PARAMS\n","      'pre_train_classes': list(range(10)),\n","      'fine_tune_classes': list(range(10)),\n","      # EXPERIMENT SETTING PARAMS\n","      'use_pooling': True,   # CHANGE\n","      'pooling_every_n_layers': 2, # add pooling after every n layers specified here. For only one pooling after all the CNN layers, this equals params['depth']\n","      # default value for pooling_every_n_layers is 1 (after each cnn layer)\n","      'pooling_stride': 2,\n","      'freeze': True,         # CHANGE: freeze the conv layers before the cut\n","      'reinit': True         # CHANGE: reinit the conv lyers only after the cut\n","      }"]},{"cell_type":"code","execution_count":4,"metadata":{"metadata":{}},"outputs":[],"source":["root_dir = './data'  # Specify your data directory here\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","dataloader_wrapped = TransferLearningWrapper(params, datasets.MNIST, datasets.FashionMNIST, root_dir, transform=transform)"]},{"cell_type":"code","execution_count":5,"metadata":{"metadata":{}},"outputs":[{"data":{"text/plain":["54000"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dataloader_wrapped.pretrain_train_loader.dataset.__len__()"]},{"cell_type":"markdown","metadata":{},"source":["## Pretraining"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act5): ReLU()\n","  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc): Linear(in_features=576, out_features=10, bias=True)\n",")"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["#Create DNN model\n","pretrained_model = CustomCNN(params, dataloader_wrapped.output_dim)\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:26:54.539725Z","iopub.status.busy":"2023-11-12T15:26:54.539463Z","iopub.status.idle":"2023-11-12T15:29:07.301509Z","shell.execute_reply":"2023-11-12T15:29:07.300272Z","shell.execute_reply.started":"2023-11-12T15:26:54.539702Z"},"id":"gU9NwDAjhT3o","outputId":"7335d6d9-a841-4397-b879-6ceef21ab105","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tTraining Accuracy: 47.74%\n","Validation Accuracy: 47.67%\n","Epoch: 1 \tTraining Accuracy: 75.33%\n","Validation Accuracy: 74.87%\n","Epoch: 2 \tTraining Accuracy: 82.54%\n","Validation Accuracy: 81.30%\n","Epoch: 3 \tTraining Accuracy: 87.35%\n","Validation Accuracy: 86.38%\n","Epoch: 4 \tTraining Accuracy: 89.96%\n","Validation Accuracy: 89.22%\n","Epoch: 5 \tTraining Accuracy: 92.27%\n","Validation Accuracy: 91.60%\n","Epoch: 6 \tTraining Accuracy: 93.92%\n","Validation Accuracy: 93.58%\n","Epoch: 7 \tTraining Accuracy: 95.48%\n","Validation Accuracy: 95.22%\n","Epoch: 8 \tTraining Accuracy: 95.81%\n","Validation Accuracy: 95.62%\n","Epoch: 9 \tTraining Accuracy: 94.51%\n","Validation Accuracy: 94.42%\n","Epoch: 10 \tTraining Accuracy: 96.38%\n","Validation Accuracy: 96.10%\n","Epoch: 11 \tTraining Accuracy: 97.17%\n","Validation Accuracy: 96.97%\n","Epoch: 12 \tTraining Accuracy: 97.34%\n","Validation Accuracy: 97.03%\n","Epoch: 13 \tTraining Accuracy: 97.67%\n","Validation Accuracy: 97.30%\n","Epoch: 14 \tTraining Accuracy: 97.27%\n","Validation Accuracy: 97.13%\n","Epoch: 15 \tTraining Accuracy: 97.97%\n","Validation Accuracy: 97.60%\n","Epoch: 16 \tTraining Accuracy: 98.11%\n","Validation Accuracy: 97.85%\n","Epoch: 17 \tTraining Accuracy: 97.84%\n","Validation Accuracy: 97.38%\n","Epoch: 18 \tTraining Accuracy: 98.31%\n","Validation Accuracy: 97.95%\n","Epoch: 19 \tTraining Accuracy: 98.27%\n","Validation Accuracy: 97.85%\n","Epoch: 20 \tTraining Accuracy: 98.30%\n","Validation Accuracy: 98.02%\n","Epoch: 21 \tTraining Accuracy: 98.37%\n","Validation Accuracy: 97.93%\n","Epoch: 22 \tTraining Accuracy: 98.14%\n","Validation Accuracy: 97.83%\n","Epoch: 23 \tTraining Accuracy: 98.53%\n","Validation Accuracy: 98.10%\n","Epoch: 24 \tTraining Accuracy: 98.67%\n","Validation Accuracy: 98.17%\n","Epoch: 25 \tTraining Accuracy: 98.60%\n","Validation Accuracy: 98.18%\n","Epoch: 26 \tTraining Accuracy: 98.47%\n","Validation Accuracy: 97.95%\n","Epoch: 27 \tTraining Accuracy: 98.92%\n","Validation Accuracy: 98.37%\n","Epoch: 28 \tTraining Accuracy: 98.87%\n","Validation Accuracy: 98.38%\n","Epoch: 29 \tTraining Accuracy: 98.91%\n","Validation Accuracy: 98.50%\n","Epoch: 30 \tTraining Accuracy: 98.82%\n","Validation Accuracy: 98.33%\n","Epoch: 31 \tTraining Accuracy: 99.00%\n","Validation Accuracy: 98.45%\n","Epoch: 32 \tTraining Accuracy: 98.90%\n","Validation Accuracy: 98.40%\n","Epoch: 33 \tTraining Accuracy: 99.10%\n","Validation Accuracy: 98.70%\n","Epoch: 34 \tTraining Accuracy: 99.06%\n","Validation Accuracy: 98.57%\n","Epoch: 35 \tTraining Accuracy: 99.12%\n","Validation Accuracy: 98.58%\n","Epoch: 36 \tTraining Accuracy: 98.85%\n","Validation Accuracy: 98.23%\n","Epoch: 37 \tTraining Accuracy: 98.85%\n","Validation Accuracy: 98.33%\n","Epoch: 38 \tTraining Accuracy: 99.21%\n","Validation Accuracy: 98.70%\n","Epoch: 39 \tTraining Accuracy: 98.33%\n","Validation Accuracy: 97.85%\n","Early stopping invoked.\n","Final Training Accuracy: 0.9910\n","Final Test Accuracy: 0.9906\n"]}],"source":["# Train and evaluate\n","trainer = Trainer(pretrained_model, dataloader_wrapped, params[\"lr_pretrain\"], params)\n","train_acc, test_acc, effective_epochs, checkpoints = trainer.train()\n","\n","print(f\"Final Training Accuracy: {train_acc:.4f}\")\n","print(f\"Final Test Accuracy: {test_acc:.4f}\")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#torch.save(pretrained_model.state_dict(), 'pretrained_models/pretrained_model_only_numbers_new.pth')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["CustomCNN(\n","  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act0): ReLU()\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act1): ReLU()\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act2): ReLU()\n","  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act3): ReLU()\n","  (pool3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act4): ReLU()\n","  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (act5): ReLU()\n","  (pool5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (fc): Linear(in_features=576, out_features=10, bias=True)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["pretrained_model.load_state_dict(torch.load('pretrained_models/pretrained_model_only_numbers_new.pth'))\n","pretrained_model.to(device)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Average loss: 0.0307, Accuracy: 59436.0/60000 (99%)\n","\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.99      1.00      1.00      5923\n","     Class 1       0.99      1.00      0.99      6742\n","     Class 2       0.99      0.99      0.99      5958\n","     Class 3       0.99      0.99      0.99      6131\n","     Class 4       0.99      0.99      0.99      5842\n","     Class 5       0.99      0.99      0.99      5421\n","     Class 6       0.99      0.99      0.99      5918\n","     Class 7       0.99      1.00      0.99      6265\n","     Class 8       0.99      0.98      0.99      5851\n","     Class 9       0.98      0.99      0.98      5949\n","\n","    accuracy                           0.99     60000\n","   macro avg       0.99      0.99      0.99     60000\n","weighted avg       0.99      0.99      0.99     60000\n","\n"]},{"data":{"text/plain":["0.9906"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["eval(pretrained_model, device, dataloader_wrapped.test_loader, debug=True, classification_report_flag=True, is_cnn=True)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# save model for later use\n","foldername = \"pretrained_models/pretrained_mnist_to_fashion_all_classes\"\n","os.mkdir(foldername)\n","torch.save(pretrained_model.state_dict(), os.path.join(foldername, 'pretrained_model.pth'))\n","\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp.get(\"activation_function\", nn.ReLU))\n","#save params as well\n","with open(os.path.join(foldername, 'params.json'), 'w') as fp:\n","    json.dump(params_tmp, fp)"]},{"cell_type":"markdown","metadata":{"id":"ge8Q1YiEqC7e"},"source":["## Fine-tuning Experiments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load results: to continue from a checkpoint (actually don't run)\n","with open('results.json', 'r') as f:\n","    results = json.load(f)"]},{"cell_type":"markdown","metadata":{},"source":["### Baselines (End-to-end models trained on subsets of fine-tuning dataset)\n","We also reuse the baselines a lot! so skip if we already have the jsons"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["baselines_results = []\n","percentages = [0.001, 0.01, 0.1, 0.5, 1.0]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 0\n","Early stopping invoked.\n","Training Accuracy: 0.5600, Test Accuracy: 0.4955\n","\n","Sampled Percentage: 0.001, Lr: 0.001, Repeat: 1\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-4e7c4f54b795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Reduce the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtrain_loader_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_percentage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/mp-tl-study/functions/utils.py\u001b[0m in \u001b[0;36mreduce_dataset\u001b[0;34m(dataloader, percentage, balanced, seed)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;31m# Extract all data and labels from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/mp-tl-study/functions/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;31m# Extract all data and labels from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/mp-tl-study/functions/utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Transform the label using the fitted label encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         return _encode_numpy(values, uniques, encode,\n\u001b[0;32m--> 122\u001b[0;31m                              check_unknown=check_unknown)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[0;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_check_unknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 raise ValueError(\"y contains previously unseen labels: %s\"\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36m_encode_check_unknown\u001b[0;34m(values, uniques, return_mask)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/anaconda/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mFind\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munique\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignoring\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \"\"\"\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0moptional_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:      \n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","    \n","    for repeat in range(repeats):\n","        # Print or log the sampled values for transparency\n","        print(f\"\\nSampled Percentage: {sampled_percentage}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","        # Reduce the dataset\n","        train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        torch.manual_seed(repeat)\n","        #train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed = repeat)\n","        dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","\n","        # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","        params_tmp = copy.deepcopy(params)\n","        params_tmp[\"reinit\"] = True\n","        model_new = cut_custom_cnn_model(pretrained_model, cut_point=0, params=params_tmp, output_dim=dataloader_wrapped.output_dim)\n","        model_new.to(device)\n","\n","        # Train and evaluate\n","        trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","        train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","        print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","        # Store the results\n","        baselines_results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":-1, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc}) # -1 for the cut point means it's baseline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(baselines_results)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# save baseline results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/baselines_freeze_{params[\"freeze\"]}_pool_{params[\"use_pooling\"]}_lr_{params[\"lr_fine_tune\"]}_dummy_run.json', 'w') as f:\n","    json.dump(results, f)"]},{"cell_type":"markdown","metadata":{},"source":["### Fine-tuning"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["results = []\n","#percentages = [0.001, 0.01, 0.1, 0.5, 1.0]\n","percentages = [0.5]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-12T15:29:09.268754Z","iopub.status.busy":"2023-11-12T15:29:09.268384Z","iopub.status.idle":"2023-11-12T17:54:32.877944Z","shell.execute_reply":"2023-11-12T17:54:32.876696Z","shell.execute_reply.started":"2023-11-12T15:29:09.268720Z"},"id":"hMZ4o1FGsipP","outputId":"08ac8a68-17f6-48a3-e06e-27f484b9507d","scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.8723, Test Accuracy: 0.8664\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8706, Test Accuracy: 0.8674\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8763, Test Accuracy: 0.8701\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8656, Test Accuracy: 0.8621\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 0, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.8631, Test Accuracy: 0.8585\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.8605, Test Accuracy: 0.8541\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8694, Test Accuracy: 0.8659\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8731, Test Accuracy: 0.8681\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8670, Test Accuracy: 0.8610\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 1, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.8681, Test Accuracy: 0.8635\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.8675, Test Accuracy: 0.8605\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8687, Test Accuracy: 0.8647\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8706, Test Accuracy: 0.8639\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8694, Test Accuracy: 0.8653\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 2, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.8728, Test Accuracy: 0.8671\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.8656, Test Accuracy: 0.8563\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8752, Test Accuracy: 0.8687\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8769, Test Accuracy: 0.8676\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8717, Test Accuracy: 0.8661\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 3, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.8736, Test Accuracy: 0.8674\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.8713, Test Accuracy: 0.8629\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8663, Test Accuracy: 0.8597\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8781, Test Accuracy: 0.8701\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8697, Test Accuracy: 0.8644\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 4, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.8736, Test Accuracy: 0.8658\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5.6, Lr: 0.001, Repeat: 0\n"]},{"ename":"TypeError","evalue":"slice indices must be integers or None or have an __index__ method","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-bf55f78cc5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Copy and then cut the model - we already deepcopy it in the function: pretrained_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mmodel_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcut_custom_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut_point\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_cut_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mmodel_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/mp-tl-study/functions/utils.py\u001b[0m in \u001b[0;36mcut_custom_cnn_model\u001b[0;34m(model, cut_point, params, output_dim)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;31m# If freeze is True, set requires_grad to False for layers before cut_point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"freeze\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconv_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcut_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 0, 'train_acc': 0.8722962962962963, 'test_acc': 0.8664166666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 1, 'train_acc': 0.8705555555555555, 'test_acc': 0.8673833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 2, 'train_acc': 0.8762962962962964, 'test_acc': 0.8701}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 3, 'train_acc': 0.8655925925925926, 'test_acc': 0.8620666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 4, 'train_acc': 0.8631481481481481, 'test_acc': 0.8585166666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 0, 'train_acc': 0.8605185185185186, 'test_acc': 0.8541333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 1, 'train_acc': 0.8693703703703703, 'test_acc': 0.8658666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 2, 'train_acc': 0.8730740740740741, 'test_acc': 0.86815}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 3, 'train_acc': 0.867, 'test_acc': 0.86105}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 4, 'train_acc': 0.8681111111111111, 'test_acc': 0.8634666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 0, 'train_acc': 0.8674814814814815, 'test_acc': 0.86045}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 1, 'train_acc': 0.8686666666666667, 'test_acc': 0.8646833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 2, 'train_acc': 0.8706296296296296, 'test_acc': 0.8638833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 3, 'train_acc': 0.8694074074074074, 'test_acc': 0.8653}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 4, 'train_acc': 0.8728148148148148, 'test_acc': 0.8671333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 0, 'train_acc': 0.8655555555555555, 'test_acc': 0.8563333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 1, 'train_acc': 0.8751851851851852, 'test_acc': 0.8686833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 2, 'train_acc': 0.8768888888888889, 'test_acc': 0.8675833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 3, 'train_acc': 0.8717407407407407, 'test_acc': 0.8661333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 4, 'train_acc': 0.8736296296296296, 'test_acc': 0.8674333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 0, 'train_acc': 0.8712962962962963, 'test_acc': 0.86285}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 1, 'train_acc': 0.8662962962962963, 'test_acc': 0.85965}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 2, 'train_acc': 0.8781481481481481, 'test_acc': 0.8700666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 3, 'train_acc': 0.8696666666666667, 'test_acc': 0.8644}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 4, 'train_acc': 0.8735925925925926, 'test_acc': 0.8658166666666667}]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["cuts = [5,6]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.8649, Test Accuracy: 0.8558\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8647, Test Accuracy: 0.8583\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8647, Test Accuracy: 0.8563\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8543, Test Accuracy: 0.8480\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 5, Lr: 0.001, Repeat: 4\n","Early stopping invoked.\n","Training Accuracy: 0.8560, Test Accuracy: 0.8502\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 0\n","Training Accuracy: 0.8408, Test Accuracy: 0.8329\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 1\n","Training Accuracy: 0.8376, Test Accuracy: 0.8337\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 2\n","Training Accuracy: 0.8429, Test Accuracy: 0.8349\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 3\n","Training Accuracy: 0.8344, Test Accuracy: 0.8302\n","\n","Sampled Percentage: 0.5, Sampled Cut Point: 6, Lr: 0.001, Repeat: 4\n","Training Accuracy: 0.8353, Test Accuracy: 0.8308\n"]}],"source":["dataloader_wrapped.update_phase('finetune')\n","\n","for sampled_percentage in percentages:\n","\n","    if sampled_percentage <= 0.01:\n","        repeats = 25\n","    elif sampled_percentage < 0.5:\n","        repeats = 20\n","    else:\n","        repeats = 5\n","        \n","    for sampled_cut_point in cuts:\n","\n","        for repeat in range(repeats):\n","            # Add the combination to the tested set\n","            # tested_combinations.add((sampled_percentage, sampled_cut_point))\n","\n","            # Print or log the sampled values for transparency\n","            print(f\"\\nSampled Percentage: {sampled_percentage}, Sampled Cut Point: {sampled_cut_point}, Lr: {params['lr_fine_tune']}, Repeat: {repeat}\")\n","\n","            # Reduce the dataset\n","            train_loader_reduced = reduce_dataset(dataloader_wrapped.train_loader, sampled_percentage, seed=repeat)\n","            dataset_namespace_new = SimpleNamespace(train_loader=train_loader_reduced, test_loader=dataloader_wrapped.test_loader, val_loader=dataloader_wrapped.val_loader)\n","            torch.manual_seed(repeat) # because in the cut function we reinitialize some layers too (at least the dense layers)\n","            \n","            # Copy and then cut the model - we already deepcopy it in the function: pretrained_model\n","            model_new = cut_custom_cnn_model(pretrained_model, cut_point=sampled_cut_point, params=params, output_dim=dataloader_wrapped.output_dim)\n","            model_new.to(device)\n","            \n","            # Train and evaluate\n","            trainer = Trainer(model_new, dataset_namespace_new, params['lr_fine_tune'], params)\n","            train_acc, test_acc, effective_epochs, checkpoints = trainer.train(verbose=0)\n","            print(f\"Training Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n","\n","            # Store the results\n","            results.append({\"lr\":params['lr_fine_tune'], \"sampled_percentage\":sampled_percentage, \"sampled_cut_point\":sampled_cut_point, \"repeat\":repeat, \"train_acc\":train_acc, \"test_acc\":test_acc})"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 0, 'train_acc': 0.8722962962962963, 'test_acc': 0.8664166666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 1, 'train_acc': 0.8705555555555555, 'test_acc': 0.8673833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 2, 'train_acc': 0.8762962962962964, 'test_acc': 0.8701}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 3, 'train_acc': 0.8655925925925926, 'test_acc': 0.8620666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 4, 'train_acc': 0.8631481481481481, 'test_acc': 0.8585166666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 0, 'train_acc': 0.8605185185185186, 'test_acc': 0.8541333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 1, 'train_acc': 0.8693703703703703, 'test_acc': 0.8658666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 2, 'train_acc': 0.8730740740740741, 'test_acc': 0.86815}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 3, 'train_acc': 0.867, 'test_acc': 0.86105}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 4, 'train_acc': 0.8681111111111111, 'test_acc': 0.8634666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 0, 'train_acc': 0.8674814814814815, 'test_acc': 0.86045}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 1, 'train_acc': 0.8686666666666667, 'test_acc': 0.8646833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 2, 'train_acc': 0.8706296296296296, 'test_acc': 0.8638833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 3, 'train_acc': 0.8694074074074074, 'test_acc': 0.8653}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 4, 'train_acc': 0.8728148148148148, 'test_acc': 0.8671333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 0, 'train_acc': 0.8655555555555555, 'test_acc': 0.8563333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 1, 'train_acc': 0.8751851851851852, 'test_acc': 0.8686833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 2, 'train_acc': 0.8768888888888889, 'test_acc': 0.8675833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 3, 'train_acc': 0.8717407407407407, 'test_acc': 0.8661333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 4, 'train_acc': 0.8736296296296296, 'test_acc': 0.8674333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 0, 'train_acc': 0.8712962962962963, 'test_acc': 0.86285}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 1, 'train_acc': 0.8662962962962963, 'test_acc': 0.85965}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 2, 'train_acc': 0.8781481481481481, 'test_acc': 0.8700666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 3, 'train_acc': 0.8696666666666667, 'test_acc': 0.8644}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 4, 'train_acc': 0.8735925925925926, 'test_acc': 0.8658166666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 0, 'train_acc': 0.8649259259259259, 'test_acc': 0.8557666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 1, 'train_acc': 0.8646666666666667, 'test_acc': 0.8582666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 2, 'train_acc': 0.8647407407407407, 'test_acc': 0.85635}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 3, 'train_acc': 0.8542592592592593, 'test_acc': 0.8480166666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 4, 'train_acc': 0.8559629629629629, 'test_acc': 0.8501666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 0, 'train_acc': 0.8408148148148148, 'test_acc': 0.8328833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 1, 'train_acc': 0.8376296296296296, 'test_acc': 0.83375}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 2, 'train_acc': 0.8428518518518519, 'test_acc': 0.8349166666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 3, 'train_acc': 0.8344444444444444, 'test_acc': 0.8301833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 4, 'train_acc': 0.8353333333333334, 'test_acc': 0.8308333333333333}]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 0, 'train_acc': 0.8722962962962963, 'test_acc': 0.8664166666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 1, 'train_acc': 0.8705555555555555, 'test_acc': 0.8673833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 2, 'train_acc': 0.8762962962962964, 'test_acc': 0.8701}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 3, 'train_acc': 0.8655925925925926, 'test_acc': 0.8620666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 0, 'repeat': 4, 'train_acc': 0.8631481481481481, 'test_acc': 0.8585166666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 0, 'train_acc': 0.8605185185185186, 'test_acc': 0.8541333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 1, 'train_acc': 0.8693703703703703, 'test_acc': 0.8658666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 2, 'train_acc': 0.8730740740740741, 'test_acc': 0.86815}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 3, 'train_acc': 0.867, 'test_acc': 0.86105}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 1, 'repeat': 4, 'train_acc': 0.8681111111111111, 'test_acc': 0.8634666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 0, 'train_acc': 0.8674814814814815, 'test_acc': 0.86045}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 1, 'train_acc': 0.8686666666666667, 'test_acc': 0.8646833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 2, 'train_acc': 0.8706296296296296, 'test_acc': 0.8638833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 3, 'train_acc': 0.8694074074074074, 'test_acc': 0.8653}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 2, 'repeat': 4, 'train_acc': 0.8728148148148148, 'test_acc': 0.8671333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 0, 'train_acc': 0.8655555555555555, 'test_acc': 0.8563333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 1, 'train_acc': 0.8751851851851852, 'test_acc': 0.8686833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 2, 'train_acc': 0.8768888888888889, 'test_acc': 0.8675833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 3, 'train_acc': 0.8717407407407407, 'test_acc': 0.8661333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 3, 'repeat': 4, 'train_acc': 0.8736296296296296, 'test_acc': 0.8674333333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 0, 'train_acc': 0.8712962962962963, 'test_acc': 0.86285}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 1, 'train_acc': 0.8662962962962963, 'test_acc': 0.85965}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 2, 'train_acc': 0.8781481481481481, 'test_acc': 0.8700666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 3, 'train_acc': 0.8696666666666667, 'test_acc': 0.8644}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 4, 'repeat': 4, 'train_acc': 0.8735925925925926, 'test_acc': 0.8658166666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 0, 'train_acc': 0.8649259259259259, 'test_acc': 0.8557666666666667}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 1, 'train_acc': 0.8646666666666667, 'test_acc': 0.8582666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 2, 'train_acc': 0.8647407407407407, 'test_acc': 0.85635}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 3, 'train_acc': 0.8542592592592593, 'test_acc': 0.8480166666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 5, 'repeat': 4, 'train_acc': 0.8559629629629629, 'test_acc': 0.8501666666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 0, 'train_acc': 0.8408148148148148, 'test_acc': 0.8328833333333333}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 1, 'train_acc': 0.8376296296296296, 'test_acc': 0.83375}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 2, 'train_acc': 0.8428518518518519, 'test_acc': 0.8349166666666666}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 3, 'train_acc': 0.8344444444444444, 'test_acc': 0.8301833333333334}, {'lr': 0.001, 'sampled_percentage': 0.5, 'sampled_cut_point': 6, 'repeat': 4, 'train_acc': 0.8353333333333334, 'test_acc': 0.8308333333333333}]\n"]}],"source":["print(results)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# save fine-tuning results\n","params_tmp = copy.deepcopy(params)\n","del params_tmp[\"device\"]\n","params_tmp[\"activation_function\"] = str(params_tmp[\"activation_function\"])\n","results = [params_tmp] + results\n","\n","with open(f'results_jsons/results_freeze_{params[\"freeze\"]}_reinit_{params[\"reinit\"]}_pool_{params[\"use_pooling\"]}_lr_{params[\"lr_fine_tune\"]}_MNIST_to_Fashion_{percentages[0]}_to_{percentages[-1]}.json', 'w') as f:\n","    json.dump(results, f)\n","results = results[1:]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}

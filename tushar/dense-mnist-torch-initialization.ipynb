{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-24T11:01:21.637008Z","iopub.execute_input":"2023-08-24T11:01:21.637393Z","iopub.status.idle":"2023-08-24T11:01:21.644693Z","shell.execute_reply.started":"2023-08-24T11:01:21.637362Z","shell.execute_reply":"2023-08-24T11:01:21.643415Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:01:21.646905Z","iopub.execute_input":"2023-08-24T11:01:21.647858Z","iopub.status.idle":"2023-08-24T11:01:21.660326Z","shell.execute_reply.started":"2023-08-24T11:01:21.647817Z","shell.execute_reply":"2023-08-24T11:01:21.658749Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:01:21.663158Z","iopub.execute_input":"2023-08-24T11:01:21.663609Z","iopub.status.idle":"2023-08-24T11:01:21.776076Z","shell.execute_reply.started":"2023-08-24T11:01:21.663577Z","shell.execute_reply":"2023-08-24T11:01:21.774847Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class DenseNet(nn.Module):\n    def __init__(self, input_dim=28*28, hidden_dim=100, output_dim=10):\n        super(DenseNet, self).__init__()\n\n        # Initial layer\n        layers = [nn.Linear(input_dim, hidden_dim), nn.ReLU()]\n\n        # 98 hidden layers\n        for _ in range(10):\n            layers.append(nn.Linear(hidden_dim, hidden_dim))\n            layers.append(nn.ReLU())\n\n        # Output layer\n        layers.append(nn.Linear(hidden_dim, output_dim))\n\n        self.net = nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        return self.net(x)\n\nmodel = DenseNet()\nprint(model)\n\n# Define the device\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\n# Instantiate the model and move to GPU\nmodel = DenseNet().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:01:21.777871Z","iopub.execute_input":"2023-08-24T11:01:21.778367Z","iopub.status.idle":"2023-08-24T11:01:21.798635Z","shell.execute_reply.started":"2023-08-24T11:01:21.778333Z","shell.execute_reply":"2023-08-24T11:01:21.797446Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"DenseNet(\n  (net): Sequential(\n    (0): Linear(in_features=784, out_features=100, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=100, out_features=100, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=100, out_features=100, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=100, out_features=100, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=100, out_features=100, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=100, out_features=100, bias=True)\n    (11): ReLU()\n    (12): Linear(in_features=100, out_features=100, bias=True)\n    (13): ReLU()\n    (14): Linear(in_features=100, out_features=100, bias=True)\n    (15): ReLU()\n    (16): Linear(in_features=100, out_features=100, bias=True)\n    (17): ReLU()\n    (18): Linear(in_features=100, out_features=100, bias=True)\n    (19): ReLU()\n    (20): Linear(in_features=100, out_features=100, bias=True)\n    (21): ReLU()\n    (22): Linear(in_features=100, out_features=10, bias=True)\n  )\n)\ncpu\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:01:21.801671Z","iopub.execute_input":"2023-08-24T11:01:21.802727Z","iopub.status.idle":"2023-08-24T11:01:21.809023Z","shell.execute_reply.started":"2023-08-24T11:01:21.802671Z","shell.execute_reply":"2023-08-24T11:01:21.807601Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"num_epochs = 25\n\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (i+1) % 100 == 0:\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:01:21.811320Z","iopub.execute_input":"2023-08-24T11:01:21.812320Z","iopub.status.idle":"2023-08-24T11:10:08.331574Z","shell.execute_reply.started":"2023-08-24T11:01:21.812264Z","shell.execute_reply":"2023-08-24T11:10:08.330243Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch [1/25], Step [100/938], Loss: 2.2881\nEpoch [1/25], Step [200/938], Loss: 1.7398\nEpoch [1/25], Step [300/938], Loss: 1.7505\nEpoch [1/25], Step [400/938], Loss: 1.6668\nEpoch [1/25], Step [500/938], Loss: 1.8363\nEpoch [1/25], Step [600/938], Loss: 1.4283\nEpoch [1/25], Step [700/938], Loss: 1.5748\nEpoch [1/25], Step [800/938], Loss: 1.5453\nEpoch [1/25], Step [900/938], Loss: 1.5766\nEpoch [2/25], Step [100/938], Loss: 1.4740\nEpoch [2/25], Step [200/938], Loss: 1.3382\nEpoch [2/25], Step [300/938], Loss: 1.2210\nEpoch [2/25], Step [400/938], Loss: 1.0425\nEpoch [2/25], Step [500/938], Loss: 1.2155\nEpoch [2/25], Step [600/938], Loss: 1.2652\nEpoch [2/25], Step [700/938], Loss: 1.3178\nEpoch [2/25], Step [800/938], Loss: 1.0327\nEpoch [2/25], Step [900/938], Loss: 0.9655\nEpoch [3/25], Step [100/938], Loss: 1.0938\nEpoch [3/25], Step [200/938], Loss: 1.0586\nEpoch [3/25], Step [300/938], Loss: 1.1197\nEpoch [3/25], Step [400/938], Loss: 0.6319\nEpoch [3/25], Step [500/938], Loss: 0.9683\nEpoch [3/25], Step [600/938], Loss: 0.9963\nEpoch [3/25], Step [700/938], Loss: 0.6945\nEpoch [3/25], Step [800/938], Loss: 0.8091\nEpoch [3/25], Step [900/938], Loss: 0.5815\nEpoch [4/25], Step [100/938], Loss: 0.8531\nEpoch [4/25], Step [200/938], Loss: 0.9025\nEpoch [4/25], Step [300/938], Loss: 0.6151\nEpoch [4/25], Step [400/938], Loss: 0.5246\nEpoch [4/25], Step [500/938], Loss: 0.5329\nEpoch [4/25], Step [600/938], Loss: 0.6837\nEpoch [4/25], Step [700/938], Loss: 0.6179\nEpoch [4/25], Step [800/938], Loss: 0.5215\nEpoch [4/25], Step [900/938], Loss: 0.7854\nEpoch [5/25], Step [100/938], Loss: 0.4010\nEpoch [5/25], Step [200/938], Loss: 0.4321\nEpoch [5/25], Step [300/938], Loss: 0.4588\nEpoch [5/25], Step [400/938], Loss: 0.5527\nEpoch [5/25], Step [500/938], Loss: 0.2649\nEpoch [5/25], Step [600/938], Loss: 0.7819\nEpoch [5/25], Step [700/938], Loss: 0.6534\nEpoch [5/25], Step [800/938], Loss: 0.3950\nEpoch [5/25], Step [900/938], Loss: 0.5612\nEpoch [6/25], Step [100/938], Loss: 0.4527\nEpoch [6/25], Step [200/938], Loss: 0.2534\nEpoch [6/25], Step [300/938], Loss: 0.3168\nEpoch [6/25], Step [400/938], Loss: 0.4406\nEpoch [6/25], Step [500/938], Loss: 0.4093\nEpoch [6/25], Step [600/938], Loss: 0.3314\nEpoch [6/25], Step [700/938], Loss: 0.3490\nEpoch [6/25], Step [800/938], Loss: 0.6114\nEpoch [6/25], Step [900/938], Loss: 0.6223\nEpoch [7/25], Step [100/938], Loss: 0.3084\nEpoch [7/25], Step [200/938], Loss: 0.4836\nEpoch [7/25], Step [300/938], Loss: 0.3746\nEpoch [7/25], Step [400/938], Loss: 0.4599\nEpoch [7/25], Step [500/938], Loss: 0.3332\nEpoch [7/25], Step [600/938], Loss: 0.4638\nEpoch [7/25], Step [700/938], Loss: 0.6896\nEpoch [7/25], Step [800/938], Loss: 0.2727\nEpoch [7/25], Step [900/938], Loss: 0.2973\nEpoch [8/25], Step [100/938], Loss: 0.5152\nEpoch [8/25], Step [200/938], Loss: 0.3031\nEpoch [8/25], Step [300/938], Loss: 0.2344\nEpoch [8/25], Step [400/938], Loss: 0.1723\nEpoch [8/25], Step [500/938], Loss: 0.4140\nEpoch [8/25], Step [600/938], Loss: 0.1836\nEpoch [8/25], Step [700/938], Loss: 0.2320\nEpoch [8/25], Step [800/938], Loss: 0.1642\nEpoch [8/25], Step [900/938], Loss: 0.4423\nEpoch [9/25], Step [100/938], Loss: 0.1676\nEpoch [9/25], Step [200/938], Loss: 0.2056\nEpoch [9/25], Step [300/938], Loss: 0.3716\nEpoch [9/25], Step [400/938], Loss: 0.1450\nEpoch [9/25], Step [500/938], Loss: 0.3146\nEpoch [9/25], Step [600/938], Loss: 0.2799\nEpoch [9/25], Step [700/938], Loss: 0.2412\nEpoch [9/25], Step [800/938], Loss: 0.3387\nEpoch [9/25], Step [900/938], Loss: 0.3383\nEpoch [10/25], Step [100/938], Loss: 0.1621\nEpoch [10/25], Step [200/938], Loss: 0.2976\nEpoch [10/25], Step [300/938], Loss: 0.2440\nEpoch [10/25], Step [400/938], Loss: 0.2248\nEpoch [10/25], Step [500/938], Loss: 0.1211\nEpoch [10/25], Step [600/938], Loss: 0.2509\nEpoch [10/25], Step [700/938], Loss: 0.1103\nEpoch [10/25], Step [800/938], Loss: 0.3687\nEpoch [10/25], Step [900/938], Loss: 0.2282\nEpoch [11/25], Step [100/938], Loss: 0.2306\nEpoch [11/25], Step [200/938], Loss: 0.1761\nEpoch [11/25], Step [300/938], Loss: 0.2053\nEpoch [11/25], Step [400/938], Loss: 0.4968\nEpoch [11/25], Step [500/938], Loss: 0.2701\nEpoch [11/25], Step [600/938], Loss: 0.1646\nEpoch [11/25], Step [700/938], Loss: 0.2328\nEpoch [11/25], Step [800/938], Loss: 0.2201\nEpoch [11/25], Step [900/938], Loss: 0.4397\nEpoch [12/25], Step [100/938], Loss: 0.1821\nEpoch [12/25], Step [200/938], Loss: 0.2059\nEpoch [12/25], Step [300/938], Loss: 0.1161\nEpoch [12/25], Step [400/938], Loss: 0.3287\nEpoch [12/25], Step [500/938], Loss: 0.2738\nEpoch [12/25], Step [600/938], Loss: 0.1675\nEpoch [12/25], Step [700/938], Loss: 0.1000\nEpoch [12/25], Step [800/938], Loss: 0.1069\nEpoch [12/25], Step [900/938], Loss: 0.3817\nEpoch [13/25], Step [100/938], Loss: 0.4138\nEpoch [13/25], Step [200/938], Loss: 0.1266\nEpoch [13/25], Step [300/938], Loss: 0.0320\nEpoch [13/25], Step [400/938], Loss: 0.2543\nEpoch [13/25], Step [500/938], Loss: 0.2088\nEpoch [13/25], Step [600/938], Loss: 0.3337\nEpoch [13/25], Step [700/938], Loss: 0.2015\nEpoch [13/25], Step [800/938], Loss: 0.1635\nEpoch [13/25], Step [900/938], Loss: 0.4217\nEpoch [14/25], Step [100/938], Loss: 0.1114\nEpoch [14/25], Step [200/938], Loss: 0.2009\nEpoch [14/25], Step [300/938], Loss: 0.2099\nEpoch [14/25], Step [400/938], Loss: 0.1340\nEpoch [14/25], Step [500/938], Loss: 0.2514\nEpoch [14/25], Step [600/938], Loss: 0.3604\nEpoch [14/25], Step [700/938], Loss: 0.1000\nEpoch [14/25], Step [800/938], Loss: 0.2680\nEpoch [14/25], Step [900/938], Loss: 0.1132\nEpoch [15/25], Step [100/938], Loss: 0.0807\nEpoch [15/25], Step [200/938], Loss: 0.1411\nEpoch [15/25], Step [300/938], Loss: 0.0435\nEpoch [15/25], Step [400/938], Loss: 0.2151\nEpoch [15/25], Step [500/938], Loss: 0.2011\nEpoch [15/25], Step [600/938], Loss: 0.1957\nEpoch [15/25], Step [700/938], Loss: 0.2192\nEpoch [15/25], Step [800/938], Loss: 0.3280\nEpoch [15/25], Step [900/938], Loss: 0.3321\nEpoch [16/25], Step [100/938], Loss: 0.1675\nEpoch [16/25], Step [200/938], Loss: 0.2052\nEpoch [16/25], Step [300/938], Loss: 0.1376\nEpoch [16/25], Step [400/938], Loss: 0.0498\nEpoch [16/25], Step [500/938], Loss: 0.2422\nEpoch [16/25], Step [600/938], Loss: 0.0432\nEpoch [16/25], Step [700/938], Loss: 0.2062\nEpoch [16/25], Step [800/938], Loss: 0.1509\nEpoch [16/25], Step [900/938], Loss: 0.0834\nEpoch [17/25], Step [100/938], Loss: 0.0889\nEpoch [17/25], Step [200/938], Loss: 0.0849\nEpoch [17/25], Step [300/938], Loss: 0.3358\nEpoch [17/25], Step [400/938], Loss: 0.0795\nEpoch [17/25], Step [500/938], Loss: 0.1800\nEpoch [17/25], Step [600/938], Loss: 0.1918\nEpoch [17/25], Step [700/938], Loss: 0.1965\nEpoch [17/25], Step [800/938], Loss: 0.1048\nEpoch [17/25], Step [900/938], Loss: 0.1694\nEpoch [18/25], Step [100/938], Loss: 0.1787\nEpoch [18/25], Step [200/938], Loss: 0.1036\nEpoch [18/25], Step [300/938], Loss: 0.1027\nEpoch [18/25], Step [400/938], Loss: 0.0286\nEpoch [18/25], Step [500/938], Loss: 0.1066\nEpoch [18/25], Step [600/938], Loss: 0.1954\nEpoch [18/25], Step [700/938], Loss: 0.1574\nEpoch [18/25], Step [800/938], Loss: 0.1691\nEpoch [18/25], Step [900/938], Loss: 0.1825\nEpoch [19/25], Step [100/938], Loss: 0.1709\nEpoch [19/25], Step [200/938], Loss: 0.1300\nEpoch [19/25], Step [300/938], Loss: 0.2101\nEpoch [19/25], Step [400/938], Loss: 0.2049\nEpoch [19/25], Step [500/938], Loss: 0.1167\nEpoch [19/25], Step [600/938], Loss: 0.0976\nEpoch [19/25], Step [700/938], Loss: 0.1479\nEpoch [19/25], Step [800/938], Loss: 0.0952\nEpoch [19/25], Step [900/938], Loss: 0.0925\nEpoch [20/25], Step [100/938], Loss: 0.1353\nEpoch [20/25], Step [200/938], Loss: 0.1540\nEpoch [20/25], Step [300/938], Loss: 0.1249\nEpoch [20/25], Step [400/938], Loss: 0.1233\nEpoch [20/25], Step [500/938], Loss: 0.0877\nEpoch [20/25], Step [600/938], Loss: 0.1998\nEpoch [20/25], Step [700/938], Loss: 0.2595\nEpoch [20/25], Step [800/938], Loss: 0.0767\nEpoch [20/25], Step [900/938], Loss: 0.2543\nEpoch [21/25], Step [100/938], Loss: 0.1594\nEpoch [21/25], Step [200/938], Loss: 0.0836\nEpoch [21/25], Step [300/938], Loss: 0.2169\nEpoch [21/25], Step [400/938], Loss: 0.4145\nEpoch [21/25], Step [500/938], Loss: 0.0974\nEpoch [21/25], Step [600/938], Loss: 0.1334\nEpoch [21/25], Step [700/938], Loss: 0.0816\nEpoch [21/25], Step [800/938], Loss: 0.0896\nEpoch [21/25], Step [900/938], Loss: 0.1338\nEpoch [22/25], Step [100/938], Loss: 0.1603\nEpoch [22/25], Step [200/938], Loss: 0.0338\nEpoch [22/25], Step [300/938], Loss: 0.0965\nEpoch [22/25], Step [400/938], Loss: 0.1046\nEpoch [22/25], Step [500/938], Loss: 0.1495\nEpoch [22/25], Step [600/938], Loss: 0.0820\nEpoch [22/25], Step [700/938], Loss: 0.0424\nEpoch [22/25], Step [800/938], Loss: 0.1270\nEpoch [22/25], Step [900/938], Loss: 0.0965\nEpoch [23/25], Step [100/938], Loss: 0.1976\nEpoch [23/25], Step [200/938], Loss: 0.1690\nEpoch [23/25], Step [300/938], Loss: 0.0709\nEpoch [23/25], Step [400/938], Loss: 0.0869\nEpoch [23/25], Step [500/938], Loss: 0.2552\nEpoch [23/25], Step [600/938], Loss: 0.1295\nEpoch [23/25], Step [700/938], Loss: 0.0786\nEpoch [23/25], Step [800/938], Loss: 0.1269\nEpoch [23/25], Step [900/938], Loss: 0.1055\nEpoch [24/25], Step [100/938], Loss: 0.1682\nEpoch [24/25], Step [200/938], Loss: 0.0278\nEpoch [24/25], Step [300/938], Loss: 0.1203\nEpoch [24/25], Step [400/938], Loss: 0.0413\nEpoch [24/25], Step [500/938], Loss: 0.0667\nEpoch [24/25], Step [600/938], Loss: 0.1519\nEpoch [24/25], Step [700/938], Loss: 0.0141\nEpoch [24/25], Step [800/938], Loss: 0.0906\nEpoch [24/25], Step [900/938], Loss: 0.1838\nEpoch [25/25], Step [100/938], Loss: 0.0716\nEpoch [25/25], Step [200/938], Loss: 0.0740\nEpoch [25/25], Step [300/938], Loss: 0.1835\nEpoch [25/25], Step [400/938], Loss: 0.1608\nEpoch [25/25], Step [500/938], Loss: 0.0530\nEpoch [25/25], Step [600/938], Loss: 0.0820\nEpoch [25/25], Step [700/938], Loss: 0.0995\nEpoch [25/25], Step [800/938], Loss: 0.0494\nEpoch [25/25], Step [900/938], Loss: 0.1199\n","output_type":"stream"}]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total} %\")\n","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:10:08.334320Z","iopub.execute_input":"2023-08-24T11:10:08.335024Z","iopub.status.idle":"2023-08-24T11:10:10.883646Z","shell.execute_reply.started":"2023-08-24T11:10:08.334973Z","shell.execute_reply":"2023-08-24T11:10:10.881985Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 95.53 %\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'mnist_dense_model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-08-24T11:10:10.885510Z","iopub.execute_input":"2023-08-24T11:10:10.886999Z","iopub.status.idle":"2023-08-24T11:10:10.899614Z","shell.execute_reply.started":"2023-08-24T11:10:10.886945Z","shell.execute_reply":"2023-08-24T11:10:10.897823Z"},"trusted":true},"execution_count":17,"outputs":[]}]}